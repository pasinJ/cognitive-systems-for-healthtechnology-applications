{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 2. Diabetic retinopathy diagnosis\n",
    "Mr.Pasin Jiratthitcheep<br>\n",
    "Last edited: 24.02.2019<br>\n",
    "Cognitive Systems for Health Technology Applications<br>\n",
    "[Helsinki Metropolia University of Applied Sciences](http://www.metropolia.fi/en/)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Objectives\n",
    "2. Required libraries\n",
    "3. Data description and preprocessing\n",
    "4. Modeling and compilation\n",
    "    * Model 1 : Xception pretrained model\n",
    "    * Model 2 : Xception pretrained model (freezing weight)\n",
    "    * Model 3 : InceptionResNetV2 pretrained model\n",
    "    * Model 4 : InceptionResNetV2 pretrained model (freezing weight)\n",
    "    * Model 5 : 4 convolutional layers model\n",
    "5. Training and Validation\n",
    "    * Training Model 1 (Xception pretrained model)\n",
    "        - Go further with Model 1 (Xception pretrained model)\n",
    "    * Training Model 2 (Xception pretrained model (freezing weight))\n",
    "    * Training Model 3 (InceptionResNetV2 pretrained model)\n",
    "        - Go further with Model 3 (InceptionResNetV2 pretrained model)\n",
    "    * Training Model 4 (InceptionResNetV2 pretrained model (freezing weight))\n",
    "    * Training Model 5 (4 convolutional layers model)\n",
    "6. Evaluation\n",
    "    * Selcetion the best of all\n",
    "    * Comparison with training by imbalance dataset\n",
    "7. Results and discussion\n",
    "    * Final model with test set\n",
    "    * ROC Curve\n",
    "    * Trying to change decisoin point\n",
    "8. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was created for learning to use convolutional neural networks to classify medical images. The study case is about <b>Diabetic retinopathy</b> that is an eye disease associated with long-standing diabetes. Around 40% to 45% of Americans with diabetes have some stage of the disease.\n",
    "\n",
    "I hoped to learn about how to preprocess the images dataset and what are the techniques those can be implemented with image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil, cv2, time\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications import InceptionResNetV2, Xception\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score, classification_report\n",
    "from sklearn.metrics import accuracy_score, roc_curve\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data description and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used a dataset from https://www.kaggle.com/sakarilukkarinen/preprocessed-diabetic-retinopathy-trainset that it was preprocessed by basing on <b>Benjamin Graham's Competition report</b> (that Sakari shared to us).\n",
    "\n",
    "In his report he explains that he used the following <b>preprocessing strategy</b>:\n",
    "    1. Rescale the images to have the same radius (scale = 300 pixels).\n",
    "    2. Subtract the local average color from the images (50% gray).\n",
    "    3. Mask the image to 90% of the scale to remove the boundary effects.\n",
    "    \n",
    "In additional, images were devided into 2 folders (300_train and 300_test) and it also include csv files (newTrainLabels.csv and retinopathy_solution.csv) those content label data for each image in the folders. The <b>newTrainLabels.csv contains totally 35,124 records</b> and the <b>retinopathy_solution.csv contains 53,576 records</b>.\n",
    "\n",
    "<b>Columns of newTrainLabels.csv:</b>\n",
    "    * image = name of the image file (without the extension *.jpeg)\n",
    "    * level = level of the retinopathy (0 = healthy, ..., 4 = severe)\n",
    "    * MB = size of the image file in MegaBytes\n",
    "    \n",
    "<b>Columns of newTrainLabels.csv:</b>\n",
    "    * image = image name\n",
    "    * level = diabetic retinopathy level (0 = Healthy, ..., 4 = Severe)\n",
    "    * Usage = Usage in original competition (public = for public rankings, private = for private rankings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I defined most of variables here. I used image size <b>only 150x150 pixel because of my resource limitation</b> even I know that the performance will be better if we use larger image size (my GPU on laptop can't calculate too big image size). So, I decided to increase the number of training-set instead by using <b>6,000 records</b> from 300_train folder for training and validaton (4,500 for training and 1,500 for validation). For the batch size, I already tried larger than 16, but my resurce can't handle them, so I decided to use <b>16 for my batch size</b>. And test set has balanced class distribution with <b>total amount 10,000 records</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:     4500\n",
      "Validation set:   1500\n",
      "Test set:         10000\n",
      "Batch size:       16\n",
      "Training steps:   281\n",
      "Validation steps: 93\n",
      "Epochs:           100\n",
      "Image size:       (150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "# Raw images directories\n",
    "raw_train_dir = \"./input/300_train/\"\n",
    "raw_test_dir = \"./input/300_test/\"\n",
    "\n",
    "SIZE = 6000 # Total number of images pooled from 300_train\n",
    "SPLIT = 4500 # Number of images used for training\n",
    "Test_SIZE = 10000 # Total number of image pooled from 300_test for testing set\n",
    "BATCH_SIZE = 16\n",
    "TRAIN_STEPS = SPLIT // BATCH_SIZE\n",
    "VALID_STEPS = (SIZE - SPLIT) // BATCH_SIZE\n",
    "EPOCHS = 100\n",
    "N_EPOCHS = 0\n",
    "IMAGE_SIZE = 150\n",
    "seed = 24 # Seed for random sample the dataset\n",
    "\n",
    "print('Training set:    ', SPLIT)\n",
    "print('Validation set:  ', SIZE - SPLIT)\n",
    "print('Test set:        ', Test_SIZE)\n",
    "print('Batch size:      ', BATCH_SIZE)\n",
    "print('Training steps:  ', TRAIN_STEPS)\n",
    "print('Validation steps:', VALID_STEPS)\n",
    "print('Epochs:          ', EPOCHS)\n",
    "print('Image size:      ', (IMAGE_SIZE, IMAGE_SIZE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "      <th>MB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_left</td>\n",
       "      <td>0</td>\n",
       "      <td>0.146893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_right</td>\n",
       "      <td>0</td>\n",
       "      <td>0.134647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13_left</td>\n",
       "      <td>0</td>\n",
       "      <td>0.179653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_right</td>\n",
       "      <td>0</td>\n",
       "      <td>0.173361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_left</td>\n",
       "      <td>1</td>\n",
       "      <td>0.129906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image  level        MB\n",
       "0   10_left      0  0.146893\n",
       "1  10_right      0  0.134647\n",
       "2   13_left      0  0.179653\n",
       "3  13_right      0  0.173361\n",
       "4   15_left      1  0.129906"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read csv file data for training-set and validation-set\n",
    "df = pd.read_csv(r\"./input/newTrainLabels.csv\")\n",
    "\n",
    "# Show top 5 record of csv file\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I get dataframe from newTrainLabels.csv, I changed label <b>from 5-classes into only binary-classes</b> then I showed the number of records for each class in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many records for each class\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    25808\n",
       "1     9316\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change categorical labels into binary labels\n",
    "df['level'] = 1*(df['level'] > 0)\n",
    "\n",
    "# Show distribution of datset for each class\n",
    "print(\"How many records for each class\")\n",
    "df['level'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the number of records for eah class in dataset, our dataset has <b>imbalanced class distribution</b>. \n",
    "\n",
    "As far as I know, some of machine learning algorithms have a bias towards classes based on number of instances. They tend to only predict the majority class data. The features of the minority class are treated as noise and are often ignored. Thus, there is a high probability of misclassification of the minority class as compared to the majority class. By using imbalanced dataset to train model, it maybe tend to get a bias model, but I'm not sure about this case from many notebook examples those seem to doesn't care much about this. So I decided to <b>create both balanced and imbalanced set</b> to test my hypothesis. I will use them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many records for each class (imbalance data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    4419\n",
       "1    1581\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample unbalanced dataframe as normally\n",
    "df_unbalance = df.sample(n = SIZE, random_state = seed)\n",
    "\n",
    "# Show distribution of datset for each class\n",
    "print(\"How many records for each class (imbalance data)\")\n",
    "df_unbalance['level'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how I create my balanced set. I group the dataframe by level column first and then sample each of them with the equal size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many records for each class (after balancing)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    3000\n",
       "0    3000\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group records by level feature\n",
    "g = df.groupby('level')\n",
    "\n",
    "# Sample records equal to SIZE//2 for each group for balancing the dataset\n",
    "df_balance = g.apply(lambda x: x.sample(SIZE//2, random_state = seed).reset_index(drop=True))\n",
    "\n",
    "# Show distribution of datset for each class\n",
    "print(\"How many records for each class (after balancing)\")\n",
    "df_balance['level'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I create testing-set from another image folder and also make it balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_left</td>\n",
       "      <td>0</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_right</td>\n",
       "      <td>0</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_left</td>\n",
       "      <td>0</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_right</td>\n",
       "      <td>0</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3_left</td>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image  level    Usage\n",
       "0   1_left      0  Private\n",
       "1  1_right      0  Private\n",
       "2   2_left      0   Public\n",
       "3  2_right      0   Public\n",
       "4   3_left      1  Private"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read csv file data for testing-set\n",
    "df_test = pd.read_csv(r\"./input/retinopathy_solution.csv\")\n",
    "\n",
    "# Change categorical labels into binary labels\n",
    "df_test['level'] = 1*(df_test['level'] > 0)\n",
    "\n",
    "# Show top 5 record of csv file\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many record for each class for testing-set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    5000\n",
       "0    5000\n",
       "Name: level, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group records by level feature\n",
    "g_test = df_test.groupby('level')\n",
    "\n",
    "# Sample records equal to Test_SIZE//2 for each group for balancing the testing-set\n",
    "df_test = g_test.apply(lambda x: x.sample(Test_SIZE//2, random_state = seed).reset_index(drop=True))\n",
    "\n",
    "# Show distribution of datset for each class\n",
    "print(\"How many record for each class for testing-set\")\n",
    "df_test['level'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function that use for creating directory for cropped images (From Demo 11 notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define creating directory function for cropped images\n",
    "def create_dir(dest_dir):\n",
    "    try:\n",
    "        # If the directory doesn't exist\n",
    "        os.mkdir(dest_dir)\n",
    "        print('Created a directory:', dest_dir)\n",
    "    except:\n",
    "        # Temp directory already exist, so clear it\n",
    "        for file in os.listdir(dest_dir):  \n",
    "            file_path = os.path.join(dest_dir, file)\n",
    "            try:\n",
    "                if os.path.isfile(file_path):\n",
    "                    os.unlink(file_path)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        print(dest_dir, ' cleared.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created 3 directories for balanced set, imbalanced set, and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for cropped training-set and validation-set those are balanced\n",
    "balance_dir = './balance/'\n",
    "create_dir(balance_dir)\n",
    "\n",
    "# Create directory for cropped training-set and validation-set those are unbalanced\n",
    "unbalance_dir = './unbalance/'\n",
    "create_dir(unbalance_dir)\n",
    "\n",
    "# Create directory for cropped testing-set\n",
    "test_dir = './test/'\n",
    "create_dir(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is cropping image function for resize image to have size as we want and save to directory that we already created above (From Demo 11 notebook).\n",
    "\n",
    "I think that cropping image is a very important step. Becuase from my experiment, before Sakari given a hint notebook (Demo 11), I have tried to use preprocessing images dataset with many types of model and it couldn't learn anything from those training set (accuracy is around 49-51%).\n",
    "\n",
    "You can see from my draft version notebook <a href=\"https://github.com/pasinJ/cognitive-systems-for-healthtechnology-applications/blob/master/(Draft)%20Case%202%20pretraining%20model%20with%20preprocessing%20dataset.ipynb\">here</a> if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for cropping image to (IMAGE_SIZE, IMAGE_SIZE)\n",
    "def cropping_image(df, source_dir, dest_dir):\n",
    "    # Start timing\n",
    "    start = time.time()\n",
    "\n",
    "    # Crop and resize all images. Store them to dest_dir\n",
    "    for i, file in enumerate(df['image']):\n",
    "        try:\n",
    "            fname = source_dir + file + '.jpeg'\n",
    "            img = cv2.imread(fname)\n",
    "\n",
    "            # Crop the image to the height\n",
    "            h, w, c = img.shape\n",
    "            if w > h:\n",
    "                wc = int(w/2)\n",
    "                w0 = wc - int(h/2)\n",
    "                w1 = w0 + h\n",
    "                img = img[:, w0:w1, :]\n",
    "            # Rescale to N x N\n",
    "            N = IMAGE_SIZE\n",
    "            img = cv2.resize(img, (N, N))\n",
    "            # Save\n",
    "            new_fname = dest_dir + file + '.png'\n",
    "            cv2.imwrite(new_fname, img)\n",
    "        except:\n",
    "            # Display the image name having troubles\n",
    "            print(fname)\n",
    "\n",
    "        # Print the progress for every N images\n",
    "        if (i % 500 == 0) & (i > 0):\n",
    "            print('{:} images resized in {:.2f} seconds.'.format(i, time.time()-start))\n",
    "\n",
    "    # End timing\n",
    "    print('Total elapsed time {:.2f} seconds.'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop and resize images for balanced training-set and validation-set\n",
    "print('Cropping and rescaling the images for training-set and validation-set (balance):')\n",
    "cropping_image(df_balance, raw_train_dir, balance_dir)\n",
    "print()\n",
    "\n",
    "# Crop and resize images for unbalanced training-set and validation-set\n",
    "print('Cropping and rescaling the images for training-set and validation-set (imbalance):')\n",
    "cropping_image(df_unbalance, raw_train_dir, unbalance_dir)\n",
    "print()\n",
    "\n",
    "# Crop and resize images for unbalanced testing-set\n",
    "print('Cropping and rescaling the images for testing-set:')\n",
    "cropping_image(df_test, raw_test_dir, test_dir)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For balanced set, I seperated them into traning-set and validation set by using StratifiedShuffleSplit function to get a balanced set for each traning-set and validation-set.\n",
    "\n",
    "    * Training-set   = 4,500 samples\n",
    "    * Validation-set = 1,500 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many record for each class for testing-set\n",
      "Training-set --->\n",
      "1    2250\n",
      "0    2250\n",
      "Name: level, dtype: int64\n",
      "Validation-set --->\n",
      "1    750\n",
      "0    750\n",
      "Name: level, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Seperate dataframe into feature(X) and label(y)\n",
    "X_balance = df_balance.image\n",
    "y_balance = df_balance.level\n",
    "\n",
    "# Ramdomly split balanced set into traning-set and validation-set\n",
    "stratSplit = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "for train_idx,test_idx in stratSplit.split(X_balance, y_balance):\n",
    "    X_train = X_balance[train_idx]\n",
    "    y_train = y_balance[train_idx]\n",
    "    X_val = X_balance[test_idx]\n",
    "    y_val = y_balance[test_idx]\n",
    "\n",
    "# Concatinate it back to dataframe format\n",
    "df_train_balance = pd.concat([X_train, y_train], axis=1)\n",
    "df_val_balance = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "# Show distribution of datset for each class\n",
    "print(\"How many record for each class for testing-set\")\n",
    "print(\"Training-set --->\")\n",
    "print(df_train_balance['level'].value_counts())\n",
    "print(\"Validation-set --->\")\n",
    "print(df_val_balance['level'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I prepared ImageDataGenerator that generate batches of tensor image data with real-time data augmentation. I decided to <b>use balanced dataset to train my models</b> so I created flow only from balanced dataset at this moment.\n",
    "\n",
    "For the validation and test generator, I only rescale the image that pass through the generator.\n",
    "\n",
    "\"Data augmentation takes the approach of generating more training data from existing training samples, by \"augmenting\" the samples via a number of random transformations that yield believable-looking images. The goal is that at training time, our model would never see the exact same picture twice. This helps the model get exposed to more aspects of the data and generalize better.\" (from <a href=\"https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.2-using-convnets-with-small-datasets.ipynb\">Using convnets with small datasets</a>)\n",
    "\n",
    "So for the train generator, I also <b>added data augmentation into the generator</b>, to avoid the overfitting while traning models, including zooming, rotation, and fliping both horizontal and vertical axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training flow (balance):\n",
      "Found 4500 images belonging to 2 classes.\n",
      "Validation flow (balance):\n",
      "Found 1500 images belonging to 2 classes.\n",
      "Test flow:\n",
      "Found 10000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Validation and testing generator, only rescale the images from 0..255 to range 0..1\n",
    "valid_test_generator = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Train generator: rescale, zoom, rotate and flip\n",
    "train_generator = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    zoom_range = 0.1,\n",
    "    rotation_range = 180,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True)\n",
    "\n",
    "# Training flow (balance)\n",
    "print('Training flow (balance):')\n",
    "train_flow = train_generator.flow_from_dataframe(\n",
    "    dataframe = df_train_balance,\n",
    "    directory = balance_dir,\n",
    "    has_ext = False,\n",
    "    x_col = 'image', \n",
    "    y_col = 'level', \n",
    "    target_size = (IMAGE_SIZE, IMAGE_SIZE), \n",
    "    classes = [0, 1], \n",
    "    class_mode = 'binary', \n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = True, \n",
    "    seed = 1)\n",
    "\n",
    "# Validation flow (balance)\n",
    "print('Validation flow (balance):')\n",
    "valid_flow = valid_test_generator.flow_from_dataframe(\n",
    "    dataframe = df_val_balance,\n",
    "    directory = balance_dir,\n",
    "    has_ext = False,\n",
    "    x_col = 'image', \n",
    "    y_col = 'level', \n",
    "    target_size = (IMAGE_SIZE, IMAGE_SIZE), \n",
    "    classes = [0, 1], \n",
    "    class_mode = 'binary', \n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = False)\n",
    "\n",
    "# Test flow\n",
    "print('Test flow:')\n",
    "test_flow = valid_test_generator.flow_from_dataframe(\n",
    "    dataframe = df_test,\n",
    "    directory = test_dir,\n",
    "    has_ext = False,\n",
    "    x_col = 'image', \n",
    "    y_col = 'level', \n",
    "    target_size = (IMAGE_SIZE, IMAGE_SIZE), \n",
    "    classes = [0, 1], \n",
    "    class_mode = 'binary', \n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling and compilation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, I already tried to use multiple of pretraining convnets with the small dataset (without preprocessing and balancing), but those didn't seem to work very well (as you can see from my draft notebook <a href=\"https://github.com/pasinJ/cognitive-systems-for-healthtechnology-applications/blob/master/(Draft)%20Case%202%20try%20pretraining%20model.ipynb\">here</a>).\n",
    "\n",
    "\"Before we compile and train our model, a <b>very important thing to do is to freeze the convolutional base</b>. \"Freezing\" a layer or set of layers means preventing their weights from getting updated during training. If we don't do this, then the representations that were previously learned by the convolutional base would get modified during training. Since the Dense layers on top are randomly initialized, very large weight updates would be propagated through the network, effectively destroying the representations previously learned.\" (from <a href=\"https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.3-using-a-pretrained-convnet.ipynb\">Using a pre-trained convnet</a>)\n",
    "\n",
    "The previous version, I train pretraining model with freezing base_layer weight as I read from the above example. Then, I found that maybe because ImageNet dataset that was used to train those pretraining models make them don't fit with this DR classification case. <b>Sakari's notebook (Demo 11) given me a idea to try to use pretraining models without freezing a base weight layers.</b>\n",
    "\n",
    "In this notebook, I tried 2 architecture of pretraining model (Xception and InceptionResNetV2) those are the highest top-1 accuracy score from among pretraining models in keras library (https://keras.io/applications/). <b>I create with and without freezing weight of base_layer to compare them after the training.</b> Another model is created with 4 convolutional layers + dense layers to compare with pretraining models those have complex architecture.\n",
    "\n",
    "So I ended up with follwing 5 models:\n",
    "    1. Xception pretraining model\n",
    "    2. Xception pretraining model (freezing weight)\n",
    "    3. InceptionResNetV2 pretraining model\n",
    "    4. InceptionResNetV2 pretraining model (freezing weight)\n",
    "    5. 4 convolutional layers model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 : Xception pretraining model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model model used <b>Xception model as a base layer</b>, but we ignore the original top layers of it and pass the output from 'avg_pool' layer to our Dense layer with sigmoid as activation function. \n",
    "\n",
    "We use rmsprop optimizer and standard binary_crossentropy loss-function and accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 74, 74, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 74, 74, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 74, 74, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 72, 72, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 72, 72, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 72, 72, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 72, 72, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 72, 72, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 72, 72, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 36, 36, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 36, 36, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 36, 36, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 36, 36, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 36, 36, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 36, 36, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 36, 36, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 36, 36, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 18, 18, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 18, 18, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 18, 18, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 18, 18, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 18, 18, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 18, 18, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 18, 18, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 18, 18, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 9, 9, 728)    186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 9, 9, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 9, 9, 728)    2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 9, 9, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 9, 9, 728)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 9, 9, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 9, 9, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 9, 9, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 9, 9, 728)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 9, 9, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 9, 9, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 9, 9, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 9, 9, 728)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 9, 9, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 9, 9, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 9, 9, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 9, 9, 728)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 9, 9, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 9, 9, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 9, 9, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 9, 9, 728)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 9, 9, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 9, 9, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 9, 9, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 9, 9, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 9, 9, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 9, 9, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 9, 9, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 9, 9, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 9, 9, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 9, 9, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 9, 9, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 9, 9, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 9, 9, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 9, 9, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 9, 9, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 5, 5, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 5, 5, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 5, 5, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 5, 5, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 5, 5, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 5, 5, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 5, 5, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 5, 5, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 5, 5, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 5, 5, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2049        avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the pretraining Xception model, pop out the last dense layer\n",
    "base_model1 = Xception(input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "x_model1 = Dense(1)(base_model1.get_layer('avg_pool').output)\n",
    "y_model1 = Activation('sigmoid')(x_model1)\n",
    "model1 = Model(inputs = base_model1.input, outputs = y_model1)\n",
    "\n",
    "# Optimizer, loss and metrics\n",
    "model1.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Show model summary\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 : Xception pretraining model (freezing weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model model used <b>Xception model as a base layer</b>, but we ignore the original top layers of it and pass the output from 'avg_pool' layer to our Dense layer with sigmoid as activation function.\n",
    "\n",
    "In this model, we also <b>freezed the weight of Xception</b> base layers.\n",
    "\n",
    "We use rmsprop optimizer and standard binary_crossentropy loss-function and accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 5, 5, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               13107456  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 33,969,193\n",
      "Trainable params: 13,107,713\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the pretraining Xception model, pop out the last dense layer\n",
    "base_model2 = Xception(include_top=False,\n",
    "                  input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "# Freeze weight of Xception layers (untrainable)\n",
    "base_model2.trainable = False\n",
    "\n",
    "# Add our Dense layers for classificaton\n",
    "model2 = models.Sequential()\n",
    "model2.add(base_model2)\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(256, activation='relu'))\n",
    "model2.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Optimizer, loss and metrics\n",
    "model2.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Show model summary\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 : InceptionResNetV2 pretraining model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model model used <b>InceptionResNetV2 model as a base layer</b>, but we ignore the original top layers of it and pass the output from 'avg_pool' layer to our Dense layer with sigmoid as activation function. \n",
    "\n",
    "We use rmsprop optimizer and standard binary_crossentropy loss-function and accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 74, 74, 32)   864         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 74, 74, 32)   96          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 74, 74, 32)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 72, 72, 32)   9216        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 72, 72, 32)   96          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 72, 72, 32)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 72, 72, 64)   18432       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 72, 72, 64)   192         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 72, 72, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 80)   240         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 80)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 33, 33, 192)  138240      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 33, 33, 192)  576         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 33, 33, 192)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 64)   192         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 96)   55296       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 48)   144         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 48)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 96)   18432       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 64)   76800       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 96)   82944       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 64)   12288       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 96)   288         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 96)   288         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 96)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 96)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 16, 16, 320)  0           activation_7[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "                                                                 activation_12[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 32)   96          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 32)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 48)   13824       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 32)   96          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 48)   144         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 32)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 48)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 32)   9216        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 64)   27648       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 32)   96          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 32)   96          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 32)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 16, 16, 128)  0           activation_14[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 16, 16, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 16, 16, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 16, 16, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 32)   96          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 32)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 48)   13824       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 32)   96          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 48)   144         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 32)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 48)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 32)   9216        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 64)   27648       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 32)   96          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 32)   96          conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 64)   192         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 32)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 32)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 16, 16, 128)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 16, 16, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 16, 16, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 16, 16, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 32)   96          conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 32)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 48)   13824       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 32)   96          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 48)   144         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 32)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 48)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 32)   9216        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 64)   27648       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 32)   96          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 32)   96          conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 64)   192         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 32)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 32)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 64)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 16, 16, 128)  0           activation_26[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 16, 16, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 16, 16, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 16, 16, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 32)   96          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 32)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 48)   13824       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 32)   96          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 48)   144         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 32)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 48)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 32)   9216        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 64)   27648       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 32)   96          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 32)   96          conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 64)   192         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 32)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 64)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 16, 16, 128)  0           activation_32[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 16, 16, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 16, 16, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 16, 16, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 32)   96          conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 32)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 48)   13824       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 32)   96          conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 48)   144         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 32)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 48)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 32)   9216        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 64)   27648       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 32)   96          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 32)   96          conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 16, 16, 64)   192         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 32)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 32)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 64)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 16, 16, 128)  0           activation_38[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 16, 16, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 16, 16, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 16, 16, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 16, 16, 32)   96          conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 32)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 16, 16, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 16, 16, 48)   13824       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 16, 16, 32)   96          conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 16, 16, 48)   144         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 32)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 48)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 16, 16, 32)   9216        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 16, 16, 64)   27648       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 16, 16, 32)   96          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 16, 16, 32)   96          conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 16, 16, 64)   192         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 32)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 32)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 64)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 16, 16, 128)  0           activation_44[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 16, 16, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 16, 16, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 16, 16, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 16, 16, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 16, 16, 32)   96          conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 16, 16, 32)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 16, 16, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 16, 16, 48)   13824       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 16, 16, 32)   96          conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 16, 16, 48)   144         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16, 16, 32)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 16, 16, 48)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 16, 16, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 16, 16, 32)   9216        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 16, 16, 64)   27648       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 16, 16, 32)   96          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 16, 16, 32)   96          conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 16, 16, 64)   192         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 16, 16, 32)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 16, 16, 32)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 16, 16, 64)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 16, 16, 128)  0           activation_50[0][0]              \n",
      "                                                                 activation_52[0][0]              \n",
      "                                                                 activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 16, 16, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 16, 16, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 16, 16, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 16, 16, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 16, 16, 32)   96          conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 16, 16, 32)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 16, 16, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 16, 16, 48)   13824       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 16, 16, 32)   96          conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 16, 16, 48)   144         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 16, 16, 32)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 16, 16, 48)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 16, 16, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 16, 16, 32)   9216        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 16, 16, 64)   27648       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 16, 16, 32)   96          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 16, 16, 32)   96          conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 16, 16, 64)   192         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 16, 16, 32)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16, 16, 32)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 16, 16, 64)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 16, 16, 128)  0           activation_56[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 16, 16, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 16, 16, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 16, 16, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 16, 16, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 16, 16, 32)   96          conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 16, 16, 32)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 16, 16, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 16, 16, 48)   13824       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 16, 16, 32)   96          conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 16, 16, 48)   144         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 16, 16, 32)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 16, 16, 48)   0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 16, 16, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 16, 16, 32)   9216        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 16, 16, 64)   27648       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 16, 16, 32)   96          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 16, 16, 32)   96          conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 16, 16, 64)   192         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 16, 16, 32)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 16, 16, 32)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 16, 16, 64)   0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 16, 16, 128)  0           activation_62[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 16, 16, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 16, 16, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 16, 16, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 16, 16, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 16, 16, 32)   96          conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 16, 16, 32)   0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 16, 16, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 16, 16, 48)   13824       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 16, 16, 32)   96          conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 16, 16, 48)   144         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 16, 16, 32)   0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 16, 16, 48)   0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 16, 16, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 16, 16, 32)   9216        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 16, 16, 64)   27648       activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 16, 16, 32)   96          conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 16, 16, 32)   96          conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 16, 16, 64)   192         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 16, 16, 32)   0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 16, 16, 32)   0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 16, 16, 64)   0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 16, 16, 128)  0           activation_68[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "                                                                 activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 16, 16, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 16, 16, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 16, 16, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 16, 16, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 16, 16, 256)  768         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 16, 16, 256)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 16, 16, 256)  589824      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 16, 16, 256)  768         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 16, 16, 256)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 7, 7, 384)    1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 7, 7, 384)    884736      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 7, 7, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 7, 7, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 7, 7, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 7, 7, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 320)    0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 7, 7, 1088)   0           activation_74[0][0]              \n",
      "                                                                 activation_77[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 7, 7, 128)    139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 7, 7, 128)    384         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 7, 7, 128)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 7, 7, 160)    143360      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 7, 7, 160)    480         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 7, 7, 160)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 7, 7, 192)    208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 7, 7, 192)    215040      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 7, 7, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 7, 7, 192)    576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 7, 7, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 7, 7, 192)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 7, 7, 384)    0           activation_78[0][0]              \n",
      "                                                                 activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 7, 7, 1088)   418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 7, 7, 1088)   0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 7, 7, 1088)   0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 7, 7, 128)    139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 7, 7, 128)    384         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 7, 7, 128)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 7, 7, 160)    143360      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 7, 7, 160)    480         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 7, 7, 160)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 7, 7, 192)    208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 7, 7, 192)    215040      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 7, 7, 192)    576         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 7, 7, 192)    576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 7, 7, 192)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 7, 7, 192)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 7, 7, 384)    0           activation_82[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 7, 7, 1088)   418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 7, 7, 1088)   0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 7, 7, 1088)   0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 7, 7, 128)    139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 7, 7, 128)    384         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 7, 7, 128)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 7, 7, 160)    143360      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 7, 7, 160)    480         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 7, 7, 160)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 7, 7, 192)    208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 7, 7, 192)    215040      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 7, 7, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 7, 7, 192)    576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 7, 7, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 7, 7, 192)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 7, 7, 384)    0           activation_86[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 7, 7, 1088)   418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 7, 7, 1088)   0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 7, 7, 1088)   0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 7, 7, 128)    139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 7, 7, 128)    384         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 7, 7, 128)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 7, 7, 160)    143360      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 7, 7, 160)    480         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 7, 7, 160)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 7, 7, 192)    208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 7, 7, 192)    215040      activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 7, 7, 192)    576         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 7, 7, 192)    576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 7, 7, 192)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 7, 7, 192)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 7, 7, 384)    0           activation_90[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 7, 7, 1088)   418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 7, 7, 1088)   0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 7, 7, 1088)   0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 7, 7, 128)    139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 7, 7, 128)    384         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 7, 7, 128)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 7, 7, 160)    143360      activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 7, 7, 160)    480         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 7, 7, 160)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 7, 7, 192)    208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 7, 7, 192)    215040      activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 7, 7, 192)    576         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 7, 7, 192)    576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 7, 7, 192)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 7, 7, 192)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 7, 7, 384)    0           activation_94[0][0]              \n",
      "                                                                 activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 7, 7, 1088)   418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 7, 7, 1088)   0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 7, 7, 1088)   0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 7, 7, 128)    139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 7, 7, 128)    384         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 7, 7, 128)    0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 7, 7, 160)    143360      activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 7, 7, 160)    480         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 7, 7, 160)    0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 7, 7, 192)    208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 7, 7, 192)    215040      activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 7, 7, 192)    576         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 7, 7, 192)    576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 7, 7, 192)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 7, 7, 192)    0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 7, 7, 384)    0           activation_98[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 7, 7, 1088)   418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 7, 7, 1088)   0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 7, 7, 1088)   0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 7, 7, 128)    139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 7, 7, 128)    384         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 7, 7, 128)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 7, 7, 160)    143360      activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 7, 7, 160)    480         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 7, 7, 160)    0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 7, 7, 192)    208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 7, 7, 192)    215040      activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 7, 7, 192)    576         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 7, 7, 192)    576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 7, 7, 192)    0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 7, 7, 192)    0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 7, 7, 384)    0           activation_102[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 7, 7, 1088)   418880      block17_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 7, 7, 1088)   0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 7, 7, 1088)   0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 7, 7, 128)    139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 7, 7, 128)    384         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 7, 7, 128)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 7, 7, 160)    143360      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 7, 7, 160)    480         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 7, 7, 160)    0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 7, 7, 192)    208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 7, 7, 192)    215040      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 7, 7, 192)    576         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 7, 7, 192)    576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 7, 7, 192)    0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 7, 7, 192)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 7, 7, 384)    0           activation_106[0][0]             \n",
      "                                                                 activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 7, 7, 1088)   418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 7, 7, 1088)   0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 7, 7, 1088)   0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 7, 7, 128)    139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 7, 7, 128)    384         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 7, 7, 128)    0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 7, 7, 160)    143360      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 7, 7, 160)    480         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 7, 7, 160)    0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 7, 7, 192)    208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 7, 7, 192)    215040      activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 7, 7, 192)    576         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 7, 7, 192)    576         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 7, 7, 192)    0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 7, 7, 192)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 7, 7, 384)    0           activation_110[0][0]             \n",
      "                                                                 activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 7, 7, 1088)   418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 7, 7, 1088)   0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 7, 7, 1088)   0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 7, 7, 128)    139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 7, 7, 128)    384         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 7, 7, 128)    0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 7, 7, 160)    143360      activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 7, 7, 160)    480         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 7, 7, 160)    0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 7, 7, 192)    208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 7, 7, 192)    215040      activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 7, 7, 192)    576         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 7, 7, 192)    576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 7, 7, 192)    0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 7, 7, 192)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 7, 7, 384)    0           activation_114[0][0]             \n",
      "                                                                 activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 7, 7, 1088)   418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 7, 7, 1088)   0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 7, 7, 1088)   0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 7, 7, 128)    139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 7, 7, 160)    143360      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 7, 7, 160)    480         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 7, 7, 160)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 7, 7, 192)    208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 7, 7, 192)    215040      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 7, 7, 192)    576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 7, 7, 192)    576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 7, 7, 192)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 7, 7, 192)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 7, 7, 384)    0           activation_118[0][0]             \n",
      "                                                                 activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 7, 7, 1088)   418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 7, 7, 1088)   0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 7, 7, 1088)   0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 7, 7, 128)    139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 7, 7, 160)    143360      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 7, 7, 160)    480         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 7, 7, 160)    0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 7, 7, 192)    208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 7, 7, 192)    215040      activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 7, 7, 192)    576         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 7, 7, 192)    576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 7, 7, 192)    0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 7, 7, 192)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 7, 7, 384)    0           activation_122[0][0]             \n",
      "                                                                 activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 7, 7, 1088)   418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 7, 7, 1088)   0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 7, 7, 1088)   0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 7, 7, 128)    139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 7, 7, 128)    384         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 7, 7, 128)    0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 7, 7, 160)    143360      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 7, 7, 160)    480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 7, 7, 160)    0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 7, 7, 192)    208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 7, 7, 192)    215040      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 7, 7, 192)    576         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 7, 7, 192)    0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 7, 7, 384)    0           activation_126[0][0]             \n",
      "                                                                 activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 7, 7, 1088)   418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 7, 7, 1088)   0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 7, 7, 1088)   0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 7, 7, 128)    139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 7, 7, 128)    384         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 7, 7, 160)    143360      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 7, 7, 192)    208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 7, 7, 192)    215040      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 7, 7, 192)    576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 7, 7, 192)    576         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 7, 7, 192)    0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 7, 7, 384)    0           activation_130[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 7, 7, 1088)   418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 7, 7, 1088)   0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 7, 7, 1088)   0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 7, 7, 128)    139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 7, 7, 128)    384         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 7, 7, 128)    0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 7, 7, 160)    143360      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 7, 7, 160)    480         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 7, 7, 192)    208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 7, 7, 192)    215040      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 7, 7, 192)    576         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 7, 7, 384)    0           activation_134[0][0]             \n",
      "                                                                 activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 7, 7, 1088)   418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 7, 7, 1088)   0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 7, 7, 1088)   0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 7, 7, 128)    139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 7, 7, 128)    384         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 7, 7, 128)    0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 7, 7, 160)    143360      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 7, 7, 160)    480         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 7, 7, 192)    208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 7, 7, 192)    215040      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 7, 7, 192)    576         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 7, 7, 192)    576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 7, 7, 192)    0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 7, 7, 192)    0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 7, 7, 384)    0           activation_138[0][0]             \n",
      "                                                                 activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 7, 7, 1088)   418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 7, 7, 1088)   0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 7, 7, 1088)   0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 7, 7, 128)    139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 7, 7, 128)    384         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 7, 7, 128)    0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 7, 7, 160)    143360      activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 7, 7, 192)    208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 7, 7, 192)    215040      activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 7, 7, 192)    576         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 7, 7, 192)    576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 7, 7, 192)    0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 7, 7, 192)    0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 7, 7, 384)    0           activation_142[0][0]             \n",
      "                                                                 activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 7, 7, 1088)   418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 7, 7, 1088)   0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 7, 7, 1088)   0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 7, 7, 128)    139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 7, 7, 128)    384         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 7, 7, 128)    0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 7, 7, 160)    143360      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 7, 7, 160)    480         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 7, 7, 160)    0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 7, 7, 192)    208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 7, 7, 192)    215040      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 7, 7, 384)    0           activation_146[0][0]             \n",
      "                                                                 activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 7, 7, 1088)   418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 7, 7, 1088)   0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 7, 7, 1088)   0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 7, 7, 128)    139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 7, 7, 128)    384         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 7, 7, 128)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 7, 7, 160)    143360      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 7, 7, 160)    480         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 7, 7, 160)    0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 7, 7, 192)    208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 7, 7, 192)    215040      activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 7, 7, 384)    0           activation_150[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 7, 7, 1088)   418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 7, 7, 1088)   0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 7, 7, 1088)   0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 7, 7, 128)    139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 7, 7, 128)    384         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 7, 7, 128)    0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 7, 7, 160)    143360      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 7, 7, 160)    480         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 7, 7, 160)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 7, 7, 192)    208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 7, 7, 192)    215040      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 7, 7, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 7, 7, 384)    0           activation_154[0][0]             \n",
      "                                                                 activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 7, 7, 1088)   418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 7, 7, 1088)   0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 7, 7, 1088)   0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 7, 7, 256)    278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 7, 7, 256)    768         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 7, 7, 256)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 7, 7, 256)    278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 7, 7, 256)    278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 7, 7, 288)    663552      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 7, 7, 256)    768         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 7, 7, 256)    768         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 7, 7, 288)    864         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 7, 7, 256)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 7, 7, 256)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 7, 7, 288)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 3, 3, 384)    884736      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 3, 3, 288)    663552      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 3, 3, 320)    829440      activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 3, 3, 384)    1152        conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 3, 3, 288)    864         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 3, 3, 320)    960         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 3, 3, 384)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 3, 3, 288)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 3, 3, 320)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 3, 3, 1088)   0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_7a (Concatenate)          (None, 3, 3, 2080)   0           activation_159[0][0]             \n",
      "                                                                 activation_161[0][0]             \n",
      "                                                                 activation_164[0][0]             \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 3, 3, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 3, 3, 192)    576         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 3, 3, 192)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 3, 3, 224)    129024      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 3, 3, 224)    672         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 3, 3, 224)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 3, 3, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 3, 3, 256)    172032      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 3, 3, 192)    576         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 3, 3, 256)    768         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 3, 3, 192)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 3, 3, 256)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_165[0][0]             \n",
      "                                                                 activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 3, 3, 2080)   0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 3, 3, 2080)   0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 3, 3, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 3, 3, 192)    576         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 3, 3, 192)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 3, 3, 224)    129024      activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 3, 3, 224)    672         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 3, 3, 224)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 3, 3, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 3, 3, 256)    172032      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 3, 3, 192)    576         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 3, 3, 256)    768         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 3, 3, 192)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 3, 3, 256)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_169[0][0]             \n",
      "                                                                 activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 3, 3, 2080)   0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 3, 3, 2080)   0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 3, 3, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 3, 3, 192)    576         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 3, 3, 192)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 3, 3, 224)    129024      activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 3, 3, 224)    672         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 3, 3, 224)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 3, 3, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 3, 3, 256)    172032      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 3, 3, 192)    576         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 3, 3, 256)    768         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 3, 3, 192)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 3, 3, 256)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_173[0][0]             \n",
      "                                                                 activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 3, 3, 2080)   0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 3, 3, 2080)   0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 3, 3, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 3, 3, 192)    576         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 3, 3, 192)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 3, 3, 224)    129024      activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 3, 3, 224)    672         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 3, 3, 224)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 3, 3, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 3, 3, 256)    172032      activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 3, 3, 192)    576         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 3, 3, 256)    768         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 3, 3, 192)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 3, 3, 256)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_177[0][0]             \n",
      "                                                                 activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 3, 3, 2080)   0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 3, 3, 2080)   0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 3, 3, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 3, 3, 192)    576         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 3, 3, 192)    0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 3, 3, 224)    129024      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 3, 3, 224)    672         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 3, 3, 224)    0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 3, 3, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 3, 3, 256)    172032      activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 3, 3, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 3, 3, 256)    768         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 3, 3, 192)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 3, 3, 256)    0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_181[0][0]             \n",
      "                                                                 activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 3, 3, 2080)   0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 3, 3, 2080)   0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 3, 3, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 3, 3, 192)    576         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 3, 3, 192)    0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 3, 3, 224)    129024      activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 3, 3, 224)    672         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 3, 3, 224)    0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 3, 3, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 3, 3, 256)    172032      activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 3, 3, 192)    576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 3, 3, 256)    768         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 3, 3, 192)    0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 3, 3, 256)    0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_185[0][0]             \n",
      "                                                                 activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 3, 3, 2080)   0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 3, 3, 2080)   0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 3, 3, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 3, 3, 192)    576         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 3, 3, 192)    0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 3, 3, 224)    129024      activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 3, 3, 224)    672         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 3, 3, 224)    0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 3, 3, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 3, 3, 256)    172032      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_196 (BatchN (None, 3, 3, 192)    576         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 3, 3, 256)    768         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 3, 3, 192)    0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 3, 3, 256)    0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_189[0][0]             \n",
      "                                                                 activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 3, 3, 2080)   0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 3, 3, 2080)   0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 3, 3, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 3, 3, 192)    576         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 3, 3, 192)    0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 3, 3, 224)    129024      activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 3, 3, 224)    672         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 3, 3, 224)    0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 3, 3, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 3, 3, 256)    172032      activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 3, 3, 192)    576         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 3, 3, 256)    768         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 3, 3, 192)    0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 3, 3, 256)    0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_193[0][0]             \n",
      "                                                                 activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 3, 3, 2080)   0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 3, 3, 2080)   0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 3, 3, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 3, 3, 192)    576         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 3, 3, 192)    0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 3, 3, 224)    129024      activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 3, 3, 224)    672         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 3, 3, 224)    0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 3, 3, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 3, 3, 256)    172032      activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 3, 3, 192)    576         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 3, 3, 256)    768         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 3, 3, 192)    0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 3, 3, 256)    0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, 3, 3, 448)    0           activation_197[0][0]             \n",
      "                                                                 activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, 3, 3, 2080)   933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, 3, 3, 2080)   0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, 3, 3, 2080)   0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 3, 3, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 3, 3, 192)    576         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 3, 3, 192)    0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 3, 3, 224)    129024      activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 3, 3, 224)    672         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 3, 3, 224)    0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 3, 3, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 3, 3, 256)    172032      activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 3, 3, 192)    576         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 3, 3, 256)    768         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 3, 3, 192)    0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 3, 3, 256)    0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, 3, 3, 448)    0           activation_201[0][0]             \n",
      "                                                                 activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, 3, 3, 2080)   933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, 3, 3, 2080)   0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b (Conv2D)                (None, 3, 3, 1536)   3194880     block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_bn (BatchNormalization) (None, 3, 3, 1536)   4608        conv_7b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_ac (Activation)         (None, 3, 3, 1536)   0           conv_7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1536)         0           conv_7b_ac[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            1537        avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 1)            0           dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 54,338,273\n",
      "Trainable params: 54,277,729\n",
      "Non-trainable params: 60,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the pretraining InceptionV2 model, pop out the last dense layer\n",
    "base_model3 = InceptionResNetV2(input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "x_model3 = Dense(1)(base_model3.get_layer('avg_pool').output)\n",
    "y_model3 = Activation('sigmoid')(x_model3)\n",
    "model3 = Model(inputs = base_model3.input, outputs = y_model3)\n",
    "\n",
    "# Optimizer, loss and metrics\n",
    "model3.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Show model summary\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 : InceptionResNetV2 pretraining model (freezing weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model model used <b>InceptionResNetV2 model as a base layer</b>, but we ignore the original top layers of it and pass the output from 'avg_pool' layer to our Dense layer with sigmoid as activation function.\n",
    "\n",
    "In this model, we also <b>freezed the weight of InceptionResNetV2</b> base layers.\n",
    "\n",
    "We use rmsprop optimizer and standard binary_crossentropy loss-function and accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_resnet_v2 (Model)  (None, 3, 3, 1536)        54336736  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               3539200   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 57,876,193\n",
      "Trainable params: 3,539,457\n",
      "Non-trainable params: 54,336,736\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the pretraining InceptionV2 model, pop out the last dense layer\n",
    "base_model4 = InceptionResNetV2(include_top=False,\n",
    "                  input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "# Freeze weight of InceptionResNetV2 layers (untrainable)\n",
    "base_model4.trainable = False\n",
    "\n",
    "# Add our Dense layers for classificaton\n",
    "model4 = models.Sequential()\n",
    "model4.add(base_model4)\n",
    "model4.add(layers.Flatten())\n",
    "model4.add(layers.Dense(256, activation='relu'))\n",
    "model4.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Optimizer, loss and metrics\n",
    "model4.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Show model summary\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5 : 4 convolutional layers model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is is sequential architecture that created by <b>4 convolutional layers</b> using 'relu' as activation function and size of filter as 3x3. They were added alternately with Maxpooling layer. Then I added flatten layer to transform matrixs into vector and added one dropout to avoid overfitting in this state. After that, I added more fully-connection layer with 256 neurons and the last layer with 'sigmoid' activation function to classify the class from given data.\n",
    "\n",
    "We use rmsprop optimizer and standard binary_crossentropy loss-function and accuracy metrics.\n",
    "\n",
    "This model has minimum trainable parameters (only 896,577 parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_415 (Conv2D)          (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_416 (Conv2D)          (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_417 (Conv2D)          (None, 34, 34, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_418 (Conv2D)          (None, 15, 15, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 896,577\n",
      "Trainable params: 896,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create our model by using 4 Convolutional layers\n",
    "model5 = models.Sequential()\n",
    "model5.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
    "model5.add(layers.MaxPooling2D((2,2)))\n",
    "model5.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model5.add(layers.MaxPooling2D((2,2)))\n",
    "model5.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model5.add(layers.MaxPooling2D((2,2)))\n",
    "model5.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model5.add(layers.MaxPooling2D((2,2)))\n",
    "model5.add(layers.Flatten())\n",
    "model5.add(layers.Dropout(0.2))\n",
    "model5.add(layers.Dense(256, activation='relu'))\n",
    "model5.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Optimizer, loss and metrics\n",
    "model5.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Show model summary\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I defined paths for each model and history after training with 100 epochs and paths for model that has minimum validation loss value while training. I used 'ModelCheckpoint' function for saving my best model (minimum validation loss).\n",
    "\n",
    "<b>I trained every models with 100 epochs and batch size of 16. And I used 'fit_generator' for feeding data from generator that I define above to models</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model path after traning 100 epochs\n",
    "last_weight_model1=\"100_xcep.hdf5\"\n",
    "last_weight_model2=\"100_xcep_freeze.hdf5\"\n",
    "last_weight_model3=\"100_inceptionV2.hdf5\"\n",
    "last_weight_model4=\"100_inceptionV2_freeze.hdf5\"\n",
    "last_weight_model5=\"100_4conv.hdf5\"\n",
    "\n",
    "# History path after traning 100 epochs\n",
    "last_his_model1=\"100_xcep_his\"\n",
    "last_his_model2=\"100_xcep_freeze_his\"\n",
    "last_his_model3=\"100_inceptionV2_his\"\n",
    "last_his_model4=\"100_inceptionV2_freeze_his\"\n",
    "last_his_model5=\"100_4conv_his\"\n",
    "\n",
    "# Model path for the epoch the has minimum val_loss\n",
    "best_weight_model1=\"best_xcep.hdf5\"\n",
    "best_weight_model2=\"best_xcep_freeze.hdf5\"\n",
    "best_weight_model3=\"best_inceptionV2.hdf5\"\n",
    "best_weight_model4=\"best_inceptionV2_freeze.hdf5\"\n",
    "best_weight_model5=\"best_4conv.hdf5\"\n",
    "\n",
    "# Create model checkpoint when it has minimum val_loss\n",
    "checkpoint1 = ModelCheckpoint(best_weight_model1, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min')\n",
    "checkpoint2 = ModelCheckpoint(best_weight_model2, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min')\n",
    "checkpoint3 = ModelCheckpoint(best_weight_model3, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min')\n",
    "checkpoint4 = ModelCheckpoint(best_weight_model4, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min')\n",
    "checkpoint5 = ModelCheckpoint(best_weight_model5, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min')\n",
    "\n",
    "# Create callback list for model fitting\n",
    "cb1 = [checkpoint1]\n",
    "cb2 = [checkpoint2]\n",
    "cb3 = [checkpoint3]\n",
    "cb4 = [checkpoint4]\n",
    "cb5 = [checkpoint5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model 1 (Xception pretraining model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model1 Xception ...\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 241s 858ms/step - loss: 0.6964 - acc: 0.5060 - val_loss: 0.9348 - val_acc: 0.4946\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.93480, saving model to best_xcep.hdf5\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 233s 831ms/step - loss: 0.6934 - acc: 0.4991 - val_loss: 0.6938 - val_acc: 0.5040\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.93480 to 0.69376, saving model to best_xcep.hdf5\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.6934 - acc: 0.5053 - val_loss: 1.0886 - val_acc: 0.4852\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.69376\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.6930 - acc: 0.4922 - val_loss: 0.7380 - val_acc: 0.4892\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.69376\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.6933 - acc: 0.5073 - val_loss: 0.6946 - val_acc: 0.4960\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.69376\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.6929 - acc: 0.5038 - val_loss: 0.6931 - val_acc: 0.5007\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.69376 to 0.69312, saving model to best_xcep.hdf5\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.6919 - acc: 0.5194 - val_loss: 0.7140 - val_acc: 0.5121\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.69312\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 232s 825ms/step - loss: 0.6894 - acc: 0.5445 - val_loss: 0.6955 - val_acc: 0.5357\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.69312\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 232s 826ms/step - loss: 0.6775 - acc: 0.5758 - val_loss: 0.6879 - val_acc: 0.5404\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.69312 to 0.68791, saving model to best_xcep.hdf5\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 232s 825ms/step - loss: 0.6613 - acc: 0.6119 - val_loss: 0.8859 - val_acc: 0.6388\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.68791\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 232s 825ms/step - loss: 0.6542 - acc: 0.6197 - val_loss: 0.6979 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.68791\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 232s 824ms/step - loss: 0.6299 - acc: 0.6512 - val_loss: 0.6964 - val_acc: 0.6220\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.68791\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 232s 826ms/step - loss: 0.6268 - acc: 0.6544 - val_loss: 0.6611 - val_acc: 0.6233\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.68791 to 0.66113, saving model to best_xcep.hdf5\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 232s 824ms/step - loss: 0.6200 - acc: 0.6561 - val_loss: 0.6120 - val_acc: 0.6536\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.66113 to 0.61195, saving model to best_xcep.hdf5\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.6165 - acc: 0.6653 - val_loss: 0.6089 - val_acc: 0.6624\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.61195 to 0.60891, saving model to best_xcep.hdf5\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.6020 - acc: 0.6673 - val_loss: 0.6313 - val_acc: 0.6354\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.60891\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.6147 - acc: 0.6570 - val_loss: 0.6587 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.60891\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.6001 - acc: 0.6813 - val_loss: 0.6602 - val_acc: 0.6509\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.60891\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.6002 - acc: 0.6784 - val_loss: 0.6554 - val_acc: 0.6826\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.60891\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5994 - acc: 0.6704 - val_loss: 0.5972 - val_acc: 0.6739\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.60891 to 0.59719, saving model to best_xcep.hdf5\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5921 - acc: 0.6893 - val_loss: 0.6951 - val_acc: 0.6408\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.59719\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5847 - acc: 0.6899 - val_loss: 0.6113 - val_acc: 0.6523\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.59719\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5836 - acc: 0.6884 - val_loss: 0.7170 - val_acc: 0.6024\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.59719\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5834 - acc: 0.6884 - val_loss: 0.6026 - val_acc: 0.6752\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.59719\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5830 - acc: 0.6960 - val_loss: 0.5841 - val_acc: 0.6860\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.59719 to 0.58415, saving model to best_xcep.hdf5\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5773 - acc: 0.6984 - val_loss: 0.7662 - val_acc: 0.6375\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.58415\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5728 - acc: 0.6955 - val_loss: 0.6220 - val_acc: 0.6664\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.58415\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5693 - acc: 0.7064 - val_loss: 0.6724 - val_acc: 0.6408\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.58415\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5724 - acc: 0.7022 - val_loss: 0.5963 - val_acc: 0.6637\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.58415\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5756 - acc: 0.6944 - val_loss: 0.5702 - val_acc: 0.6988\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.58415 to 0.57017, saving model to best_xcep.hdf5\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5694 - acc: 0.7020 - val_loss: 0.6312 - val_acc: 0.6718\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.57017\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5564 - acc: 0.7149 - val_loss: 0.6760 - val_acc: 0.5836\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.57017\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5611 - acc: 0.7102 - val_loss: 0.8027 - val_acc: 0.6482\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.57017\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5605 - acc: 0.7055 - val_loss: 0.6613 - val_acc: 0.6644\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.57017\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5528 - acc: 0.7226 - val_loss: 0.6457 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.57017\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5498 - acc: 0.7171 - val_loss: 0.8601 - val_acc: 0.6233\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.57017\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5504 - acc: 0.7129 - val_loss: 0.6589 - val_acc: 0.6759\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.57017\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5454 - acc: 0.7146 - val_loss: 0.5785 - val_acc: 0.6920\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.57017\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.5462 - acc: 0.7155 - val_loss: 0.6487 - val_acc: 0.6779\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.57017\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.5477 - acc: 0.7115 - val_loss: 0.5814 - val_acc: 0.6947\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.57017\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5401 - acc: 0.7175 - val_loss: 0.6142 - val_acc: 0.6894\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.57017\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5392 - acc: 0.7204 - val_loss: 0.6728 - val_acc: 0.6503\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.57017\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5393 - acc: 0.7184 - val_loss: 0.5732 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.57017\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5376 - acc: 0.7231 - val_loss: 0.5732 - val_acc: 0.7069\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.57017\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5353 - acc: 0.7287 - val_loss: 0.7193 - val_acc: 0.6220\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.57017\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5292 - acc: 0.7291 - val_loss: 0.5759 - val_acc: 0.6840\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.57017\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5357 - acc: 0.7235 - val_loss: 0.8088 - val_acc: 0.6018\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.57017\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5335 - acc: 0.7320 - val_loss: 0.6895 - val_acc: 0.6435\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.57017\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5308 - acc: 0.7293 - val_loss: 0.6242 - val_acc: 0.6792\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.57017\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5273 - acc: 0.7353 - val_loss: 0.5678 - val_acc: 0.7197\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.57017 to 0.56782, saving model to best_xcep.hdf5\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5278 - acc: 0.7300 - val_loss: 0.6339 - val_acc: 0.6894\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.56782\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5154 - acc: 0.7438 - val_loss: 0.8715 - val_acc: 0.6611\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.56782\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5287 - acc: 0.7284 - val_loss: 0.5924 - val_acc: 0.7015\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.56782\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5090 - acc: 0.7491 - val_loss: 0.5780 - val_acc: 0.7001\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.56782\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5148 - acc: 0.7384 - val_loss: 0.6424 - val_acc: 0.6098\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.56782\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5087 - acc: 0.7467 - val_loss: 0.5973 - val_acc: 0.7042\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.56782\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5150 - acc: 0.7438 - val_loss: 0.5897 - val_acc: 0.6772\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.56782\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5157 - acc: 0.7418 - val_loss: 0.6267 - val_acc: 0.6321\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.56782\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5096 - acc: 0.7433 - val_loss: 0.6317 - val_acc: 0.6395\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.56782\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5058 - acc: 0.7476 - val_loss: 0.5421 - val_acc: 0.7426\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.56782 to 0.54207, saving model to best_xcep.hdf5\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5084 - acc: 0.7453 - val_loss: 0.5987 - val_acc: 0.7305\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.54207\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5085 - acc: 0.7440 - val_loss: 0.5867 - val_acc: 0.7123\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.54207\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5140 - acc: 0.7433 - val_loss: 0.6661 - val_acc: 0.6941\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.54207\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4903 - acc: 0.7631 - val_loss: 0.6046 - val_acc: 0.6570\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.54207\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5112 - acc: 0.7453 - val_loss: 0.7644 - val_acc: 0.6590\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.54207\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4956 - acc: 0.7498 - val_loss: 0.5616 - val_acc: 0.7210\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.54207\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4958 - acc: 0.7542 - val_loss: 0.7395 - val_acc: 0.5997\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.54207\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4908 - acc: 0.7618 - val_loss: 0.5867 - val_acc: 0.7197\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.54207\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5009 - acc: 0.7529 - val_loss: 0.5836 - val_acc: 0.7204\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.54207\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.5040 - acc: 0.7473 - val_loss: 0.5509 - val_acc: 0.7197\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.54207\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4820 - acc: 0.7587 - val_loss: 0.5452 - val_acc: 0.7352\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.54207\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4937 - acc: 0.7576 - val_loss: 0.5454 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.54207\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4801 - acc: 0.7625 - val_loss: 0.6127 - val_acc: 0.7183\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.54207\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4922 - acc: 0.7627 - val_loss: 0.6723 - val_acc: 0.6691\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.54207\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4929 - acc: 0.7551 - val_loss: 0.5509 - val_acc: 0.7338\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.54207\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4782 - acc: 0.7616 - val_loss: 0.8064 - val_acc: 0.6301\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.54207\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4907 - acc: 0.7591 - val_loss: 1.0407 - val_acc: 0.6590\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.54207\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4859 - acc: 0.7636 - val_loss: 0.6240 - val_acc: 0.7075\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.54207\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4929 - acc: 0.7538 - val_loss: 0.5695 - val_acc: 0.7190\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.54207\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4784 - acc: 0.7631 - val_loss: 0.5853 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.54207\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4864 - acc: 0.7625 - val_loss: 0.6799 - val_acc: 0.6435\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.54207\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4834 - acc: 0.7609 - val_loss: 0.6136 - val_acc: 0.7069\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.54207\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4724 - acc: 0.7742 - val_loss: 0.5802 - val_acc: 0.7264\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.54207\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4683 - acc: 0.7762 - val_loss: 0.6048 - val_acc: 0.6920\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.54207\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 231s 822ms/step - loss: 0.4778 - acc: 0.7658 - val_loss: 0.6810 - val_acc: 0.6739\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.54207\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.4878 - acc: 0.7640 - val_loss: 1.0688 - val_acc: 0.5377\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.54207\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.4655 - acc: 0.7765 - val_loss: 0.8091 - val_acc: 0.6280\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.54207\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.4693 - acc: 0.7765 - val_loss: 0.6057 - val_acc: 0.7156\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.54207\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.4599 - acc: 0.7760 - val_loss: 0.5413 - val_acc: 0.7311\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.54207 to 0.54127, saving model to best_xcep.hdf5\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4632 - acc: 0.7769 - val_loss: 0.6957 - val_acc: 0.6739\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.54127\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4609 - acc: 0.7765 - val_loss: 0.6326 - val_acc: 0.6995\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.54127\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4668 - acc: 0.7716 - val_loss: 0.6171 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.54127\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4615 - acc: 0.7754 - val_loss: 0.5839 - val_acc: 0.7204\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.54127\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.4522 - acc: 0.7807 - val_loss: 0.6307 - val_acc: 0.7015\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.54127\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.4612 - acc: 0.7823 - val_loss: 0.6333 - val_acc: 0.6915\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.54127\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4631 - acc: 0.7762 - val_loss: 0.6842 - val_acc: 0.6934\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.54127\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4550 - acc: 0.7845 - val_loss: 0.8314 - val_acc: 0.6590\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.54127\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4490 - acc: 0.7867 - val_loss: 0.8746 - val_acc: 0.6671\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.54127\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.4516 - acc: 0.7885 - val_loss: 0.7747 - val_acc: 0.6570\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.54127\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.4511 - acc: 0.7849 - val_loss: 0.6324 - val_acc: 0.6995\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.54127\n",
      "Done. Elapsed time 23166 seconds for 100 epochs, average 231.7 seconds/epoch.\n"
     ]
    }
   ],
   "source": [
    "# Start timing\n",
    "start = time.time()\n",
    "\n",
    "# Training\n",
    "print('Training the model1 Xception ...')\n",
    "history1 = model1.fit_generator(\n",
    "    generator = train_flow,\n",
    "    steps_per_epoch = TRAIN_STEPS,\n",
    "    epochs = N_EPOCHS + EPOCHS,\n",
    "    initial_epoch = N_EPOCHS,\n",
    "    verbose = 1,\n",
    "    callbacks = cb1,\n",
    "    validation_data = valid_flow,\n",
    "    validation_steps = VALID_STEPS)\n",
    "stop = time.time()\n",
    "etime = stop - start\n",
    "print('Done. Elapsed time {:.0f} seconds for {:} epochs, average {:.1f} seconds/epoch.'.format(etime, EPOCHS, etime/EPOCHS))\n",
    "\n",
    "# Save last model\n",
    "model1.save(last_weight_model1)\n",
    "\n",
    "# Save the history\n",
    "with open(last_his_model1, 'wb') as file_pi:\n",
    "    pickle.dump(history1.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This training model 1 used total time 23,166 seconds for 100 epochs and average time 231.7 seconds/epoch. We ended up with <b>89th as the best epoch</b>.\n",
    "\n",
    "Then, I plotted accuracy and loss value for each epoch into line graph as you can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure()\n",
    "plt.plot(history1.history['acc'])\n",
    "plt.plot(history1.history['val_acc'])\n",
    "plt.title('Model1 Xception accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure()\n",
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.title('Model1 Xception loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 3])\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from above accuracy and loss graph, accuracy and loss of traning-set increse and decrese respectively quite smooth. On the other hand, even accuracy and loss of the validation-set are fructuate but they seem to increse and decrese respectively so I decided to try to <b>train this model further another 100 epochs</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Go further with Model 1 (Xception pretraining model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set next epoch starting\n",
    "N_EPOCHS = 100\n",
    "\n",
    "# Model path after traning 200 epochs\n",
    "fur_weight_model1=\"200_xcep.hdf5\"\n",
    "\n",
    "# History path after traning 200 epochs\n",
    "fur_his_model1=\"200_xcep_his\"\n",
    "\n",
    "# Model path for the epoch the has minimum val_loss\n",
    "best_weight_model1_fur=\"best_xcep_fur.hdf5\"\n",
    "\n",
    "# Create model checkpoint when it has minimum val_loss\n",
    "checkpointf1 = ModelCheckpoint(best_weight_model1_fur, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min')\n",
    "cbf1 = [checkpointf1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training further the model1 Xception ...\n",
      "Epoch 101/200\n",
      "281/281 [==============================] - 242s 860ms/step - loss: 0.4522 - acc: 0.7838 - val_loss: 0.6373 - val_acc: 0.7003\n",
      "\n",
      "Epoch 00101: val_loss improved from inf to 0.63731, saving model to best_xcep_fur.hdf5\n",
      "Epoch 102/200\n",
      "281/281 [==============================] - 236s 841ms/step - loss: 0.4597 - acc: 0.7754 - val_loss: 0.6687 - val_acc: 0.6584\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.63731\n",
      "Epoch 103/200\n",
      "281/281 [==============================] - 234s 832ms/step - loss: 0.4473 - acc: 0.7863 - val_loss: 0.7218 - val_acc: 0.6152\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.63731\n",
      "Epoch 104/200\n",
      "281/281 [==============================] - 234s 831ms/step - loss: 0.4484 - acc: 0.7818 - val_loss: 0.6169 - val_acc: 0.7035\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.63731 to 0.61692, saving model to best_xcep_fur.hdf5\n",
      "Epoch 105/200\n",
      "281/281 [==============================] - 233s 831ms/step - loss: 0.4510 - acc: 0.7829 - val_loss: 0.7225 - val_acc: 0.7156\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.61692\n",
      "Epoch 106/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.4406 - acc: 0.7900 - val_loss: 0.5993 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.61692 to 0.59928, saving model to best_xcep_fur.hdf5\n",
      "Epoch 107/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.4455 - acc: 0.7896 - val_loss: 0.7046 - val_acc: 0.6826\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.59928\n",
      "Epoch 108/200\n",
      "281/281 [==============================] - 234s 832ms/step - loss: 0.4445 - acc: 0.7929 - val_loss: 1.5642 - val_acc: 0.6449\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.59928\n",
      "Epoch 109/200\n",
      "281/281 [==============================] - 234s 833ms/step - loss: 0.4399 - acc: 0.7896 - val_loss: 0.6159 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.59928\n",
      "Epoch 110/200\n",
      "281/281 [==============================] - 234s 831ms/step - loss: 0.4457 - acc: 0.7885 - val_loss: 0.8407 - val_acc: 0.6287\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.59928\n",
      "Epoch 111/200\n",
      "281/281 [==============================] - 233s 831ms/step - loss: 0.4369 - acc: 0.7985 - val_loss: 1.0590 - val_acc: 0.6132\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.59928\n",
      "Epoch 112/200\n",
      "281/281 [==============================] - 234s 832ms/step - loss: 0.4417 - acc: 0.7878 - val_loss: 0.7770 - val_acc: 0.7210\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.59928\n",
      "Epoch 113/200\n",
      "281/281 [==============================] - 234s 831ms/step - loss: 0.4309 - acc: 0.7952 - val_loss: 0.9674 - val_acc: 0.6354\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.59928\n",
      "Epoch 114/200\n",
      "281/281 [==============================] - 234s 831ms/step - loss: 0.4377 - acc: 0.7914 - val_loss: 0.7930 - val_acc: 0.6988\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.59928\n",
      "Epoch 115/200\n",
      "281/281 [==============================] - 233s 831ms/step - loss: 0.4356 - acc: 0.7911 - val_loss: 0.5952 - val_acc: 0.7204\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.59928 to 0.59522, saving model to best_xcep_fur.hdf5\n",
      "Epoch 116/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.4323 - acc: 0.8032 - val_loss: 0.6871 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.59522\n",
      "Epoch 117/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.4306 - acc: 0.7974 - val_loss: 0.7267 - val_acc: 0.7224\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.59522\n",
      "Epoch 118/200\n",
      "281/281 [==============================] - 234s 831ms/step - loss: 0.4273 - acc: 0.7967 - val_loss: 0.7630 - val_acc: 0.6739\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.59522\n",
      "Epoch 119/200\n",
      "281/281 [==============================] - 234s 831ms/step - loss: 0.4302 - acc: 0.7923 - val_loss: 0.7664 - val_acc: 0.6853\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.59522\n",
      "Epoch 120/200\n",
      "281/281 [==============================] - 234s 832ms/step - loss: 0.4255 - acc: 0.8043 - val_loss: 1.1149 - val_acc: 0.6314\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.59522\n",
      "Epoch 121/200\n",
      "281/281 [==============================] - 233s 831ms/step - loss: 0.4144 - acc: 0.8089 - val_loss: 1.0196 - val_acc: 0.6894\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.59522\n",
      "Epoch 122/200\n",
      "281/281 [==============================] - 234s 834ms/step - loss: 0.4263 - acc: 0.8052 - val_loss: 0.9577 - val_acc: 0.5937\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.59522\n",
      "Epoch 123/200\n",
      "281/281 [==============================] - 234s 832ms/step - loss: 0.4203 - acc: 0.8058 - val_loss: 0.7412 - val_acc: 0.7035\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.59522\n",
      "Epoch 124/200\n",
      "281/281 [==============================] - 234s 831ms/step - loss: 0.4187 - acc: 0.8063 - val_loss: 0.5873 - val_acc: 0.7311\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.59522 to 0.58728, saving model to best_xcep_fur.hdf5\n",
      "Epoch 125/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.4079 - acc: 0.8074 - val_loss: 0.8469 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.58728\n",
      "Epoch 126/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.4140 - acc: 0.8052 - val_loss: 0.7366 - val_acc: 0.6974\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.58728\n",
      "Epoch 127/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.4145 - acc: 0.8049 - val_loss: 0.7271 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.58728\n",
      "Epoch 128/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.4129 - acc: 0.8038 - val_loss: 1.1451 - val_acc: 0.5943\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.58728\n",
      "Epoch 129/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.4198 - acc: 0.8036 - val_loss: 0.6713 - val_acc: 0.7035\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.58728\n",
      "Epoch 130/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.4189 - acc: 0.8076 - val_loss: 0.6828 - val_acc: 0.6745\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.58728\n",
      "Epoch 131/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.4108 - acc: 0.8098 - val_loss: 0.9229 - val_acc: 0.5964\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.58728\n",
      "Epoch 132/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.4051 - acc: 0.8134 - val_loss: 0.7563 - val_acc: 0.6631\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.58728\n",
      "Epoch 133/200\n",
      "281/281 [==============================] - 233s 831ms/step - loss: 0.4104 - acc: 0.8065 - val_loss: 0.8262 - val_acc: 0.7042\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.58728\n",
      "Epoch 134/200\n",
      "281/281 [==============================] - 234s 832ms/step - loss: 0.4025 - acc: 0.8141 - val_loss: 0.6988 - val_acc: 0.6853\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.58728\n",
      "Epoch 135/200\n",
      "281/281 [==============================] - 234s 831ms/step - loss: 0.3965 - acc: 0.8205 - val_loss: 1.4689 - val_acc: 0.6004\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.58728\n",
      "Epoch 136/200\n",
      "281/281 [==============================] - 234s 831ms/step - loss: 0.3995 - acc: 0.8145 - val_loss: 0.8096 - val_acc: 0.7210\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.58728\n",
      "Epoch 137/200\n",
      "281/281 [==============================] - 234s 832ms/step - loss: 0.4051 - acc: 0.8094 - val_loss: 1.0086 - val_acc: 0.6152\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.58728\n",
      "Epoch 138/200\n",
      "281/281 [==============================] - 234s 831ms/step - loss: 0.4017 - acc: 0.8132 - val_loss: 0.8842 - val_acc: 0.6637\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.58728\n",
      "Epoch 139/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.3964 - acc: 0.8203 - val_loss: 0.8618 - val_acc: 0.6739\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.58728\n",
      "Epoch 140/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.4047 - acc: 0.8210 - val_loss: 0.6379 - val_acc: 0.7183\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.58728\n",
      "Epoch 141/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.4045 - acc: 0.8060 - val_loss: 0.6872 - val_acc: 0.7116\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.58728\n",
      "Epoch 142/200\n",
      "281/281 [==============================] - 233s 831ms/step - loss: 0.3975 - acc: 0.8152 - val_loss: 1.1299 - val_acc: 0.6509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00142: val_loss did not improve from 0.58728\n",
      "Epoch 143/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.3985 - acc: 0.8167 - val_loss: 0.8166 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.58728\n",
      "Epoch 144/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.4151 - acc: 0.8201 - val_loss: 1.0781 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.58728\n",
      "Epoch 145/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.3858 - acc: 0.8241 - val_loss: 0.7312 - val_acc: 0.7204\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.58728\n",
      "Epoch 146/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.3887 - acc: 0.8261 - val_loss: 0.8767 - val_acc: 0.6934\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.58728\n",
      "Epoch 147/200\n",
      "281/281 [==============================] - 233s 831ms/step - loss: 0.3849 - acc: 0.8178 - val_loss: 1.6613 - val_acc: 0.6584\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.58728\n",
      "Epoch 148/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.3920 - acc: 0.8261 - val_loss: 0.6876 - val_acc: 0.6974\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.58728\n",
      "Epoch 149/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.3896 - acc: 0.8225 - val_loss: 0.8714 - val_acc: 0.6637\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.58728\n",
      "Epoch 150/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.3940 - acc: 0.8158 - val_loss: 1.4442 - val_acc: 0.6301\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.58728\n",
      "Epoch 151/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.3857 - acc: 0.8212 - val_loss: 0.9845 - val_acc: 0.7156\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.58728\n",
      "Epoch 152/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3762 - acc: 0.8243 - val_loss: 1.0088 - val_acc: 0.6981\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.58728\n",
      "Epoch 153/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3832 - acc: 0.8270 - val_loss: 0.7356 - val_acc: 0.7042\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.58728\n",
      "Epoch 154/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3630 - acc: 0.8350 - val_loss: 1.1504 - val_acc: 0.6819\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.58728\n",
      "Epoch 155/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.3797 - acc: 0.8341 - val_loss: 0.7281 - val_acc: 0.7183\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.58728\n",
      "Epoch 156/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3653 - acc: 0.8310 - val_loss: 1.0825 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.58728\n",
      "Epoch 157/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.3711 - acc: 0.8336 - val_loss: 1.0411 - val_acc: 0.7082\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.58728\n",
      "Epoch 158/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3675 - acc: 0.8270 - val_loss: 0.6632 - val_acc: 0.7008\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.58728\n",
      "Epoch 159/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3739 - acc: 0.8287 - val_loss: 0.7300 - val_acc: 0.7150\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.58728\n",
      "Epoch 160/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.3741 - acc: 0.8325 - val_loss: 0.7302 - val_acc: 0.7183\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.58728\n",
      "Epoch 161/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3678 - acc: 0.8330 - val_loss: 0.8675 - val_acc: 0.6826\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.58728\n",
      "Epoch 162/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3796 - acc: 0.8274 - val_loss: 0.7135 - val_acc: 0.7075\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.58728\n",
      "Epoch 163/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.3758 - acc: 0.8307 - val_loss: 1.1554 - val_acc: 0.6388\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.58728\n",
      "Epoch 164/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3543 - acc: 0.8441 - val_loss: 1.2977 - val_acc: 0.5539\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.58728\n",
      "Epoch 165/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3693 - acc: 0.8390 - val_loss: 1.0086 - val_acc: 0.6678\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.58728\n",
      "Epoch 166/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3511 - acc: 0.8463 - val_loss: 0.9141 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.58728\n",
      "Epoch 167/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3560 - acc: 0.8445 - val_loss: 1.0245 - val_acc: 0.7035\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.58728\n",
      "Epoch 168/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3505 - acc: 0.8439 - val_loss: 0.7583 - val_acc: 0.7197\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.58728\n",
      "Epoch 169/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.3639 - acc: 0.8416 - val_loss: 0.7684 - val_acc: 0.6833\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.58728\n",
      "Epoch 170/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3566 - acc: 0.8403 - val_loss: 0.9575 - val_acc: 0.6725\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.58728\n",
      "Epoch 171/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3413 - acc: 0.8465 - val_loss: 0.7776 - val_acc: 0.6961\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.58728\n",
      "Epoch 172/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3525 - acc: 0.8427 - val_loss: 0.7540 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.58728\n",
      "Epoch 173/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3369 - acc: 0.8537 - val_loss: 0.7737 - val_acc: 0.6920\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.58728\n",
      "Epoch 174/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3572 - acc: 0.8423 - val_loss: 0.8242 - val_acc: 0.6934\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.58728\n",
      "Epoch 175/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3463 - acc: 0.8450 - val_loss: 0.8590 - val_acc: 0.7075\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.58728\n",
      "Epoch 176/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3331 - acc: 0.8485 - val_loss: 1.2102 - val_acc: 0.6476\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.58728\n",
      "Epoch 177/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3545 - acc: 0.8436 - val_loss: 0.8906 - val_acc: 0.7136\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.58728\n",
      "Epoch 178/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.3461 - acc: 0.8405 - val_loss: 0.9501 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.58728\n",
      "Epoch 179/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3509 - acc: 0.8414 - val_loss: 1.6196 - val_acc: 0.6381\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.58728\n",
      "Epoch 180/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.3511 - acc: 0.8499 - val_loss: 0.8419 - val_acc: 0.7230\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.58728\n",
      "Epoch 181/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3355 - acc: 0.8548 - val_loss: 0.9157 - val_acc: 0.6637\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.58728\n",
      "Epoch 182/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3363 - acc: 0.8510 - val_loss: 0.8908 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.58728\n",
      "Epoch 183/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3375 - acc: 0.8521 - val_loss: 0.8485 - val_acc: 0.7190\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.58728\n",
      "Epoch 184/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3305 - acc: 0.8532 - val_loss: 0.8001 - val_acc: 0.7042\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.58728\n",
      "Epoch 185/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3298 - acc: 0.8537 - val_loss: 0.8066 - val_acc: 0.7109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00185: val_loss did not improve from 0.58728\n",
      "Epoch 186/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.3309 - acc: 0.8565 - val_loss: 0.9324 - val_acc: 0.6644\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.58728\n",
      "Epoch 187/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3196 - acc: 0.8612 - val_loss: 1.0088 - val_acc: 0.6590\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.58728\n",
      "Epoch 188/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3198 - acc: 0.8601 - val_loss: 0.7756 - val_acc: 0.6934\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.58728\n",
      "Epoch 189/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3176 - acc: 0.8652 - val_loss: 0.9584 - val_acc: 0.6590\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.58728\n",
      "Epoch 190/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3172 - acc: 0.8663 - val_loss: 1.4198 - val_acc: 0.6914\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.58728\n",
      "Epoch 191/200\n",
      "281/281 [==============================] - 233s 828ms/step - loss: 0.2971 - acc: 0.8730 - val_loss: 1.1575 - val_acc: 0.7156\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.58728\n",
      "Epoch 192/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3346 - acc: 0.8492 - val_loss: 0.7607 - val_acc: 0.6961\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.58728\n",
      "Epoch 193/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3261 - acc: 0.8617 - val_loss: 1.1979 - val_acc: 0.6988\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.58728\n",
      "Epoch 194/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3271 - acc: 0.8599 - val_loss: 0.8803 - val_acc: 0.6705\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.58728\n",
      "Epoch 195/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3228 - acc: 0.8614 - val_loss: 1.1639 - val_acc: 0.6902\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.58728\n",
      "Epoch 196/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3231 - acc: 0.8588 - val_loss: 1.0958 - val_acc: 0.6759\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.58728\n",
      "Epoch 197/200\n",
      "281/281 [==============================] - 233s 830ms/step - loss: 0.3139 - acc: 0.8681 - val_loss: 0.8723 - val_acc: 0.6920\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.58728\n",
      "Epoch 198/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3116 - acc: 0.8632 - val_loss: 0.9774 - val_acc: 0.6961\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.58728\n",
      "Epoch 199/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3013 - acc: 0.8730 - val_loss: 1.2872 - val_acc: 0.6732\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.58728\n",
      "Epoch 200/200\n",
      "281/281 [==============================] - 233s 829ms/step - loss: 0.3054 - acc: 0.8694 - val_loss: 0.9344 - val_acc: 0.6974\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.58728\n",
      "Done. Elapsed time 23350 seconds for 100 epochs, average 233.5 seconds/epoch.\n"
     ]
    }
   ],
   "source": [
    "# Load architecture and weight from the last 100 epochs training\n",
    "model1 = load_model(last_weight_model1)\n",
    "\n",
    "# Start timing\n",
    "start = time.time()\n",
    "\n",
    "# Training\n",
    "print('Training further the model1 Xception ...')\n",
    "historyf1 = model1.fit_generator(\n",
    "    generator = train_flow,\n",
    "    steps_per_epoch = TRAIN_STEPS,\n",
    "    epochs = N_EPOCHS + EPOCHS,\n",
    "    initial_epoch = N_EPOCHS,\n",
    "    verbose = 1,\n",
    "    callbacks = cbf1,\n",
    "    validation_data = valid_flow,\n",
    "    validation_steps = VALID_STEPS)\n",
    "stop = time.time()\n",
    "etime = stop - start\n",
    "print('Done. Elapsed time {:.0f} seconds for {:} epochs, average {:.1f} seconds/epoch.'.format(etime, EPOCHS, etime/EPOCHS))\n",
    "\n",
    "# Save last model\n",
    "model1.save(fur_weight_model1)\n",
    "\n",
    "# Save the history\n",
    "with open(fur_his_model1, 'wb') as file_pi:\n",
    "    pickle.dump(historyf1.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This training model 1 used total time 23,350 seconds for 100 epochs and average time 233.5 seconds/epoch. We ended up with 124th as the best epoch. The best epoch given minimum loss equal to 0.58728 that was <b>higher loss than the last best model</b> that given loss equal to 0.54127.\n",
    "\n",
    "Then, I plotted accuracy and loss value for each epoch into line graph as you can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(last_his_model1, \"rb\") as input_file:\n",
    "     his_model_1 = pd.DataFrame(pickle.load(input_file))\n",
    "\n",
    "with open(fur_his_model1, \"rb\") as input_file:\n",
    "     his_model_1_fur = pd.DataFrame(pickle.load(input_file))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure()\n",
    "plt.plot(pd.concat([his_model_1['acc'], his_model_1_fur['acc']], axis=0, ignore_index=True))\n",
    "plt.plot(pd.concat([his_model_1['val_acc'], his_model_1_fur['val_acc']], axis=0, ignore_index=True))\n",
    "plt.title('Model1 Further Xception accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure()\n",
    "plt.plot(pd.concat([his_model_1['loss'], his_model_1_fur['loss']], axis=0, ignore_index=True))\n",
    "plt.plot(pd.concat([his_model_1['val_loss'], his_model_1_fur['val_loss']], axis=0, ignore_index=True))\n",
    "plt.title('Model1 Further Xception loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 3])\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above loss graph, we can see that trend of loss value of validation set was already incresing that mean <b>overfitting of the model</b>. And as I already mention that the lowest validation loss of further training model is higher than the lowest validation loss from the last best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model 2 (Xception pretraining model (freezing weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model2 Xception freezing weight ...\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 75s 265ms/step - loss: 4.3976 - acc: 0.5151 - val_loss: 0.7488 - val_acc: 0.5236\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.74878, saving model to best_xcep_freeze.hdf5\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.7330 - acc: 0.5318 - val_loss: 0.6906 - val_acc: 0.5303\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.74878 to 0.69060, saving model to best_xcep_freeze.hdf5\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6986 - acc: 0.5412 - val_loss: 0.6879 - val_acc: 0.5195\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.69060 to 0.68787, saving model to best_xcep_freeze.hdf5\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6933 - acc: 0.5687 - val_loss: 0.7749 - val_acc: 0.5276\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.68787\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6929 - acc: 0.5598 - val_loss: 0.6917 - val_acc: 0.5330\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.68787\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6856 - acc: 0.5830 - val_loss: 0.6808 - val_acc: 0.5558\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.68787 to 0.68076, saving model to best_xcep_freeze.hdf5\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6863 - acc: 0.5703 - val_loss: 0.7497 - val_acc: 0.5492\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.68076\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6832 - acc: 0.5770 - val_loss: 0.7585 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.68076\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 63s 226ms/step - loss: 0.6860 - acc: 0.5894 - val_loss: 0.8804 - val_acc: 0.5121\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.68076\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6807 - acc: 0.5967 - val_loss: 0.9776 - val_acc: 0.5128\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.68076\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6833 - acc: 0.5881 - val_loss: 0.8050 - val_acc: 0.5162\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.68076\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6870 - acc: 0.5863 - val_loss: 0.8396 - val_acc: 0.5216\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.68076\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6885 - acc: 0.5954 - val_loss: 0.8343 - val_acc: 0.5054\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.68076\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6758 - acc: 0.5916 - val_loss: 0.8638 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.68076\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6761 - acc: 0.5992 - val_loss: 0.8279 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.68076\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6823 - acc: 0.5883 - val_loss: 0.8876 - val_acc: 0.5310\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.68076\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6820 - acc: 0.5845 - val_loss: 1.0906 - val_acc: 0.5330\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.68076\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6756 - acc: 0.5990 - val_loss: 0.9429 - val_acc: 0.5364\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.68076\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6856 - acc: 0.5910 - val_loss: 1.0793 - val_acc: 0.5384\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.68076\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6780 - acc: 0.5972 - val_loss: 1.3066 - val_acc: 0.5222\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.68076\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.7036 - acc: 0.6045 - val_loss: 0.7956 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.68076\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6804 - acc: 0.5939 - val_loss: 0.8740 - val_acc: 0.5512\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.68076\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6826 - acc: 0.5921 - val_loss: 0.9051 - val_acc: 0.5243\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.68076\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6818 - acc: 0.5992 - val_loss: 0.9781 - val_acc: 0.5404\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.68076\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6734 - acc: 0.6003 - val_loss: 0.8983 - val_acc: 0.5573\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.68076\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6895 - acc: 0.5903 - val_loss: 0.8359 - val_acc: 0.5499\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.68076\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6795 - acc: 0.6032 - val_loss: 1.5196 - val_acc: 0.5404\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.68076\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6801 - acc: 0.5847 - val_loss: 1.1046 - val_acc: 0.5485\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.68076\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6827 - acc: 0.5939 - val_loss: 0.9243 - val_acc: 0.5809\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.68076\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6791 - acc: 0.6128 - val_loss: 1.1651 - val_acc: 0.5761\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.68076\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6873 - acc: 0.5928 - val_loss: 1.1812 - val_acc: 0.5404\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.68076\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6694 - acc: 0.6048 - val_loss: 1.1020 - val_acc: 0.5586\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.68076\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6844 - acc: 0.5905 - val_loss: 1.2639 - val_acc: 0.5620\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.68076\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6797 - acc: 0.6039 - val_loss: 1.2333 - val_acc: 0.5458\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.68076\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6851 - acc: 0.6063 - val_loss: 1.0613 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.68076\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6820 - acc: 0.5912 - val_loss: 1.0774 - val_acc: 0.5573\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.68076\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6806 - acc: 0.6134 - val_loss: 1.3621 - val_acc: 0.5532\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.68076\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6769 - acc: 0.6010 - val_loss: 1.8379 - val_acc: 0.5681\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.68076\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6811 - acc: 0.6023 - val_loss: 1.5253 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.68076\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6739 - acc: 0.6077 - val_loss: 1.5156 - val_acc: 0.5505\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.68076\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6740 - acc: 0.6061 - val_loss: 1.8349 - val_acc: 0.5364\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.68076\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6767 - acc: 0.6016 - val_loss: 2.2585 - val_acc: 0.5276\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.68076\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 63s 226ms/step - loss: 0.6907 - acc: 0.6016 - val_loss: 2.7961 - val_acc: 0.5296\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.68076\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 63s 226ms/step - loss: 0.6828 - acc: 0.6048 - val_loss: 2.8129 - val_acc: 0.5168\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.68076\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6829 - acc: 0.6125 - val_loss: 3.0276 - val_acc: 0.5195\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.68076\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 63s 226ms/step - loss: 0.6702 - acc: 0.6110 - val_loss: 2.9459 - val_acc: 0.5317\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.68076\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 63s 226ms/step - loss: 0.6846 - acc: 0.6125 - val_loss: 2.3220 - val_acc: 0.5310\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.68076\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6806 - acc: 0.6036 - val_loss: 3.9026 - val_acc: 0.5222\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.68076\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 63s 226ms/step - loss: 0.6738 - acc: 0.6070 - val_loss: 2.7709 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.68076\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6813 - acc: 0.6036 - val_loss: 1.3906 - val_acc: 0.5768\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.68076\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6951 - acc: 0.5910 - val_loss: 3.6013 - val_acc: 0.5162\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.68076\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6736 - acc: 0.6099 - val_loss: 1.5872 - val_acc: 0.5445\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.68076\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 63s 226ms/step - loss: 0.6833 - acc: 0.6154 - val_loss: 1.2260 - val_acc: 0.5694\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.68076\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6841 - acc: 0.6077 - val_loss: 1.4378 - val_acc: 0.5431\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.68076\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6764 - acc: 0.6234 - val_loss: 1.5579 - val_acc: 0.5640\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.68076\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6728 - acc: 0.6117 - val_loss: 2.8428 - val_acc: 0.5243\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.68076\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6754 - acc: 0.6092 - val_loss: 2.7765 - val_acc: 0.5310\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.68076\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6794 - acc: 0.5936 - val_loss: 1.2407 - val_acc: 0.5573\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.68076\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6852 - acc: 0.6072 - val_loss: 1.2267 - val_acc: 0.5640\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.68076\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6864 - acc: 0.6034 - val_loss: 1.2344 - val_acc: 0.5822\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.68076\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6772 - acc: 0.6061 - val_loss: 2.7858 - val_acc: 0.5256\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.68076\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6872 - acc: 0.6083 - val_loss: 1.9610 - val_acc: 0.5532\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.68076\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6870 - acc: 0.5988 - val_loss: 1.6294 - val_acc: 0.5714\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.68076\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6684 - acc: 0.6232 - val_loss: 1.6077 - val_acc: 0.5499\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.68076\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6765 - acc: 0.6061 - val_loss: 2.7560 - val_acc: 0.5357\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.68076\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6702 - acc: 0.6072 - val_loss: 2.0492 - val_acc: 0.5465\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.68076\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6832 - acc: 0.6054 - val_loss: 2.4243 - val_acc: 0.5296\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.68076\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6887 - acc: 0.6150 - val_loss: 1.5686 - val_acc: 0.5357\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.68076\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6771 - acc: 0.6036 - val_loss: 1.7111 - val_acc: 0.5492\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.68076\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6677 - acc: 0.6201 - val_loss: 2.1038 - val_acc: 0.5404\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.68076\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6814 - acc: 0.6039 - val_loss: 3.1363 - val_acc: 0.5222\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.68076\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6795 - acc: 0.6088 - val_loss: 1.5028 - val_acc: 0.5499\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.68076\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6806 - acc: 0.6048 - val_loss: 1.0790 - val_acc: 0.5553\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.68076\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6685 - acc: 0.6063 - val_loss: 2.0161 - val_acc: 0.5162\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.68076\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6738 - acc: 0.6112 - val_loss: 1.7282 - val_acc: 0.5519\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.68076\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6890 - acc: 0.6070 - val_loss: 1.6106 - val_acc: 0.5478\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.68076\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6743 - acc: 0.6030 - val_loss: 2.3597 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.68076\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6788 - acc: 0.6097 - val_loss: 1.5332 - val_acc: 0.5627\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.68076\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6862 - acc: 0.6041 - val_loss: 1.7470 - val_acc: 0.5411s: 0.6863 - ac\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.68076\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6722 - acc: 0.6072 - val_loss: 1.6728 - val_acc: 0.5532\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.68076\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6766 - acc: 0.6145 - val_loss: 3.3919 - val_acc: 0.5425\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.68076\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6830 - acc: 0.6005 - val_loss: 2.7296 - val_acc: 0.5539\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.68076\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6705 - acc: 0.6141 - val_loss: 1.7072 - val_acc: 0.5580\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.68076\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6729 - acc: 0.6125 - val_loss: 1.7729 - val_acc: 0.5647\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.68076\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6800 - acc: 0.6101 - val_loss: 1.5198 - val_acc: 0.5654\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.68076\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 63s 226ms/step - loss: 0.6821 - acc: 0.6072 - val_loss: 3.1291 - val_acc: 0.5492\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.68076\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6817 - acc: 0.6130 - val_loss: 2.2973 - val_acc: 0.5451\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.68076\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 63s 226ms/step - loss: 0.6746 - acc: 0.6186 - val_loss: 3.4884 - val_acc: 0.5431\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.68076\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 63s 226ms/step - loss: 0.6853 - acc: 0.6061 - val_loss: 1.7501 - val_acc: 0.5647\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.68076\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 63s 226ms/step - loss: 0.6866 - acc: 0.6025 - val_loss: 2.5434 - val_acc: 0.5512\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.68076\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6720 - acc: 0.6208 - val_loss: 3.5140 - val_acc: 0.5404\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.68076\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 63s 226ms/step - loss: 0.6774 - acc: 0.6092 - val_loss: 1.2534 - val_acc: 0.5627\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.68076\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6785 - acc: 0.6208 - val_loss: 3.0141 - val_acc: 0.5323\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.68076\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6811 - acc: 0.6063 - val_loss: 1.7847 - val_acc: 0.5485\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.68076\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6765 - acc: 0.6097 - val_loss: 1.5976 - val_acc: 0.5499\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.68076\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 63s 226ms/step - loss: 0.6735 - acc: 0.6197 - val_loss: 5.1961 - val_acc: 0.5236\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.68076\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6742 - acc: 0.6283 - val_loss: 3.2752 - val_acc: 0.5465\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.68076\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6829 - acc: 0.6081 - val_loss: 3.1190 - val_acc: 0.5566\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.68076\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 63s 225ms/step - loss: 0.6835 - acc: 0.6065 - val_loss: 2.1296 - val_acc: 0.5512\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.68076\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 63s 226ms/step - loss: 0.6715 - acc: 0.6261 - val_loss: 2.5275 - val_acc: 0.5417\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.68076\n",
      "Done. Elapsed time 6349 seconds for 100 epochs, average 63.5 seconds/epoch.\n"
     ]
    }
   ],
   "source": [
    "# Start timing\n",
    "start = time.time()\n",
    "\n",
    "# Training\n",
    "print('Training the model2 Xception freezing weight ...')\n",
    "history2 = model2.fit_generator(\n",
    "    generator = train_flow,\n",
    "    steps_per_epoch = TRAIN_STEPS,\n",
    "    epochs = N_EPOCHS + EPOCHS,\n",
    "    initial_epoch = N_EPOCHS,\n",
    "    verbose = 1,\n",
    "    callbacks = cb2,\n",
    "    validation_data = valid_flow,\n",
    "    validation_steps = VALID_STEPS)\n",
    "stop = time.time()\n",
    "etime = stop - start\n",
    "print('Done. Elapsed time {:.0f} seconds for {:} epochs, average {:.1f} seconds/epoch.'.format(etime, EPOCHS, etime/EPOCHS))\n",
    "\n",
    "# Save last model\n",
    "model2.save(last_weight_model2)\n",
    "\n",
    "# Save the history\n",
    "with open(last_his_model2, 'wb') as file_pi:\n",
    "    pickle.dump(history2.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This training model 2 used total time 6,349 seconds for 100 epochs, and average time 63.5 seconds/epoch. We ended up with <b>6th as the best epoch</b>.\n",
    "\n",
    "Then, I plotted accuracy and loss value for each epoch into line graph as you can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure()\n",
    "plt.plot(history2.history['acc'])\n",
    "plt.plot(history2.history['val_acc'])\n",
    "plt.title('Model2 Xception freezing weight accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure()\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('Model2 Xception freezing weight loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 3])\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this model, accuracy of validation-set didn't much and the loss value showed that <b>this model overfit very quickly</b> (as you can see from the minimum validation loss is at 5th epoch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model 3 (InceptionResNetV2 pretraining model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model3 inceptionV2 ...\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 292s 1s/step - loss: 0.7992 - acc: 0.5153 - val_loss: 7.8704 - val_acc: 0.4973\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.87041, saving model to best_inceptionV2.hdf5\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.6836 - acc: 0.5943 - val_loss: 1.4736 - val_acc: 0.5377\n",
      "\n",
      "Epoch 00002: val_loss improved from 7.87041 to 1.47357, saving model to best_inceptionV2.hdf5\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.6680 - acc: 0.6125 - val_loss: 2.6551 - val_acc: 0.5094\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.47357\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.6469 - acc: 0.6386 - val_loss: 0.7945 - val_acc: 0.5822\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.47357 to 0.79449, saving model to best_inceptionV2.hdf5\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.6615 - acc: 0.6303 - val_loss: 0.6897 - val_acc: 0.5829\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.79449 to 0.68970, saving model to best_inceptionV2.hdf5\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.6470 - acc: 0.6408 - val_loss: 0.8385 - val_acc: 0.5620\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.68970\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.6356 - acc: 0.6415 - val_loss: 0.6446 - val_acc: 0.6456\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.68970 to 0.64459, saving model to best_inceptionV2.hdf5\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.6339 - acc: 0.6479 - val_loss: 0.7400 - val_acc: 0.6112\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.64459\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.6201 - acc: 0.6588 - val_loss: 0.6627 - val_acc: 0.5970\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.64459\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.6400 - acc: 0.6424 - val_loss: 1.5056 - val_acc: 0.4394\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.64459\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.6341 - acc: 0.6448 - val_loss: 0.7513 - val_acc: 0.5249\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.64459\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.6221 - acc: 0.6628 - val_loss: 0.6454 - val_acc: 0.6179\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.64459\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.6211 - acc: 0.6657 - val_loss: 0.6353 - val_acc: 0.6550\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.64459 to 0.63533, saving model to best_inceptionV2.hdf5\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.6293 - acc: 0.6468 - val_loss: 0.8387 - val_acc: 0.5317\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.63533\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.6127 - acc: 0.6655 - val_loss: 0.6788 - val_acc: 0.5923\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.63533\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.6139 - acc: 0.6646 - val_loss: 0.6943 - val_acc: 0.5883\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.63533\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.6152 - acc: 0.6606 - val_loss: 0.6938 - val_acc: 0.6368\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.63533\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.6083 - acc: 0.6790 - val_loss: 0.8903 - val_acc: 0.6173\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.63533\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.6071 - acc: 0.6735 - val_loss: 0.6015 - val_acc: 0.6840\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.63533 to 0.60152, saving model to best_inceptionV2.hdf5\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5903 - acc: 0.6879 - val_loss: 1.5599 - val_acc: 0.5135\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.60152\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5982 - acc: 0.6806 - val_loss: 0.6568 - val_acc: 0.6617\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.60152\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.6037 - acc: 0.6721 - val_loss: 1.1645 - val_acc: 0.5148\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.60152\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5921 - acc: 0.6857 - val_loss: 0.7233 - val_acc: 0.6307\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.60152\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.6130 - acc: 0.6693 - val_loss: 0.6885 - val_acc: 0.6274\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.60152\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.6023 - acc: 0.6815 - val_loss: 0.7245 - val_acc: 0.6018\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.60152\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5889 - acc: 0.6879 - val_loss: 0.6190 - val_acc: 0.6644\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.60152\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.5836 - acc: 0.6879 - val_loss: 0.7582 - val_acc: 0.5775\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.60152\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5836 - acc: 0.6911 - val_loss: 0.6549 - val_acc: 0.7035\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.60152\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.5761 - acc: 0.6995 - val_loss: 0.6889 - val_acc: 0.6806\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.60152\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.5808 - acc: 0.6964 - val_loss: 0.7667 - val_acc: 0.6253\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.60152\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.5653 - acc: 0.7146 - val_loss: 0.6158 - val_acc: 0.6759\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.60152\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5645 - acc: 0.7064 - val_loss: 0.7625 - val_acc: 0.6307\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.60152\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5663 - acc: 0.7046 - val_loss: 0.7785 - val_acc: 0.6813\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.60152\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5695 - acc: 0.7053 - val_loss: 0.7749 - val_acc: 0.6415\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.60152\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.5679 - acc: 0.7026 - val_loss: 0.6456 - val_acc: 0.6914\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.60152\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5611 - acc: 0.7073 - val_loss: 0.5724 - val_acc: 0.6995\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.60152 to 0.57242, saving model to best_inceptionV2.hdf5\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.5522 - acc: 0.7106 - val_loss: 0.6074 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.57242\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.5446 - acc: 0.7124 - val_loss: 0.9230 - val_acc: 0.6260\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.57242\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.5664 - acc: 0.7017 - val_loss: 1.1542 - val_acc: 0.5296\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.57242\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5616 - acc: 0.7042 - val_loss: 0.6469 - val_acc: 0.6732\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.57242\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.5531 - acc: 0.7157 - val_loss: 1.2854 - val_acc: 0.5499\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.57242\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.5526 - acc: 0.7229 - val_loss: 1.7938 - val_acc: 0.5889\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.57242\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5454 - acc: 0.7115 - val_loss: 0.7995 - val_acc: 0.5593\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.57242\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.5518 - acc: 0.7184 - val_loss: 0.6507 - val_acc: 0.6772\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.57242\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5409 - acc: 0.7251 - val_loss: 0.5999 - val_acc: 0.6920\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.57242\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.5399 - acc: 0.7258 - val_loss: 0.6379 - val_acc: 0.6611\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.57242\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.5412 - acc: 0.7215 - val_loss: 0.7359 - val_acc: 0.6705\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.57242\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5412 - acc: 0.7306 - val_loss: 0.6913 - val_acc: 0.6267\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.57242\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.5306 - acc: 0.7262 - val_loss: 0.8440 - val_acc: 0.6193\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.57242\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 250s 890ms/step - loss: 0.5438 - acc: 0.7258 - val_loss: 0.6629 - val_acc: 0.6651\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.57242\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 251s 892ms/step - loss: 0.5349 - acc: 0.7224 - val_loss: 0.6754 - val_acc: 0.6381\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.57242\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 251s 892ms/step - loss: 0.5396 - acc: 0.7273 - val_loss: 1.8453 - val_acc: 0.4751\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.57242\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 250s 891ms/step - loss: 0.5344 - acc: 0.7302 - val_loss: 0.6467 - val_acc: 0.6705\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.57242\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 250s 890ms/step - loss: 0.5323 - acc: 0.7286 - val_loss: 0.7226 - val_acc: 0.6705\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.57242\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 250s 891ms/step - loss: 0.5516 - acc: 0.7191 - val_loss: 0.7893 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.57242\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 251s 892ms/step - loss: 0.5410 - acc: 0.7222 - val_loss: 1.1436 - val_acc: 0.5708\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.57242\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 250s 891ms/step - loss: 0.5319 - acc: 0.7300 - val_loss: 0.7045 - val_acc: 0.6658\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.57242\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 251s 892ms/step - loss: 0.5315 - acc: 0.7302 - val_loss: 0.8590 - val_acc: 0.6024\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.57242\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 251s 891ms/step - loss: 0.5289 - acc: 0.7380 - val_loss: 0.8874 - val_acc: 0.5991\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.57242\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 250s 891ms/step - loss: 0.5345 - acc: 0.7302 - val_loss: 0.9287 - val_acc: 0.5943\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.57242\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.5384 - acc: 0.7218 - val_loss: 0.7753 - val_acc: 0.6476\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.57242\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5270 - acc: 0.7240 - val_loss: 0.8582 - val_acc: 0.5613\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.57242\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.5247 - acc: 0.7329 - val_loss: 0.6046 - val_acc: 0.6759\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.57242\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5139 - acc: 0.7473 - val_loss: 0.8144 - val_acc: 0.6550\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.57242\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5259 - acc: 0.7255 - val_loss: 0.6171 - val_acc: 0.6752\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.57242\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5376 - acc: 0.7322 - val_loss: 0.7277 - val_acc: 0.6550\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.57242\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5184 - acc: 0.7415 - val_loss: 0.7287 - val_acc: 0.5916\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.57242\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5181 - acc: 0.7378 - val_loss: 0.7571 - val_acc: 0.6577\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.57242\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.5173 - acc: 0.7442 - val_loss: 0.6570 - val_acc: 0.6584\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.57242\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.5180 - acc: 0.7355 - val_loss: 0.7269 - val_acc: 0.6604\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.57242\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.5067 - acc: 0.7449 - val_loss: 0.6878 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.57242\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.5184 - acc: 0.7422 - val_loss: 0.6626 - val_acc: 0.6907\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.57242\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.5057 - acc: 0.7471 - val_loss: 1.8641 - val_acc: 0.5964\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.57242\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.5141 - acc: 0.7440 - val_loss: 0.6113 - val_acc: 0.6954\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.57242\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.4974 - acc: 0.7553 - val_loss: 0.9455 - val_acc: 0.6334\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.57242\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5050 - acc: 0.7531 - val_loss: 0.7875 - val_acc: 0.5849\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.57242\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5076 - acc: 0.7460 - val_loss: 0.9956 - val_acc: 0.6867\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.57242\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5102 - acc: 0.7538 - val_loss: 0.8556 - val_acc: 0.6907\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.57242\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5015 - acc: 0.7504 - val_loss: 0.7184 - val_acc: 0.6408\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.57242\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5023 - acc: 0.7498 - val_loss: 0.6395 - val_acc: 0.7096\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.57242\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.4869 - acc: 0.7596 - val_loss: 0.6591 - val_acc: 0.6388\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.57242\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5035 - acc: 0.7578 - val_loss: 0.7345 - val_acc: 0.6166\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.57242\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.5055 - acc: 0.7498 - val_loss: 0.9166 - val_acc: 0.6132\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.57242\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.4998 - acc: 0.7558 - val_loss: 0.7471 - val_acc: 0.6732\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.57242\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 250s 889ms/step - loss: 0.4913 - acc: 0.7602 - val_loss: 0.5945 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.57242\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.4956 - acc: 0.7527 - val_loss: 1.8325 - val_acc: 0.6105\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.57242\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.4958 - acc: 0.7549 - val_loss: 0.6443 - val_acc: 0.6691\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.57242\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.5045 - acc: 0.7569 - val_loss: 0.7554 - val_acc: 0.6388\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.57242\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.4947 - acc: 0.7540 - val_loss: 1.2010 - val_acc: 0.6570\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.57242\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.4788 - acc: 0.7625 - val_loss: 2.5996 - val_acc: 0.5580\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.57242\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.4959 - acc: 0.7565 - val_loss: 0.7232 - val_acc: 0.7042\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.57242\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.4945 - acc: 0.7671 - val_loss: 0.7705 - val_acc: 0.6247\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.57242\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.4952 - acc: 0.7569 - val_loss: 0.8451 - val_acc: 0.6530\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.57242\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.4987 - acc: 0.7560 - val_loss: 0.6686 - val_acc: 0.6887\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.57242\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.4881 - acc: 0.7627 - val_loss: 0.8637 - val_acc: 0.6462\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.57242\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.4788 - acc: 0.7649 - val_loss: 0.7538 - val_acc: 0.6186\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.57242\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.4922 - acc: 0.7565 - val_loss: 0.8900 - val_acc: 0.6193\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.57242\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.4753 - acc: 0.7731 - val_loss: 0.9539 - val_acc: 0.6280\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.57242\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.4849 - acc: 0.7647 - val_loss: 0.6002 - val_acc: 0.7008\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.57242\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 250s 890ms/step - loss: 0.4963 - acc: 0.7462 - val_loss: 0.6402 - val_acc: 0.6624\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.57242\n",
      "Done. Elapsed time 25425 seconds for 100 epochs, average 254.2 seconds/epoch.\n"
     ]
    }
   ],
   "source": [
    "# Start timing\n",
    "start = time.time()\n",
    "\n",
    "# Training\n",
    "print('Training the model3 inceptionV2 ...')\n",
    "history3 = model3.fit_generator(\n",
    "    generator = train_flow,\n",
    "    steps_per_epoch = TRAIN_STEPS,\n",
    "    epochs = N_EPOCHS + EPOCHS,\n",
    "    initial_epoch = N_EPOCHS,\n",
    "    verbose = 1,\n",
    "    callbacks = cb3,\n",
    "    validation_data = valid_flow,\n",
    "    validation_steps = VALID_STEPS)\n",
    "stop = time.time()\n",
    "etime = stop - start\n",
    "print('Done. Elapsed time {:.0f} seconds for {:} epochs, average {:.1f} seconds/epoch.'.format(etime, EPOCHS, etime/EPOCHS))\n",
    "\n",
    "# Save last model\n",
    "model3.save(last_weight_model3)\n",
    "\n",
    "# Save the history\n",
    "with open(last_his_model3, 'wb') as file_pi:\n",
    "    pickle.dump(history3.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This training model 3 used total time 25,425 seconds for 100 epochs, and average time 254.2 seconds/epoch. We ended up with <b>36th as the best epoch</b>.\n",
    "\n",
    "Then, I plotted accuracy and loss value for each epoch into line graph as you can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure()\n",
    "plt.plot(history3.history['acc'])\n",
    "plt.plot(history3.history['val_acc'])\n",
    "plt.title('Model3 inceptionV2 accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure()\n",
    "plt.plot(history3.history['loss'])\n",
    "plt.plot(history3.history['val_loss'])\n",
    "plt.title('Model3 inceptionV2 loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 3])\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model, accuracy and loss of traning-set increse and decrese respectively. On the other hand, even accuracy of the validation-set are fructuate but loss value tend to decrese so I decided to try to <b>train this model further another 100 epochs</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Go further with Model 3  (InceptionResNetV2 pretraining model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model path after traning 200 epochs\n",
    "fur_weight_model3=\"200_inceptionV2.hdf5\"\n",
    "\n",
    "# History path after traning 200 epochs\n",
    "fur_his_model3=\"200_inceptionV2_his\"\n",
    "\n",
    "# Model path for the epoch the has minimum val_loss\n",
    "best_weight_model3_fur=\"best_inceptionV2_fur.hdf5\"\n",
    "\n",
    "# Create model checkpoint when it has minimum val_loss\n",
    "checkpointf3 = ModelCheckpoint(best_weight_model3_fur, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min')\n",
    "cbf3 = [checkpointf3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training further the model3 inceptionV2 ...\n",
      "Epoch 101/200\n",
      "281/281 [==============================] - 280s 998ms/step - loss: 0.4762 - acc: 0.7714 - val_loss: 0.6336 - val_acc: 0.7055\n",
      "\n",
      "Epoch 00101: val_loss improved from inf to 0.63360, saving model to best_inceptionV2_fur.hdf5\n",
      "Epoch 102/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4887 - acc: 0.7616 - val_loss: 0.7244 - val_acc: 0.6577\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.63360\n",
      "Epoch 103/200\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.4749 - acc: 0.7667 - val_loss: 0.7552 - val_acc: 0.5761\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.63360\n",
      "Epoch 104/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4859 - acc: 0.7693 - val_loss: 0.5773 - val_acc: 0.6941\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.63360 to 0.57729, saving model to best_inceptionV2_fur.hdf5\n",
      "Epoch 105/200\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.4849 - acc: 0.7667 - val_loss: 0.7870 - val_acc: 0.6294\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.57729\n",
      "Epoch 106/200\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.4817 - acc: 0.7707 - val_loss: 0.7385 - val_acc: 0.6808\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.57729\n",
      "Epoch 107/200\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.4795 - acc: 0.7656 - val_loss: 0.6952 - val_acc: 0.6476\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.57729\n",
      "Epoch 108/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4798 - acc: 0.7676 - val_loss: 0.7600 - val_acc: 0.6867\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.57729\n",
      "Epoch 109/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4649 - acc: 0.7765 - val_loss: 0.7362 - val_acc: 0.6806\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.57729\n",
      "Epoch 110/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4778 - acc: 0.7669 - val_loss: 0.7289 - val_acc: 0.6408\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.57729\n",
      "Epoch 111/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4756 - acc: 0.7651 - val_loss: 0.6952 - val_acc: 0.5991\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.57729\n",
      "Epoch 112/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4780 - acc: 0.7689 - val_loss: 0.8220 - val_acc: 0.6139\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.57729\n",
      "Epoch 113/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4598 - acc: 0.7778 - val_loss: 0.6401 - val_acc: 0.6961\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.57729\n",
      "Epoch 114/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4766 - acc: 0.7687 - val_loss: 0.7029 - val_acc: 0.6947\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.57729\n",
      "Epoch 115/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4685 - acc: 0.7702 - val_loss: 0.7262 - val_acc: 0.6853\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.57729\n",
      "Epoch 116/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4690 - acc: 0.7729 - val_loss: 0.7875 - val_acc: 0.7210\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.57729\n",
      "Epoch 117/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4683 - acc: 0.7727 - val_loss: 0.5992 - val_acc: 0.7123\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.57729\n",
      "Epoch 118/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4666 - acc: 0.7760 - val_loss: 1.5045 - val_acc: 0.5997\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.57729\n",
      "Epoch 119/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4743 - acc: 0.7796 - val_loss: 0.6499 - val_acc: 0.7049\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.57729\n",
      "Epoch 120/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4610 - acc: 0.7791 - val_loss: 0.8189 - val_acc: 0.6617\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.57729\n",
      "Epoch 121/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4612 - acc: 0.7794 - val_loss: 0.6349 - val_acc: 0.6179\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.57729\n",
      "Epoch 122/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4520 - acc: 0.7798 - val_loss: 1.0392 - val_acc: 0.6139\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.57729\n",
      "Epoch 123/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4686 - acc: 0.7849 - val_loss: 0.6690 - val_acc: 0.7109\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.57729\n",
      "Epoch 124/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4572 - acc: 0.7776 - val_loss: 0.8121 - val_acc: 0.6799\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.57729\n",
      "Epoch 125/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4539 - acc: 0.7847 - val_loss: 0.7058 - val_acc: 0.6873\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.57729\n",
      "Epoch 126/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4539 - acc: 0.7849 - val_loss: 1.4471 - val_acc: 0.7001\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.57729\n",
      "Epoch 127/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4599 - acc: 0.7820 - val_loss: 0.7228 - val_acc: 0.6732\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.57729\n",
      "Epoch 128/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4513 - acc: 0.7802 - val_loss: 1.0009 - val_acc: 0.6206\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.57729\n",
      "Epoch 129/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4551 - acc: 0.7847 - val_loss: 0.6996 - val_acc: 0.6813\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.57729\n",
      "Epoch 130/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4609 - acc: 0.7729 - val_loss: 0.6799 - val_acc: 0.6516\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.57729\n",
      "Epoch 131/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4528 - acc: 0.7867 - val_loss: 1.2184 - val_acc: 0.6482\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.57729\n",
      "Epoch 132/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4659 - acc: 0.7716 - val_loss: 0.6833 - val_acc: 0.6395\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.57729\n",
      "Epoch 133/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4544 - acc: 0.7794 - val_loss: 0.8162 - val_acc: 0.6361\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.57729\n",
      "Epoch 134/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4485 - acc: 0.7938 - val_loss: 0.8311 - val_acc: 0.6691\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.57729\n",
      "Epoch 135/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4413 - acc: 0.7907 - val_loss: 0.8851 - val_acc: 0.6846\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.57729\n",
      "Epoch 136/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4518 - acc: 0.7827 - val_loss: 1.0298 - val_acc: 0.5458\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.57729\n",
      "Epoch 137/200\n",
      "281/281 [==============================] - 249s 886ms/step - loss: 0.4561 - acc: 0.7827 - val_loss: 1.2657 - val_acc: 0.6489\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.57729\n",
      "Epoch 138/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4465 - acc: 0.7925 - val_loss: 0.8607 - val_acc: 0.6934\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.57729\n",
      "Epoch 139/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4517 - acc: 0.7905 - val_loss: 1.1339 - val_acc: 0.6826\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.57729\n",
      "Epoch 140/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4499 - acc: 0.7918 - val_loss: 0.9318 - val_acc: 0.6927\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.57729\n",
      "Epoch 141/200\n",
      "281/281 [==============================] - 249s 886ms/step - loss: 0.4521 - acc: 0.7849 - val_loss: 0.9747 - val_acc: 0.6732\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.57729\n",
      "Epoch 142/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4246 - acc: 0.7929 - val_loss: 0.8562 - val_acc: 0.6806\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.57729\n",
      "Epoch 143/200\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.4349 - acc: 0.7954 - val_loss: 1.1760 - val_acc: 0.6509\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.57729\n",
      "Epoch 144/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4323 - acc: 0.7992 - val_loss: 1.4358 - val_acc: 0.6112\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.57729\n",
      "Epoch 145/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4474 - acc: 0.7896 - val_loss: 0.6646 - val_acc: 0.6193\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.57729\n",
      "Epoch 146/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4346 - acc: 0.7947 - val_loss: 1.2447 - val_acc: 0.6334\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.57729\n",
      "Epoch 147/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4335 - acc: 0.7918 - val_loss: 0.6974 - val_acc: 0.6806\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.57729\n",
      "Epoch 148/200\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.4355 - acc: 0.7883 - val_loss: 1.0414 - val_acc: 0.6658\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.57729\n",
      "Epoch 149/200\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.4250 - acc: 0.8005 - val_loss: 0.9645 - val_acc: 0.6543\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.57729\n",
      "Epoch 150/200\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.4352 - acc: 0.7923 - val_loss: 1.2679 - val_acc: 0.5937\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.57729\n",
      "Epoch 151/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4291 - acc: 0.8020 - val_loss: 0.8291 - val_acc: 0.6584\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.57729\n",
      "Epoch 152/200\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.4407 - acc: 0.7952 - val_loss: 1.8610 - val_acc: 0.6321\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.57729\n",
      "Epoch 153/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4303 - acc: 0.7934 - val_loss: 1.3544 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.57729\n",
      "Epoch 154/200\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.4307 - acc: 0.8023 - val_loss: 0.8604 - val_acc: 0.6503\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.57729\n",
      "Epoch 155/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4291 - acc: 0.8052 - val_loss: 1.2760 - val_acc: 0.6516\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.57729\n",
      "Epoch 156/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4236 - acc: 0.8065 - val_loss: 0.8568 - val_acc: 0.6739\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.57729\n",
      "Epoch 157/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4204 - acc: 0.8016 - val_loss: 0.6803 - val_acc: 0.6570\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.57729\n",
      "Epoch 158/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4460 - acc: 0.7952 - val_loss: 0.9264 - val_acc: 0.7015\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.57729\n",
      "Epoch 159/200\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.4204 - acc: 0.8032 - val_loss: 0.8536 - val_acc: 0.6860\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.57729\n",
      "Epoch 160/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4191 - acc: 0.8096 - val_loss: 0.9647 - val_acc: 0.6947\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.57729\n",
      "Epoch 161/200\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.4252 - acc: 0.8020 - val_loss: 0.8493 - val_acc: 0.6678\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.57729\n",
      "Epoch 162/200\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.4155 - acc: 0.8038 - val_loss: 0.7971 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.57729\n",
      "Epoch 163/200\n",
      "281/281 [==============================] - 250s 890ms/step - loss: 0.4200 - acc: 0.8052 - val_loss: 0.9952 - val_acc: 0.6678\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.57729\n",
      "Epoch 164/200\n",
      "281/281 [==============================] - 250s 890ms/step - loss: 0.4133 - acc: 0.8105 - val_loss: 1.0236 - val_acc: 0.6577\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.57729\n",
      "Epoch 165/200\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.4232 - acc: 0.8081 - val_loss: 1.2423 - val_acc: 0.6853\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.57729\n",
      "Epoch 166/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4296 - acc: 0.8040 - val_loss: 0.7725 - val_acc: 0.6819\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.57729\n",
      "Epoch 167/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4357 - acc: 0.8096 - val_loss: 0.8716 - val_acc: 0.6678\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.57729\n",
      "Epoch 168/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4027 - acc: 0.8174 - val_loss: 0.6669 - val_acc: 0.6934\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.57729\n",
      "Epoch 169/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4136 - acc: 0.8087 - val_loss: 0.7676 - val_acc: 0.6806\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.57729\n",
      "Epoch 170/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4199 - acc: 0.7983 - val_loss: 0.8020 - val_acc: 0.6260\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.57729\n",
      "Epoch 171/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4129 - acc: 0.8132 - val_loss: 0.7560 - val_acc: 0.6947\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.57729\n",
      "Epoch 172/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4150 - acc: 0.8049 - val_loss: 0.6754 - val_acc: 0.7069\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.57729\n",
      "Epoch 173/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4140 - acc: 0.8103 - val_loss: 0.7439 - val_acc: 0.7022\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.57729\n",
      "Epoch 174/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4309 - acc: 0.8005 - val_loss: 0.7456 - val_acc: 0.6442\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.57729\n",
      "Epoch 175/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4147 - acc: 0.8123 - val_loss: 0.9633 - val_acc: 0.6671\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.57729\n",
      "Epoch 176/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4032 - acc: 0.8152 - val_loss: 0.9917 - val_acc: 0.6388\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.57729\n",
      "Epoch 177/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4218 - acc: 0.8136 - val_loss: 4.6953 - val_acc: 0.5586\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.57729\n",
      "Epoch 178/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4080 - acc: 0.8058 - val_loss: 0.7228 - val_acc: 0.6671\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.57729\n",
      "Epoch 179/200\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.3999 - acc: 0.8161 - val_loss: 1.0223 - val_acc: 0.6516\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.57729\n",
      "Epoch 180/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.3963 - acc: 0.8225 - val_loss: 1.1902 - val_acc: 0.6388\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.57729\n",
      "Epoch 181/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.4078 - acc: 0.8156 - val_loss: 0.8694 - val_acc: 0.6698\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.57729\n",
      "Epoch 182/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.3963 - acc: 0.8176 - val_loss: 0.7702 - val_acc: 0.7102\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.57729\n",
      "Epoch 183/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4009 - acc: 0.8185 - val_loss: 0.9446 - val_acc: 0.6718\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.57729\n",
      "Epoch 184/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.3903 - acc: 0.8227 - val_loss: 1.0504 - val_acc: 0.6658\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.57729\n",
      "Epoch 185/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.3913 - acc: 0.8250 - val_loss: 1.0792 - val_acc: 0.6745\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.57729\n",
      "Epoch 186/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 250s 888ms/step - loss: 0.4127 - acc: 0.8112 - val_loss: 0.9306 - val_acc: 0.6732\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.57729\n",
      "Epoch 187/200\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.3818 - acc: 0.8292 - val_loss: 0.6962 - val_acc: 0.7008\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.57729\n",
      "Epoch 188/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.3929 - acc: 0.8187 - val_loss: 0.7797 - val_acc: 0.6887\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.57729\n",
      "Epoch 189/200\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.3980 - acc: 0.8210 - val_loss: 1.2756 - val_acc: 0.6611\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.57729\n",
      "Epoch 190/200\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.3790 - acc: 0.8334 - val_loss: 0.8661 - val_acc: 0.7049\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.57729\n",
      "Epoch 191/200\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.3823 - acc: 0.8238 - val_loss: 1.2125 - val_acc: 0.6691\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.57729\n",
      "Epoch 192/200\n",
      "281/281 [==============================] - 250s 889ms/step - loss: 0.3809 - acc: 0.8332 - val_loss: 0.7798 - val_acc: 0.6240\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.57729\n",
      "Epoch 193/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.3716 - acc: 0.8276 - val_loss: 1.0741 - val_acc: 0.6691\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.57729\n",
      "Epoch 194/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.3952 - acc: 0.8256 - val_loss: 1.0830 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.57729\n",
      "Epoch 195/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.3814 - acc: 0.8296 - val_loss: 1.3966 - val_acc: 0.6873\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.57729\n",
      "Epoch 196/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.3744 - acc: 0.8287 - val_loss: 0.7576 - val_acc: 0.7022\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.57729\n",
      "Epoch 197/200\n",
      "281/281 [==============================] - 250s 888ms/step - loss: 0.3857 - acc: 0.8274 - val_loss: 1.4274 - val_acc: 0.5559\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.57729\n",
      "Epoch 198/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.3670 - acc: 0.8376 - val_loss: 0.9948 - val_acc: 0.7102\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.57729\n",
      "Epoch 199/200\n",
      "281/281 [==============================] - 249s 887ms/step - loss: 0.4044 - acc: 0.8241 - val_loss: 1.0663 - val_acc: 0.6119\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.57729\n",
      "Epoch 200/200\n",
      "281/281 [==============================] - 249s 888ms/step - loss: 0.3869 - acc: 0.8256 - val_loss: 0.8739 - val_acc: 0.6788\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.57729\n",
      "Done. Elapsed time 25201 seconds for 100 epochs, average 252.0 seconds/epoch.\n"
     ]
    }
   ],
   "source": [
    "# Load architecture and weight from the last 100 epochs training\n",
    "model3 = load_model(last_weight_model3)\n",
    "\n",
    "# Start timing\n",
    "start = time.time()\n",
    "\n",
    "# Training\n",
    "print('Training further the model3 inceptionV2 ...')\n",
    "historyf3 = model3.fit_generator(\n",
    "    generator = train_flow,\n",
    "    steps_per_epoch = TRAIN_STEPS,\n",
    "    epochs = N_EPOCHS + EPOCHS,\n",
    "    initial_epoch = N_EPOCHS,\n",
    "    verbose = 1,\n",
    "    callbacks = cbf3,\n",
    "    validation_data = valid_flow,\n",
    "    validation_steps = VALID_STEPS)\n",
    "stop = time.time()\n",
    "etime = stop - start\n",
    "print('Done. Elapsed time {:.0f} seconds for {:} epochs, average {:.1f} seconds/epoch.'.format(etime, EPOCHS, etime/EPOCHS))\n",
    "\n",
    "# Save last model\n",
    "model3.save(fur_weight_model3)\n",
    "\n",
    "# Save the history\n",
    "with open(fur_his_model3, 'wb') as file_pi:\n",
    "    pickle.dump(historyf3.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This training model 3 used total time 25,201 seconds for 100 epochs and average time 252 seconds/epoch. We ended up with 104th as the best epoch. The best epoch given minimum loss equal to 0.57729 that was <b>higher than the last best model</b> that given loss equal to 0.57242.\n",
    "\n",
    "Then, I plotted accuracy and loss value for each epoch into line graph as you can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXeYFdXdgN+zvfcC7NJ7hwVBEARjN/aOsXeNMYlRo8Z8mmJiEjVq7L1X7AU7oiAd6b0ssMD23tv5/vjNuTP37t2Gu8sK8z7PPnvv1DNzz/z6OaO01ri4uLi4uAAEHOgGuLi4uLh0H1yl4OLi4uLiwVUKLi4uLi4eXKXg4uLi4uLBVQouLi4uLh5cpeDi4uLi4sFVCocASql+SimtlApqw7aXKqXmd0W72ktnt00pdYdS6pnOOv7+oJSarpTadKDb4XLo4CqFboZSKlMpVauUSvJZvtIS7P26uD1zlVJ5SqlSpdQqpdRpLWx7t1KqTilV7vi7dT/P22ZF1lForf+htb6yq87nD+uaBzna9L3WemgHHHejUupyP8t/q5RaZn2+Tym1RSlVZm1/8U89r8vPD1cpdE92ALPMF6XUaCD8ALXlt0BPrXUMcDXwilKqZwvbv6m1jnL8/bu9J+wKRdCVyqab8CLgT8hfZK0DqABOAWKBS4CHlFJTu6Z57eMQ/P26DFcpdE9exvsBvgR4ybmBUipWKfWSZcXvVErdqZQKsNYFWlZfvlJqO/BLP/s+q5Tap5Tao5T6u1Iq0F9DtNartdb15isQDPRu7wVZHtAxju93K6VesT4br+AKpdQu4BvgO2vTYsvjmOLY9z6lVJFSaodS6sS2XJcVelqglPqvUqoQuNtPG/216RKl1C7rXv7JsW2gFW7aZlnWy5VSva11w5RSXyqlCpVSm5RS5zr2e0Ep9YS1vkwpNU8p1ddaZ655lXXN5ymlZiqlshz7D1dKfauUKlZKrVNKnepz7EeVUp9Yx16slBporX4ZmGbOZY4FjAFeB9Ba36W13qi1btRaLwa+Bzz33edexSulPrb6X5H1Od2xPkEp9bxSaq+1/n3HutOUeL6l1v07wVre3j6CUuptpVS2UqpEKfWdUmqkY/9wpdT91vNRopSaby37RCn1G5/rWa2UOt3ftR5quEqhe7IIiLEEQCBwHvCKzzb/Qyy6AcAMRIlcZq27CjgZGA9MBM722fdFoB4YZG1zHNBs2MR64KuBxcC3wLL9vbBWmAEMB44HjrSWxVkex0Lr+2RgE5AE/Bt4VimlrHWtXddkYDuQAtzTxjZNA4YCRwP/ZwlSgJsQb+4kIAa4HKhUSkUCXwKvWeeZBTzmFFbAr4C/WdewEngVQGttrnmsdc1vOhuilAoGPgK+sI79G+BVpZQzvDQL+AsQD2w116m1zgLmIp6B4WLgU611vu9FK6XCgcOAdc3clwDgeaAv0AeoAh5xrH8ZiABGWm39r3XcSYiBcwsQh/zOmc2cwx/OPgIwBxhsnWMF1r20uA+YAEwFEoBbgUakn1zouNaxQBrwaTvacfCitXb/utEf8oAcA9wJ/BM4AREyQYil3g8IBGqAEY79rgG+tT5/A1zrWHectW8QkGrtG+5YPwuYa32+FJjvp13BwInA71to+91ALVDs+OvlvC6fbV+xPvez2jfAsd4sC3IsuxTY6vgeYW3To43XtauVe++vTemO9UuA863Pm4DT/BzjPOB7n2VPAndZn18A3nCsiwIagN7Wdw0McqyfCWRZn6cD2UCAY/3rwN2OYz/jWHcSsNHx/UJgk/U5ANgFnNHMvXgR+AxQbey344Ai63NPRPjG+9nuSeC/LfX9tvYRP/vHWdvEWtdXhShY3+1CgUJgsPX9PuCxznyuf05/blyu+/IyEkLpj0/oCLEwQ4CdjmU7EWsHoBew22edoS8i4PfZBjYBPts3QWtdB8xRkpjcprX+sJlN39JaX9jMutZosQ0W2Y42VVrXEIVYgq1dV1uO3+z5gErrXCAhtG1+tu8LTFZKFTuWBSG/Z5N2aK3LrXCW72/mj17Abq11o2OZ83dvqb0A7yJey+GIQo0APvE9iVLqP8Ao4ChtSU0/20Qg1v8JiFcCEG15tr2BQq11kZ9de/PTLHLPPbLOdQ9wDpCMKCKQ5yMUCMPPb6S1rlFKvQVcqJT6C2I8+HrThyyuUuimaK13KqV2INbeFT6r84E6RACtt5b1AfZYn/fhHffv4/i8G7Gok7SdK2gPQcDAVrdqSgUihAw9/Gyjm/ncFtpyXR05JfBu5D6s9bN8ntb62Bb29fw2Simj0Pa24Zx7gd5KqQCHYugDbG5Lgy0lOhsJG4UjHkutcxtLSJ4IzNBal7ZwuD8gYbXJWutspdQ44EdAIfcgQSkVp7Uu9tnP3Dd/tLePXACchnjWmYiHUGS1IR+ots61ys9xXkQU9XygUtvhyUMeN6fQvbkC+IXWusK5UGvdALwF3KOUiraShzdh5x3eAm5USqUrpeKB2xz77kNi0vcrpWKUUgFKqYFKqRm+J7cSpidayblgpdSFSAx43n5cy0rgfOs4/vIcvuQhlt+Athy8PdfVQTwD/E0pNVgJY5RSicDHwBCl1EXWtQYrpQ5z5CIATlJKTVNKhSC5hcVaa2MB59D8NS9GBOet1nFnItVCb7Sj3S8iIa6zsKuOAFBK3Y4I2mO11gWtHCcaCc8UK6USgLvMCuu3mIN4JfFWW02+5FngMqXU0dZvlKaUGmata28fiUYMgQJEmfzD0YZG4DngAaVULyWFAVOUUqHW+oVI/7ofby/ukMdVCt0YrfU2rXVzSd3fIAJiO2LtvIY8BABPA58jFtIKJGzg5GIk/LQesaxmI3FgXxQS181FhPRvgfO01iv243L+jFhtRUgi9LWWNtZaVyKhgQVKKm0Ob8M52npdHcEDiPL9AihFhF241roMyeGcj1j22cC/kHCG4TVEiBYiidBfOdbdDbxoXfO5juVYVv2piCWfDzwGXKy13tiOdn8HlAB7tNZLfdb9A/E8tih7nMkdzRznQcTbyEcKIz7zWX8R4s1uRPrP76xrWIIURPzXasc8xOOFdvYRJKy6E/GQ11vtcHIzsAZYitzrf+Et814CRtO0iOOQRjUTMnRxcekElFIvIInjOw90Ww51lAzOu1prPe1At6U74XoKLi4uhxxWovx64KkD3ZbuRqcpBaXUc0qpXKWUbyLOrFdKqYeVUlutgSMZndUWFxcXF4NS6ngkHJpD6yGqQ45OCx9ZiaVy4CWt9Sg/609C4uInIYOKHtJaT+6Uxri4uLi4tIlO8xS01t8hyZ3mOA1RGFprvQiIUy3PqePi4uLi0skcyHEKaXgP1smylu3z3VApdTUyGRuRkZEThg0b5ruJi4uLi0sLLF++PF9rndzadgdSKSg/y/zGsrTWT2ElhCZOnKiXLeusqXdcXFxcDk6UUjtb3+rAVh9l4T3qNp22jep0cXFxcekkDqRS+BC42KpCOhwosUZCuri4uLgcIDotfKSUeh2Z4TFJyXzwdyETlqG1fgKZFOskZHrfSuxpn11cXFxcDhCdphS01rNaWa+BX3fEuerq6sjKyqK6urojDucChIWFkZ6eTnBw8IFuiouLSxdyUMySmpWVRXR0NP369cMxbbLLfqK1pqCggKysLPr373+gm+Pi4tKFHBTTXFRXV5OYmOgqhA5CKUViYqLrebm4HIIcFEoBcBVCB+PeTxeXQ5ODRim4uLi4uPx0XKXQARQUFDBu3DjGjRtHjx49SEtL83yvra1t/QDAZZddxqZNmzq5pS4uLi4tc1Akmg80iYmJrFy5EoC7776bqKgobr75Zq9tzEuxAwL86+Hnn3++09vp4uLi0hqup9CJbN26lVGjRnHttdeSkZHBvn37uPrqq5k4cSIjR47kr3/9q2fbadOmsXLlSurr64mLi+O2225j7NixTJkyhdzc3AN4FS4uLocSB52n8JeP1rF+b0vvG28/I3rFcNcpI/dr3/Xr1/P888/zxBNPAHDvvfeSkJBAfX09Rx11FGeffTYjRozw2qekpIQZM2Zw7733ctNNN/Hcc89x2223+Tu8i4uLS4fiegqdzMCBAznssMM8319//XUyMjLIyMhgw4YNrF+/vsk+4eHhnHjiiQBMmDCBzMzMrmqui4vLIc5B5ynsr0XfWURGRno+b9myhYceeoglS5YQFxfHhRde6HcsQEhIiOdzYGAg9fX1XdJWFxcXF9dT6EJKS0uJjo4mJiaGffv28fnnnx/oJrm4uLh4cdB5Ct2ZjIwMRowYwahRoxgwYABHHHHEgW6Si4uLixed9o7mzsLfS3Y2bNjA8OHDD1CLDl7c++ricvCglFqutZ7Y2nZu+MjFxcXFxYOrFFxcXFxcPLhKwcXFxcXFg6sUXFxcXFw8uErBxcXFxcWDqxRcXFxcXDy4SqEDmDlzZpOBaA8++CDXX399s/tERUUBsHfvXs4+++xmj+tbfuvLgw8+SGVlpef7SSedRHFxcVub7uLi4uKFqxQ6gFmzZvHGG294LXvjjTeYNWtWq/v26tWL2bNn7/e5fZXCp59+Slxc3H4fz8XF5dDGVQodwNlnn83HH39MTU0NAJmZmezdu5dx48Zx9NFHk5GRwejRo/nggw+a7JuZmcmoUaMAqKqq4vzzz2fMmDGcd955VFVVeba77rrrPFNu33XXXQA8/PDD7N27l6OOOoqjjjoKgH79+pGfnw/AAw88wKhRoxg1ahQPPvig53zDhw/nqquuYuTIkRx33HFe53FxcTm0OfimuZhzG2Sv6dhj9hgNJ97b7OrExEQmTZrEZ599xmmnncYbb7zBeeedR3h4OO+99x4xMTHk5+dz+OGHc+qppzb7/uPHH3+ciIgIVq9ezerVq8nIyPCsu+eee0hISKChoYGjjz6a1atXc+ONN/LAAw8wd+5ckpKSvI61fPlynn/+eRYvXozWmsmTJzNjxgzi4+PZsmULr7/+Ok8//TTnnnsu77zzDhdeeGHH3CsXF5efNa6n0EE4Q0gmdKS15o477mDMmDEcc8wx7Nmzh5ycnGaP8d1333mE85gxYxgzZoxn3VtvvUVGRgbjx49n3bp1fqfcdjJ//nzOOOMMIiMjiYqK4swzz+T7778HoH///owbNw5wp+Z2cXHx5uDzFFqw6DuT008/nZtuuokVK1ZQVVVFRkYGL7zwAnl5eSxfvpzg4GD69evnd6psJ/68iB07dnDfffexdOlS4uPjufTSS1s9TktzWoWGhno+BwYGuuEjFxcXD66n0EFERUUxc+ZMLr/8ck+CuaSkhJSUFIKDg5k7dy47d+5s8RhHHnkkr776KgBr165l9erVgEy5HRkZSWxsLDk5OcyZM8ezT3R0NGVlZX6P9f7771NZWUlFRQXvvfce06dP76jLdXFxOUg5+DyFA8isWbM488wzPWGkX/3qV5xyyilMnDiRcePGMWzYsBb3v+6667jssssYM2YM48aNY9KkSQCMHTuW8ePHM3LkyCZTbl999dWceOKJ9OzZk7lz53qWZ2RkcOmll3qOceWVVzJ+/Hg3VOTi4tIi7tTZLs3i3lcXl4MHd+psFxcXl5851XUNXX5OVym4uLi4dAFaa/LKZCxTQ6NmdVZxiwUhC7bmM/YvX/DO8qyuaiJwECmFn1sYrLvj3k8Xl5/G1twyKmvrPd8fn7eNSf/4iq835PC3j9dz6iMLuP3dNdQ3NAKQW1rNvM15fLZ2H8t3FvK7N1dSU9/Ivz/f6HWczuagSDSHhYVRUFBAYmJiswPDXNqO1pqCggLCwsIOdFNcXH421NQ38MO2Aib2jae2vpFfPjyfI4ck8/TFE8ktq+aRb7YCcMNrP1JV18DIXjG8sXQ3S3YUMiQ1mq835lDXYBtjIUEB/O20kfz5g3Xc+f5a0uPCOWZEKmPSO3cam4NCKaSnp5OVlUVeXt6BbspBQ1hYGOnp6Qe6GS4u3YaGRs2/P9tITmk1fzltFLHhwQCUVdfxwoJMXlyYSX55LWdmpDEkNZqa+ka+XJ/D7OVZzN2US11DI69cMZkbXlvBkB7RvH3NFD5fl82bS3ezNLOQWZP6cMrYXoQHB7I1t5yesWFMHpDI/K35vLtiD0pBamxYpyuFg6L6yMXFxaU5csuquenNVZx3WG9OGdur1e211izeUUhRRS2DU6MYlBJNXUMjv3tzJZ+s3keAgt4JEUzsm0BOaTU/7iqioraBXwxLITwkkE/X7CMxMpS+iRFU1jawYV8pADf+YhA3HTeUoopawkMCCQsObFP7q+sayCurITUmjJCg/Y/4t7X66KDwFFxcXFwA6hsaCQq0BWdZdR2XPreU9ftKWZJZSO+ECMb1jmNZZiHP/5DJ304bRVx4MMVVdSREhrA1t4yrX17O9rwKzzHuOWMUWUVVfLJ6H7efOIyMvvHc9cE6Fm0vIC4imDMy0jh3Ym/GpMdRXFnL95vzyC+v4c8nD2dEzxjeWrabU8emMTo9FoD4yJB2XVNYcCC9EyI65ga1gU71FJRSJwAPAYHAM1rre33W9wFeBOKsbW7TWn/a0jFdT8HF5eCnpr6BzdnlVNTWM7l/gleucN7mPB74cjN/PGEoUwfKRJC19Y08Oncrj327ldSYME4Y2YOrjhzADa+t4Mddxdx3zlju+2IT9Q2az343nQueXsz6faWMSY8lIiSQpZlFPH3xBB7+eiu7Ciu585fDGZIazX8+38T8rfk0NGpmTerDP88c3WrbX1qYySuLdvLhDdPa7A10BW31FDpNKSilAoHNwLFAFrAUmKW1Xu/Y5ingR63140qpEcCnWut+LR3XVQouLgcHWmveXbGHSf0TPJZwdV0Dz87fwVPfbaekqg6AM8an8c8zRxMWHMhHq/by+zdXooEABedM7E1JVR0LtxVQWFHLiaN6UN+o+WpDDgGWInno/HGcPKYXa/eUcPqjCxiUEsXG7DLOzEjjg5V7iQgOJCk6lF2FlTQ0ah48bxynj08DoLS6jnMeX4hS8N71RxAe0n2EfHvpDuGjScBWrfV2q0FvAKcBzuk9NRBjfY4F9nZie1xcXDqZvLIanpi3jcSoEK6fOYjGRo0GAgNEQOeWVXPDaz9y2dR+1DY08oe3V5EWF87s66aQEh3G9a+u4JuNuRw9LIUzM9LZmlvOg19vZktuGedN7M1dH65jYt8E7j93LH96fy0f/LiH+MgQZgxJ5vTxacwYkgzA8p2FPPDlZi6e0o/jR/YAYFRaLNcfNYiHv95Cn4QI/nXWGC4/oj/J0aHUN2rOeHQBI3vFcNo4O+8QExbMR7+ZhkYTGvTzVQjtoTM9hbOBE7TWV1rfLwIma61vcGzTE/gCiAcigWO01sv9HOtq4GqAPn36TGhtYjkXF5f9R2vNs/N3kBQVyrEjUokMtW3H0uo6ApUiMEAxd2Mug1KiGJwazcrdxby0MJPP1mZTWSujcG84ahBzN+VSWFHLn345nJNG9eSql5bx9cZcQoICiAwJJDk6lH3F1USEBtI/KZJF2wv52+mjuOjwvp5zfr0hh9++sZLymnom9I3npcsnebWpPdTWN3Ln+2s4eUwvjrQUiKGytp6QwACvnMTBRHcIH50DHO+jFCZprX/j2OYmqw33K6WmAM8Co7TWjc0d1w0fubh0LnM35XLZ80sBSI4O5cMbjqBnbDhZRZWc+sgCiiprCQsKpKqugeiwIK6dMZAHv9pMWHCgCP4jB3DvnA18tSGX+IhgUmPC2JhdRnxEMEWVddz4i0F8sGovWUVVfHTDNKrrG3joqy0s31nEryb34faTms63tTW3nHdWZHHtjIGeUlCX9tEdlMIU4G6t9fHW99sBtNb/dGyzDvEmdlvftwOHa61zmzuuqxRcXJqnsVHzyZp9pMWHMzY9jge+3MSSHYUEBiiumj6Ao4enAvDpmn00as3JY3rxl4/WsWJnEe9dfwRKwVmP/0BOaQ3/PHM0172ynOE9Y3jkggyueWU523PLufSIfhRX1nHEoET+OWcjOwsqyegTx/OXTiI2QgR2RU09ry3exanjepEYGcIna/YxZ002kaFB/OfsMeRX1LCnqIrxfeIP5O06pOgOSiEISTQfDexBEs0XaK3XObaZA7yptX5BKTUc+BpI0y00ylUKLocCdQ2NBLcQxqipb+CDlXspq64nPDiQytp6KmoaWLA1nyWZogRG9YphVVYJE/rGk19ew86CSsb2jiMhIpi5m/IIClA8ceEErnllOQ2NmicvmkB0aBAXPLPYE8L5YOUefvvGSs95n7gwgxNG9fR8zy6p5r0f93DxlL77HdJx6RoOuFKwGnES8CBSbvqc1voepdRfgWVa6w+tiqOngSgk6Xyr1vqLlo7pKgWX7kJDo/YkUPeHzTll3Pf5Ju44aTj9kiI9y+dtzuPal5fzu2MGc82MgQAUVtSys6CCkb1i+WTNXu77fDN7ipu+MS8pKoTfHzuEH7YV8Mnqfdz5y+FcOX0AtfWNvLxoJx+t2su23HIunNKXVxftpKK2gaAARWJkCLERIRRX1qKAb26e6Smn/GxtNjml1QzvGcOk/gn7fb0uB5ZuoRQ6A1cpuHQH9pVUccr/FnDl9P5cawnuzPwKluwo5JyJ6Z66+vKaekKtUaiLtxfSKy6MAclRlFTVceoj89lZUMnQ1Gje+/VUIkKC2JhdytmPL6SuoZGa+kZ+d8xg4sKDefDrLRRX1hESGEBtQyOj0mL44wnDGJMWR1VdAxGhgUQEB3qSpFpriivrWhwo9dLCTP7vg3VcOa0/fRMj+PMH64gODeLNa6YwoldMs/u5/DzpDiWpLi4/S3YVVPLgV5u55YSh9IwN9ywvqaxjd1Elw3vG8NLCneSX13DvnI30S4zkhFE9+N83W3lnRRaBAYqgQMX9X2xmV2ElIYEBhIcEUlJVR3Cg4ozxaazaXcKeoipuPm4ID3y5mVlPLWLygEReXriT6LAg3r52Gne+v5YHv9oCwPg+cVw4uS8rdxdzWP8ETh7dkwDLS4mlaeJVKdXqyNlfTe5LUlQoM4cmo1Cs2VPC2RN6uwrhEMf1FFwOOsqq64gMCfIITUNFTT0RIYF+Z9LNLqnm9SW7uGhKX65/ZQVLMgs5YlAiL18+GYA/vrOat6157U8f14u5m/I4rF88+eW1bM8rZ9EdR3Pkv+eSX15LaFAANfWNjE2P5dgRqZRV15NfXsvRw1P4an0O76/cw8hesVw7YyC/HNOTd5Zn8b9vtpBZUMnRw1L42+mj6BUXTmOjJquoiur6BgYmR/2kUJWLixs+cjko2VtcRc/YMI9gr61vpFFrT/x7dVYxZz+xkMiQQE4e04u7ThlBdmk1//1yCx+u2sPRw1J5eNZ4dhdVsjW3nIZGzaT+CVz87BLW7yslMiTQM7nZNxtzuXRqP+oaGnl18S4uOrwvwYEBPLdgBwCzr51CbUMjFzy9mCum9efZ+Tu45fihPL8gk0n943ng3HF+pznwl4vQWlNQUUtiZIg7/btLp+CGj1wOOt5ZnsUf3l7F4JQofnvMYI4b0YPzn1rIrsJKHj5/PGN7x/HbN1aSGBnCYf0SeHnRTooqa1maWUhpVT0zh6bw2bpsjvz3XLJLqz3HNfL5zyeP4NVFOxmYEsVTF03gN6//yAs/ZAJw8ZS+/OXUkQCEBgewp6iKCX3j0RrS48N5bsEOlILzDuvN1UcOaLFyyJ/Fr5QiKSq0426Wi8t+4noKLl3Gur0lDEmNblFg+lJaXcdS6yUkpz4yn9QY8RI27CtlbO84Vu0uJi0unD3FVQQoKWF7/arDOXxAIv/+bCOPfbuNpKhQXr1yMkN7RPPa4l28smgnZ4xPY8rARMpr6nlneRaH9U/g3Im90VqjNZ7QU25pNXtLqhmTFtskHGV46Kst/PerzYxNj+WDG6Z1xK1ycelwXE/BpVuxfGcRZz3+A3ecNIyrjxzoWa61RinFywszeWfFHh6/MIOlmUU8+NVmZgxJ5ot1OewprkIpCFSKN64eT/+kSG56ayUfr97HldP68/tjh/DKop2UVtcxvnc8hw9IBODm44bSLzGSwwck0idRJly7YHIfLpjcx6ttZnsQi90ZvUmJCSMlpuU30J01IY2Hv9nCMdbAMBeXnzOup+DSYczdJAPRjxqa0mTdhc8sZv7WfIb1iOaz3x0JwD/nbOC1RbuYNjiJOWuzAeiXGMGe4iqSo0LJKauhd3w4vz92CPM25zE2PY5LpvYDJC6/YlcRGX3iu0UCdmtuGenxEd1qqmQXFyeup+DSpXy5PodrXl6GUornLj3MM1slwOLtBR6FsDG7jE3ZZazdU8KT87YzomcMX67P4dgRqVwwuQ9XvbiM/kmRzL5uKgFKXjASHBjAaePSvM4XGKA4rF/3GUg1KCX6QDfBxaVDcD0FFwC+3ZTLD9sKuHJaf69wSU19Ax+u3Ms7K7JIjQnjkqn9yLDmqzGzaX61IYcVu4oZ1iOaugbN7sJK3r52CsN7xlBRU8/pjy6gpKqOd6+fyoz/fMvotFjW7S3hsH4JvHj5JCprG4gOlRLSzTllpEYEEFu6CdIyDtTtcHE56HBLUl08NDRqGrX2JHhr6ht4ffEuVu4uJiw4kEn9E7jt3TXU1jcSGhRAcnQo0WHBHDs8hY9W72NHfgUDkiLJK6uhrKae+88Zy5kZadz3xSYenbuNkb1iGJ0Wyy3HD6W2oZHTH11AgFI89qsMnpy3nS/WZ/PyFZM5YlASlz6/hG835XHM8BTuP3ec/xkvf3wFPrgBfrsK4vs2Xe/i4tJuXKXgAsCe4ioufnYx0WHBvHXNFHJKq7n+1RWs2VNCz9gwiivrqKprYGByJA+cO453VmRRXl3PrsJKlu0son9SJP93yghmDkmmsraBq19exqLthfRNiGB7fgWzJvXhntNHeVXmrNtbwrlPLKTCmlf/9hOHeebwycyvYPWeEq8RuU34+m/w/X1w7ssw4tROv0c/C7Z9A1u/hmP/CgFu3sKl/bg5hYOEipp6cstq6O+YMK2t7Cup4uzHf7AEfwW3zF7F/C351DY08tRFEzhuZA/yy2t4/8c9/HJMT3rGhjO2d5xn/7yyGmLDgwmx5u6JDA3iyYuQkfYxAAAgAElEQVQmct0ry6mtb+SaGQM4Z0LvJsJ9ZK9YZl83lVW7ixnfJ56hPex4e7+kSK/J3/xSJklnstd0rFIo3g2RSRAc3vq23Y2lz8LGjyEwGI65+0C3xuUgxlUK3Zzb3l3DZ2v38fIVk71KJ52UVdcxZ002H63ey4whyVw5fQAA//5sEwUVtbx//RG8+EMmby7bTe+EcN6+bAoDkqMASIoK9WzvS3J008FUUaFBvHzF5FbbPbxnDMN77uccOmXWW1mz17Rvv5pyqK8Wwe9LfS08PhWm/R6m37R/7TqQ7FsFgaEw/7/QbzoMOrr5bbd+BVE9oMeormvfoUjpPqgs6Nz7vOM76DNFjIEu4uB879xBQn55DZ+t3Ud9o+aal5fz5focCsprWJpZyNbcMtbvLeX3b67kpL+/xbL3H2Ll7iLu+XQD32/JY93eEt5fuYfLj+jPiF4x/N8pI7j9xGG8c91Uj0LothhPIWdt+/b76i54sRnPomAr1JRCSdZPa1tLVJeI8O5oKgqgZDcceYt8z1pqLc8XZefLR7+DL//c8e3obDZ+2v7fp7EBlr8I9TX7d84fHoE1s2F/wuhf3AmvnNX2fRsbRZG0lcId8OIp4iF2Ia5S6E5Ul8CTMzyCZfbyLOoaNM9eMpGIkECuemkZE/7+Fec8sZBjHviOkx7+nvXrVvFhxN/4d/DTLLl+CINTorj25eX86pnFxIYHc91MieVHhgZxzYyBpES3PBCrW1C2D1SgCMLKwrbvl78ZCrb4f0jzNsj/qqKWj/HmRTDnj20/Z1UR5G2WzwsegmeP238B1RzZlqLpPQlCoqWfaA2PToYfHm66fUU+ZC0TgWkob/Zlht2Dhjp480JY+Jj/9bWVsPJ172sC2DEPProRNnzU/nNu/Rq++BO8cwW8fakI7faQvQbKs6E8x//6fauhutT+vu5deHB0y4qhplxyatUlUGX1/bJmjt9JuOGj7kTBNti3kpUf/I+7Gi5jT1EVk/ol8Ithqcy7JZnvt+SxLa+cQSlRFFbUoUv2cNaPtxBgWdbhtYU8edFEHvpqMwFKcfaE9J/f+2zrqkTQ9j0Cdi4Qb6H/kbJcBUBQC/MDlWVDQ63sH+EzhiHXUgrVxS2fP3d98w+5P767T6qlbt0B2WslfFWUCclD234Mf2Qtg7A4SBgAe603n/UcA2GxIjBqK6AyH/as8N6vrgrqrb+8jZA6Eta+C7Mvg6u+gbQJP61dnUVFHugGKN7pf/369+H96ySMMvpsUYpK2SHGnLWyvK001MFnt0N8fxhyAix+HPJvh5Rhbdu/vka8T5DfPbqH9/qacnjmGBh0DMx6TZbtWQGNdbBnGcSc4v+4S56UIou0DAi1cnFV7TCMOgDXU+hGNFSJVZG87xtqauuprmvgyun9AQgJCuDo4alcfeRAfjEslbNHxXLO5j8QUFMCpzwoByjPpX9SJA+eP54HzhvH1EF+YusgD9SGj6Cu2v/6A4kJHQ0+Vv5nWyGk12fBJ35yAQ31dgjF7Gv+OzFKoaoVpVBb0T6ruihTFE3RDhHCIMrd8OGNIpTbQ+F2eOZoeGQCPDUDdv4A8f0gPN5WCka55W/y3tfpCe1eLMLrq7vk+5Yv29cOf3x7L2z+XD6vfgt2L/npxwRbETenFMy9/eFh2DQH/jMQ8rfa/SO7hVBjYyN8eitkLbeXrZkt9+74e2DEabKsZHfb25u/WZQYQI6f3NeuRdBQA5s+kcoxsH+r5kKMtZW2p1RbIX/QunfbwbhKoRMpqqjlrWW7qW9o3i3dsK+Uy55fwh/eWsVf31kMQJoqYM55saz9y/EcN7KH/x2XvyBW0jkvwkAr6ViR17aGrf9AXPXVb7TjarqIMsu17jEGIlMg13qld8G2ponnNbPFHX/tXLHMaixXvdyfUlgv/1t7wGrKJfzi/P7JH5oPYxlhlrUUindZbd1qr1/9Jmz8pOl+FQXeoQUnJXvkf8Ylcs1bv4SeY2WZUQrmOgp3eIervJTCEljytLQrLA62z/N/vrZSXwvz/g3vXgWr3pT/n978045pMIrY3ENfTIhu3yp462JJ8G761M47tZR/yl4tFviHv7HDT3kbICAYhp4Ecb1bPrc/jJEREOxfIWV+J+vi+sKc20QxOa/BHz++It4fQG25qxQOOhY/xXNvvs2ts1fz69dWUFPfgNaai55dzO3vinBbllnIuU8uZOXuYuZtziNSV3h2V5vm+D+uiZfnbRKhOfgYiLSmlKhog4WrNXx/v3zetXh/r67zMEohuqe45OWWoqsqsoUlQM56iQVX5sOe5d7ega+nUFclwhNaDh9pbT2MZbIPiJW39BnbOm7SXksprHsPmaMVWynU10o4qXRv0/1ePw8emdg0/AO2cj/8Ophh5Td6jpP/YbFyDcbj0Q3enolRXmFxsPkz+PovMOhYmHCJKC4jaLRuPYa+5Ut47zr7e+F2OV91Cbx3NQQEiYDL3djycdqCUa7VJf69ufzNEuaJTIbQGIjtDVu+kOWhsdJvKgpk2wUPwWNTJQHd2ADbvpbluetg1evyuSxb+phS8j8gqH2eQs46Efr9j/SvkHZ8D+kTYcat4iFkLYESS+nsXek/77X6TUgaIp9rXKVw0LB+byl/encVDZ/fQY/t7zChbzyfr8vh5rdX892WfL7fks9by3azLa+cX7+2gqSoUD6+cTrL7jyGW4+y5vdJHCwPtC9LnoYHx0hHL9wh8WaA4DB5UJwWbnNs+1osp5BoCS90N0wSLqan5AWqCkW41paJAjAhL1OlMvxU8RCcLryvUsjbBGhIGipCpzlhWFeFR7Aby3WfFc/P8yP4tLa9kq2W4AlPEOEJtudSaimzty6G7x+Q69n7owjCF34p4yecmN8xMlmEykn3wfiLZJlv+Ai8Q0gm/jz4OBEmSUPgzKeg/wyJZ+9aKOs/vRlePcv/fQC5R5/fAates8Nz5jxjZ0FwJJz/mhQErHhREvTz/uP/WJWF8NgU2Lmw+fM5k6m+Fnt9jYTneoyBy+bA1XNFQWR+D431MPJ02c70gZWvibL46EYp4d02F1JHQdpEmPsP+d3K9kkfAxkMGJPW9HdoidwNcm97jYf8Ld6h2OoS6Tf9psPAX8iypc/K/77TxHjz7aONDaJozPbO8FFloRx/zm0dF65rAVcpdDAPf72Fz5asI7Cxjvjgel66fBI3HzeEj1bt5aY3V3pq/y98ZjE5pTX866wxpMVZg6mMEBkwUwSZ1lJx8falsny3ZW0UZYrgSXCML4hM8o6FF+/2Hxv/8RXxMKb9Fgq3tU2R/FSWPgvvXiOfN30Gn/+p+W3L9kFQmFi64QnyQDgFoBGwxnoyidPMBY5j+DxwxtXvczjoRvs++1Jbbn8298W4+v6UQnWxJLZBBK4KlPEDxlOoLrGvqbFBrn3deyKwGuth6o1QV2kLas+58ySpHh4vAmvSVRBleYOe8JHjnuQ5lYJ1Xw6/DiZdDRe9J8q1zxSxbE0Iac8K+VzjuGYnxgp33hfz/Zf3w63bYcjxMPAoWPQYbPhQlIM/9q2U8N03f/e/HryT+0YpVJfA6rfFE9KNIoSTBkNcHxgww95+7PnyP3utKJe8jfCLO2Hw8fDD/yS+P+hoGHOu9J+KPMtTcIRm4/q0z1PIXQ+pI2SMgm6QczbUwzf3iPDWjdB/OsT0goSBkigHGHOOdU98QkgF26Q4oOdYCI6Qe17n8BTK9lnJ8M1tb+N+4iqFDqS4spavN+ZwwXAp6josPYzI0CCumzmIyf0TKKio5cZfDOKk0T3ZV1LNMcNTmdTfUSVTXSoDlJIGSwepyJNE1br3xGowFmjWMhng5aUUUrxzCrMv919aWZ4nx+9rvQxm69fw/vWthwC+uhteOFmO296Sy+1zJX9RuB2+/QcsfESsK3+U7bPdeuMpON3n5pTCzh/kf1SPpjmF/E0iEM221cWiRHxr4r2UQq4o5b0teArGuk21Bi8lDoTkYXINNeW2UmiolRBDQ41Yg3usaVpGny3tMvkOz7nzICLR/3QWYbHST4xHEJHorRRM+Ch5GJz0H4iypjEPiZDrN95hSZYIs6xmLM8f/md/rimz7sFmCduERIp3CjDhUlFg/aaLUPVnbZvw1s75zYcsy3PsMKhRCgsfg3evhKVPW9c0xN6+7xGAgqBw6D1ZfvecdeI9gAjkmbfJb91YJxZ4nDWPVtFOO3xkiO3ddk+hulSuNWW4eC8Ay5+HL/8Pvvu3eFdhsZA+yW5LQ60YDSNOk3YbD3Tvj/LsZa+W7z1GQ0hU00SzM6zaybhKoR1orVm0vYC7P1zH7sJKAD5YuYf7v9jEM99v94wrOHuwPMzJoZLUCgxQ/O+C8dz5y+Gce1hvrp85kCGpUdx24jARPJvmiCVZUwZhMXbnLd5lx8ILtooLDfZglkQfT8GpFMpz/JdW1pRIqKnXOBFIH/8OVr4qlp6hYBv8+Kr3fkueFsG29h0ZMWtY8RKs/5AWMQnV7+63LaQ1s/1v63xYIxLFInZ6MyU+SqHnGBFKueskpJE0uKmnUJIFsWn2SOeqInj9fPjqL97b1do5HcpzJRdQmQ9RqSJIaiu9tzfKx4wuTh4KiYPkc+F2b4/EeDK6QcIbgSGQMkLaazwZQ0UeRDRTORYWC2gRYCoQemV4W49VRWJY+JvKI2mwnZg2+Sd/IZ2ybBHgJrnt9BSSBntvO/wU+ONOOP4f8t3X6wHpu8GR4vl910yIqTxXFFlIlK0UTD9f/oL8T3ScOyJBlFzPMaI8e4yWMQubP5P+3WOslHUOPl6O2WeKPbli7nr5bbw8hd4ieHd8D/cP984DfXoLzL7C/m76cI8xYghMvk7auOhR8c5u2w2/+dFWnP2my/+EAeL9JQ6yiybeu1YMrew18jwmDRWl60w0V5fY/T6ml//714G4SqEFqmq9B8rc+9lGzn9qES/8kMmT321jY3Ypv31jJY/M3crfP9nA3z/ZwNDUaPoEWxaiESJf3U3Kjo+4cvoAQoMCGd4zhi9+P4NBKVFiub1+vljTNWVSmxxnvRmsKNNWCllLpeICbKHs9BSifDyF2gr/1S3VJaJ4gsPloa+z2ui0Nhc/CR9c7y1c66okrh2eYCVVLRY8BEueavlGGot55SuAEmG41mcUaV2VWE0F2+xYb3gCoOU+GIx1X10sCcbgcLHyQB7y6B7NKIXe8kCCLbB3LfLezqkUKvLsh3/0OdIOX9fdeAqDjpH/ycNspVCw1fv+73SEt3YvFgUSGCzWZhNPId//VB1gKQWkdDMsVurq87fYVTVVhSIwlWq6b3w/UQZOL82fEM+yPJkhJ8j/mnLJMeRvEaHVpE0xMh4iNMb22Jzkb4GkQXDEjVJJ5UzaN9TbuZnoHtL3i3dKv89ZKwaCboTYPuLtODnnBTjrGfl85M0i1Ne8DX2nQqA1BOuMJ+Dyz2V8i3mujLfk6ymgZYxA2V67jBTk2Vs7264yMvunW3PLnXivhNQyLhblGBYDkY4paYxSMGNXkofKPWmok36Su04GtiUPg6AQh6dgjBBtD770HQ/RCbhKoRm+3pDDuL9+wbzNImiraht4bdEujh+ZyvUD8/li1U5eX7yL4EDFsj8dw4uXT2JIahRXHTkAZVw9I3BXvi5hIH8UWXXZZTlNlULWMjuuuPkL+R8cYR83vr99nMhkCR001Mv32nL/sfPqUluwTLoKJl4urrUzWWmE347v5H9DnVi4odFiGW6aY1fnVBa2PjVBdYlYtSBu/+Rr5GHYt0oEwpMz4J4e8NRMEQ59psi2ZgBaoaO6ptQ6V1URhFuT9xnlGNPLVgpOhVOSBbHpkqcA++Eu2SUW4Rd/Fs/FGV83SkEFwCgrIetUnGB7Yj3HwVnPwmFX2W0p2GYrQxClEBAE0Zallzpa/qcMF8vYhGjMuU0oxRfz2xXtlOtPGiphKaM4q4otZeqHhP52WwBSRorA850qY89yaWvfqfK9tkwEZV1FU0/BEBAoI659FS3Ib504CA7/tbT305tF4NXXwP1D4MeXxVOIShUvuXiX7SWc+bT8Bs7QkSGut/2s9DkcjvidfDZCGKQPmbmJQiLlvpo2+noKANu/lf+Z8+11Jn+z8BH5v3uxCHBjZAAcdiWc+j//cxRFp8Lka+3cR9JgMUzyt0huCeSae1h9IjTK8hQc/TFnvYTKTB/uRFyl4IfS6jr+9N5aauobeWyuJA2/WJ9NWU0914wO5NY9N3Jk7Xe8vGgnRw9LJTEqVN4n/PsZnD0h3Z7QzQhvZ3ywycksIVeZL0I8NEY6RUSi3UHBFtAmVBGRaAtFsISIFm+ioV5KIX2Vgtb2OUA66cn/heThMhDIVOWYRKlJShoFEBQGo86UzrrlS9m+ulgEa0vzv1SXSFIyOAIyLpKKIZBKKFOpMexkOPMZuHmLKCuwhZtpT3w/7/CReSiNII7uIbHlhho7Od1QL+2LTbfvl4nfgoTOfnhYEoHOh7A8V9qVNEQe1oAg21rzbJMjD2potOQHolPFmg2PF+XmvP9VRWKN9j5MvqeOlP8p1n+nwqnIb10pFO+S8yQP896/stBbWDmJ7yf/Tdx99NnST9a87f377VkmeRITwqopt4+f5Ec4G/pMkXvkHNNRXyNtTRwkVvBJ/5Hva9+R/FBlgRQ/1FVaSqGPCMzlL4ji7D8djv+nhGhaY+btsu34XzW/TVwf28iIdoRijLcJUpnnLFyoLhHFtOZtCdvtXiIKsD2c+C8xqEDuYWOdeE0AMeny3yiFkMimMiN3nXjQ/jzADsZVCk60pn73cu58by25ZdWcNq4Xi3cUsnZPCbOXZ5EeH864oEwAeodU0KgRJeCLKausq7Jr35ur8jCxy4p8y1OwBHZcX1sIJQ6SxDOI8ATv0BF4j1Uwwq261Pthry0XVzzMZ/bS5CFy/JJd0hFNFcaOebK/UQrB4ZKgDo+HLZ+L4NWNIoRNaMuwZraEoYwiSh4mAn/MeWK9hceLgDfXP+pMqcwwiVGACEu4FWyXhzJlhCPRXNzUUzDhI7BDSOXZ4uXEptvC0sRzA4JkmgpzPPMQRvcSpbBrkTz8gcHyG/h6CmXZogh8H9TIZLH2TfjIhCkS+tvJbo9SGC7/c6xBevW1kvdpTSnUV4nVaCxo4+lVFdr3zRfjWRqBN+5Xcu8+uB5eOlUEeGMj7PlR2hlqTZxYW24r5paUQm9r9lzn2IvCHYC2w2r9psl9L9phPycmHBOVKlZ9XaUURJjZbA+/VsbjtEZQCEy5vnmlCHa+Drw9hVjrOVaBMPU3VpXfTum/1SVWCFHBe9dIvzfXuj+Ye2gGNc68Tf6bNw2GRIq8qKsUQwxEkUZ3fj4BXKXgoaa+gTXzPybo2V+Qtfpbbjp2CH89bRSRIYFc+vxS5m/N56yMdAIsK3NizyDS48OZMdTPw2vCR7UVdu17bTNKwVi+lYWWFW/Nd2LcYhVoj1iOSoV0y9L0VQpGmFbkOQYoNdgCHWwhFeqjFEycOG+zXSliqkkKt9sKKThcYrXx/UWY+6sKMix5GhY/IR27sV6EWWiULUBj0uUYxqvy1+HDHeGjsDh5cFv0FHo2VQomtBWbbrU/VCz84AixbOur7eOZ+5bQX8Iq1cV2KCJ1ZNNBR+U54pn4EplsKflSsTqNFRrfX0JR435lC5W4vtIWk2w2I1pbyymAKMWwWLluo7Cc98WX8HjJw1QVShujU+H6xXDCv8QT/eQmCR3Wlkm8PMTqizXlVr5KNa+szD0CexQ62MokUSZmJCBQfuuSrKaD+qJSJG918xa4bacYCh2NSTYHR9rPGkjOISZNQmbGos+cL4aabhArftJVdujtpygFoyB3L5H+M/5CuOY7CYGB3PfaCpEZsQ6jM6Zn02N1Aoe0Urjl7VX898vNVNbWc/qjP/DiZ+JW/2V8OTf8YjCx4cHcesIwhvWI5spp/WUeIsvKnJoWzNd/mOF5xSUgFlhFgd3Z6yptZdCW8FG1QymYzhubbj9sCQNEsCQMsOPuBvOwlud5KyBnCMN8dgoWsBNgeRtlllGAw6xqix3z7IE5xmqJSpHzOMMEJT5KoSjTmsqhxP85Y3rJtTsHq/licgp1lSLQYtLEiq4p8xZ+qSNFeSYPtYW0+Q08SsESzMa7iE2372FUqlxLrRXXj+8n3g9YpY/W/7K9dlkwiFKITm3ablMJVl0qXpmpGEnoL+c9/TE7aRoQIF6USTabYoHWPAWw48tJQ+xxLZWFzecUlPLuVyDW9eHXyrTcP74iA+zAx1MoE08qLFba2xwRCSLwcxyJc49SGGQvi023lILVZ5R1zCjL64pK6bwwifEUons0PcdZz1jh1GFyD3f+4N1/j7xFlKqpINpfwuOkhBwt+QWl7Eov8K4+ciqFLihHhUN4ltTiylpmr8hCa/h8XTabc8r417hI2ACjlf3gXzK1H5dM7WfvaHkKqqaM0CBHHXldNbx0mrwprLpYLNL6ajuB6JxeQGv74fINH5nQjvEUEgbY7mbCANnvxh+bXpAnfOSrFMps69l4Cr7ho4gEiR/nb7LyIEoqTwJDRbj3Gi/bmTLHyGSpFHLO3uj0FGor7XJNU07qqxRi0yR2ba7fX4cPjZFQQ2O9tNE8ICVZohSMUIzvCzetF6HSWC/LM7+X2LIJhcVYo8XD40WYx/aWahHdKL/N8hfkvwr0tuxjrf36W4OldnxnW71lOTLQ0JfIFCifZ1VIxdjndhYGOEkZIYPFoHWl4PTyjIJLHia5kdpyiVX7zhDrJL6f9GHTJsPMO6QkctGjch8TB0tfCwi2xlwUtxyWMaSOsENhIMnUyBTv3z82XUJGpXtFyKYMk+9dUFnjUYr++ptJrIOE9Yp22LmpsDi5r2c+KQrypyqtpCES6vUXjjNKITjc+3fqgnJUOIQ9hYXbCtAaBqdEsTG7jJuOHcKY+DpZudfPfDQgQsBUnDirRUCEZ2OdXa5pKj3MQ24E9evnw39HSnilrsqOxZfstit8AOL62cdJGiLWVEvWSVis1L5X5HrnL5xlkcbqCfUR0CCCJW+zPMRxvaVDhkSIgPfnKVTke+cRnKEA5zQFZmyFryKK6SX7F+0QheRvSmylbEEUHm8rypx1cq+cQspYfoHBotA2zZGqqZIsK2xiWb1GkcT1lr+j/yyjheur5JpCo+zRw/2OsI+fOFAEiUn411WJ1xLlz1NIFmFSWSi/i9NT8EfqCPndKvIdU1w0Ez4KDLLDOuZakodI/zLCuCXhbZLNzsQqiAKY+Uf4/Tq4dr5ttIRa5ZHOaq+WSB0pxkVDnfS3jR/ZYRFDbJr0l5Ldcm9GnC73tgsqa7w8hZYweSFTeWSufeiJMG7WT2+HqeLyV80VGiXGTVWRyAOjUF1PoXOZvzWfyJBA3rl+Ksszi5gxJBk+sB7Iokx5oH0tLpOgDAxpWtljKhq0VcGTOEjCMR6lUCFJvNwNIgyds0uGxdnKxjd8lDBAap4v+diuTvCHUnYs2xmqqnGURdY04ymAPMzLXxCBbsJVwZHiOZgqqmAr5BGZ4j0RW2ist6fgnP7YbOP7wBsLKGtZy7HS8AS5h+HxMl2A2QeaF37DT5YR1DsX2OWonuNZ+/hbVpIlNeLGSneWNiol37d/K57evH/LcjOi1YkR6IXbZXDV8FMkz+Svxh/sZHPuBoen0IxSABEStWXengLYYwSaCx+BrZhi/RRIgPQ/Z6w9JFoUTlUbPYWUkTJ6t2CrTM9eXQLT/+C9TWy6GFB7V8q1H36dxOtbCk11FLG9xftp7voNkclSbNBc+POnYjwEf0ohxDJg6qvFawhPkHZ0kVI4ZD2FH7YVMHlAIjFhwRw1LEVePl+Rb8c39/oJ0Zg3YKVNaKoUjPAzZXwmxOCZf0iLNVpTKlU2gaEyiyOI4DAYKz5xkCQAx1pWSb8j/AtzJ2auIN/wkaGlDn7kzfKglGfbHTUkQhSMScaaEZrGks7baFUFDfP2FJyDzUwMvklOwVIKBVuahjKcRFiDgMLjRUmHxUodvVnmj4FHS6noho/tgWsGT06hj2OZUQq75SHsN11CS0NP9D5u/+li0b97Ncx/QKa2HnJc0/N78jvZEu6J7yvz9gc2Y4OljJD/uetFKQSGNC0GcGLupSenYCkbU3/fJk+hhXvuJDTKzuG0xZJPta5l5wJY+CgMOVFGzzsxv0fZXvEUjIfXFQSFwCUfwpQbWt7OeHtGSXe0FzP4WOlnaRObrguJ9P5sfk830dx57C2uYkd+BVMHJnqvqMizfyR/SiFvs1TNxKY3HS1csFUEWMZFEgc3oR7fufmrSyXk0HeqPaujM8lkrDSlJAHYksXoS0S8xPlrmwkfGUXmT+BEpcjD0vtwmWET7IFynnEKjpwCSKWKpyrIMYDNn1LwPadTEbRkARlvLTxe7knCQHukcXPhjJAIGc+x6g0JhzmtQmf4yODrKUQkyEAkX0U28GjxnjZ+DEN/KTX3/nDmA9piYUalShty19tjFFqKWZtjmnZHJklobYs1UrilnELfaXDUnfZv3Boh1kCqtuYUkoZI/59zmxgUR93RdJsDECf3ou9U27BpDrPeJMo73FMYDJd+7L8PG08BrOlBrPvur9KtE+hUpaCUOkEptUkptVUpdVsz25yrlFqvlFqnlHqtM9tj+HaTaP8jfN9MVpEvFn7CQPvl6E4q80V4hsb4CR9tl/1m3AZXfmXHmp3vOCjPkbBLWKw9RS7IPC0Gp+veXsITxKKracFTCAjyPy8OiPC84nN7gFxIpDXy1MdTiLTKXwu2iQCKSfMewFaU6b0N+K8+8ve5yTWZnIIl6BIH2pVBLQmp4/4GfSbLtiY849zHX/iortLbSvMlNg1u3w137JVXLDb3alAvpdCKdweiAFJGyEjrXYtsa745PEohzt7/4g/khTERSS17XkEhMOOWlq/TicdTKG5eCXsdP1SS1I11UsOwO9AAABoqSURBVGXV0094zavM8gAohbYQ6VQKqmXPraNxKoWQSFH6Uany23UBnZZTUEoFAo8CxwJZwFKl1Ida6/WObQYDtwNHaK2LlFIp/o/WcWiteW3JToamRjOsR7RzhQj9yCQY9ktrJs+tMmeLobJAvIHQ6KaJ5oJtMp1vcJhU65iEpHM+IhNiCYsVj+TLP8vxnK78T1IK8Vb4yJlTcCaardHMba2cCI6w3mFQZX8He0yEbhBhHZNmD2CLTLIrlrZ8ISGUwFBboRjMyN+qorZ7CmDnFZzL/JEwAC58R0penUJ68DGS83AKTmcM3vlA+sPfzKW+OL27tgqTlBH2bKBH/7nlbX3DRyDXO+v1tp2rPYREiYfsm9hviZl/lD445lz/68NibQ+kJQV2IDFGTf6W1ktxOxrf8NH0m2HcBV12+s680knAVq31dq11LfAGcJrPNlcBj2qtiwC01u14Oe7+sXJ3MWv3lHLhlL4op3CsLReLODJZRjQGhsrkWE4qC0WIh8VIMs1U5dRWSnw00SGwgq0fttyhFMxArVBrArGoVHkoIhxhrLZYls0RYTyFMjl/cGTT8FF73GBP9ZFjmgsQYRQQZJ/TKLV5/5IcSlGm3AsjRJq7JjO8v0VPwUcpOO9xW+K8MT29Y/lpE8SCdQp3p7ALbUUptIWwWElmQtt/T+PNJA6ypwFp6fjQNsv9pxIabffbtsbVR54hA7KaQynbW+i2noKl2IsyOz501BqhPp5C8hD/pc+dRGcqhTTAOUF5lrXMyRBgiFJqgVJqkVLqBH8HUkpdrZRappRalpfXxvcQN8PLi3YSFRrEGeN9mmJi/xFJYgkfdoW8mNwZHzcDg4z1Z7wFEzd3WrFmcJJz+mqnp6AUHPtXUUAR+2FZ+iM8QSy6sr3SmcJ8wlxmhtS2Ehzpk2i2wk4BAbb1HZ4gr3scfY6U2f5vgoRh4vvZD1ZzD5URCC0JhuY8heamh94fQiJtId7WsEpLmEowaLsgNcnYab9v3RtJGizeVWteTUcQEmVX1HWkEjJKoYsqatqNlzfcBcrXia+n0MV0plLwF6PwnTUtCBgMzARmAc8opZr8Alrrp7TWE7XWE5OTW0kQtcKX63M4aXQPokJ9ImfOVyACjDxTOoSZfsC8EjLCoRSqSyShtuBB+e7lKYR7Hxe8lQLIhHRjzpVOZ6qefmr4CGTSrtCoprkPEz5qKyERMjNmXZUM6nJWiJj7FJEgoaGznoFfL7bLI5OH2squNaXQkmDoM1WqNExFlHmHhEk8dwTO8RAdJWiNQmzr/U6bIOMDxrUwmZth4hUygLELJkfzslrbGj5qC3F95F535DE7kpAoh2fcxZ6Cb06hi2k1p6CUugF41YR42kEW4Bwhkw74vsE8C1ikta4DdiilNiFKwk+W96dTXddAWXU9fRP93GjPnDNWKMczxN/n5dkRCba1nbdRXpFncM5HZMJHznECppbft5MFBMrDUVv500rzjFVdslssncBQ8WY++q39GkrfOZNaIjjCTjT7WuXGknI+1MlD4fLPpDqo13h54T00/1ANPk48qZYeuqRBUqVhCI+3ZojtYGESHi9FAR2mFIyn0A4l3NI4FCcBARDQQV5SazjvR0eWZU7/gxheXaHY9gfj7ZXs7ppBdU6ciiC4GyoFoAeSJF4BPAd8rnVL8yR7WAoMVkr1B/YA5wO+2ZL3EQ/hBaVUEhJO2k4nkVcmVStJUVYWf9171gvXtV0BZB5m88N4Xp5tjd4NT7CteeNFTL5WhK3TyncK0YhE2d/M8+PPeoxIAtVeveuDib+X50iYJThMvAPz/oOQyHbmFCIlgVxT1lQpOD0FJwGB9myPEa1Yy8NOkr/2kjy8+Zr//cVcR0dZZh6l0MVWZkfj7NMdqYhj01sfQHagMUqhq8NHwRFIoEV3T09Ba32nUurPwHHAZcAjSqm3gGe11tta2K/e8jI+BwKB57TW65RSfwWWaa0/tNYdp5RaDzQAt2itC5o75k+loEJeJpIUZZUSzrlNrOe6SkixxiUYQWYqbcxoXs87cR3hIzOJWcYl9qAdg9kfrAnXCpqGj5xEJtkv3NhffBOmweFitRuFVtPO8JG5hqoie4yCp72OnEJztJZT2F9Of6xjjweO8FFHKYV2ho+6K05PoauF44HmQCl2pazqrLLuqRQAtNZaKZUNZAP1QDwwWyn1pdb61hb2+xT41GfZ/zmPC9xk/XU6+R5PIVReX1iRC9Nuknfmmnf8mgSxeRjMQDAzI2hEor3OeAr+LJ6AAIlJ1leLwAkIkh85MKRpeSZI3NxMub2/OK32kEhpp+97DtoTzjD3orKgaZtN+KilgVKt5RT2FzMFSEdilMJPyek4SegvirS7xszbigmjBoZ4GzqHAlHtLBboSEIiu69SUErdCFwC5APPINZ8nVIqANgCNKsUuhv55ZZSiA6VBLBulImxRp4Oix7zri8PCrEEueUpOMNHJpRSsEWmpWhO0AZHWPOXRMmPW13SvIA86vaffoHOzhsS1XSaZTNrZ1sxyq+ywE66GUxyOLKFoSUeT+FnYC13tKcw/mIZAe37XuGfG6YPhMV13/h/Z3EgQ4ChUVAV0nXTfzhoS/VREnCm1vp4rfXbVlIYrXUjcHKntq6DMUohMTLEnto5uofUVUPTKSXMa/HAJ3xkWZON9S3PIWMETEikPbNlZ4YTAoPsuZNCoux2RqbIXCvQvg5uLMOK/KZW4vBT4bxXZd6j5jDjLw6EpdVeTGiko5RCUEjzs6L+nDB96Ofu8ewPkX6KKbqKkMgD4iVA25TCp4Bn4nylVLRSajKA1npDs3t1Q/LLa4kODSIsOFCmwQaZTyRtokyQ5ju6MjhSSjJBwkfBEdbbu4LtGHtLyTLjUTh/4M62OsyrGE1JKshAOfNCmf0JH1UVNQ0fBYXIbKQtYab6+DkIFJMbCemg8NHBgvEUDrV8ArR/rElHEhJ1QCqPoG1K4XHA+S7JCmvZz4788hoJHYHtKUSlSPz/kg/k5dpOzCyh0PSNVka4tqgULKEaGu1QCp0cSvEIN4enkDoShhwvL2P3N9Vzc3g6pW6aaG4LKcPhjCdl2pDuTnw/GSvi701qhzImp/BzUOwdTepI6ffO8UddRUjUAQs9tiXRrJwlqFrrRqXUz/I9DPnlNXY5qhlpbKxZf/X7ZkI4sF6I7lAKodFyjJbmbjFKoSs9BWds3Cig1FGivK5b0L5jOTulv+R4ayglA/R+Dgz8BfxuTfcvk+xqPP32EPQUUkfAndkH5tyTr/F+3W0X0hbhvt1KNhvv4Ho6cSxBZ1JQXsvAZMvyKcuRjt6SsDMvmQFrMjynUjCeQu+m+xlCHEohtAtyCmC3MTRaXngS19f7DWLtwem+7o+n8HPCOR+Pi03IIZxTOJCYmYoPAG0JH10LTEUGoGUBk4GrO7NRnYWEj4ynkN36K/nMu1KhafjICPm2hI9M9RF0gafgGISVNAh+t9p+jWV78fIUDnKl4OKfwCAYfa73VO8uBzVtGbyWi4xG/llT19BIUWUdF+z5B6w+UzyFqBbKKUGEYrEzfORnNtOWqo8OaPioA6ZrCHaVggtw1tMHugUuXUhbximEAVcAIwFPrEVrfXkntqvDKayoJYpKRuR9CstLxVPofXjLO4VYLy1vbJCXjHiFj2IBBdEtzPDpDB956r07u/rIET76qThL4nzHKbi4uByUtCV89DIy/9HxwDxkYruyFvfohuSX1zBEWa+MzFoinkJrlSbB1iyhVcWA9g4f/X97dx9rWVXecfz7Y4ZBFMQXBkoZZIYyYqlaISMl1pdWpgqoM62aOoRGYkmIRqrW2khDS401bcBWGytRx0iLlhbU1nRq8C3Ul5gWZERARkRHCjJlhAFFBJQ3n/6x99keLvfl3GHOy8z5fpKTs/c6+5773HXOPc9Za+219uHPa86qme9qSI/oPmqTwrDHFHpdYruiD3jJ3r9YUnpnBpol7XYGSQpHVtVfAPdW1YXAy4ABl3OcHHfc8wBH7dVe3uHhB5qF3ha65mnvlNTebOb+lsIxp8KGi+b/+XGMKRz1Mjjt07vuNLpea2dPH2iWBAyWFB5s7+9K8kzgAGDl0CIakjt+cj9H5RZ+vvRxdJd6WHCgeb8mgfTmNPSPKQxi1slrQ24pLFkKq16w656vdwaSYwrSVBjklNSNSZ4M/DmwCdgPWOAispPnznvv51nZRh30TKgHm9VDFxpo7n3Tv+v7zf3MZTAW0r/MRa/baHdbSrnXUjApSFNh3qTQLnp3d3uBna8Ai7hCy2RZ+4yDOPSrt7LXweuaQdjt1wzQfdR+qPeSwuMXmRRWPLdZ/XT/Q5q1h044p5k7sDvpJUYHmqWpMG9SaGcvnwl8fETxDM0R+94HD9zVTF0/4kXNldYWWrCslxR+dHNzv9iWwqHH/uKqYXs/rrna1O5mmd1H0jQZZEzhC0neluSwJE/p3YYe2a52+5bm/qBfbW6v3LjwsrT9LYV9nghL9xlujJNob7uPpGkyyJhCbz7CG/vKit2tK6l3QZyDF9F9040p3Lz4QeY9hWcfSVNlkBnNe8Ci8MCqF8JL/2ZxXUC9lsLdt8KKNcOJa9J1Zx85piBNg0FmNL92tvKq+uiuD2eIfulZzW0xuhm9tfhB5j2FLQVpqgzSffTcvu3HAScAVwG7V1LYGf1r/zxhWruPbClI02SQ7qM/6t9PcgDN0hd7vv5F5aa1pdB1H+3m1xqWNJBBzj6a6T5g9a4OZCL1Lx292NNR9xRPPKRJDLti1VVJE2+QMYX/pDnbCJokcjR7wLyFgfT3o09rS+E5p8KRa+0+kqbEIGMKf9u3/RBwc1VtG1I8k2Wvvdqrr907vS2FJXt7RTJpigySFL4PbK+qnwEk2TfJyqq6aaiRTYpl7fLZ0zpPQdJUGWRM4RPAz/v2H27LpkPv7JtpbSlImiqDJIWlVfVAb6fdnufKMnuY3tk30zqmIGmqDJIUdiRZ19tJsh64Y3ghTZhlT2jPvvGUTEl7vkHGFF4PXJTk/e3+NmDWWc57pGWPn96Ja5KmziCT174HHJ9kPyBVtdtdn/kx+eVjF77ugiTtIRbsPkry10meVFX3VNVPkjw5ybtGEdxEWPuX8MoPjTsKSRqJQcYUTqqqu3o77VXYTh5eSJKkcRkkKSxJ0l1dJsm+wBRebUaS9nyDDDT/M3BZkn9s918HXDi8kCRJ4zLIQPN5Sa4F1gIBPgscPuzAJEmjN+gqqT+gmdX8KprrKVw/yA8lOTHJDUm2JjlrnuNenaSSTOnlzSRpMszZUkjydGADcApwJ3AJzSmpvz3IEydZApwP/A7N3IYrk2yqqm/NOG5/4E3AFTv1F0iSdpn5WgrfpmkVvKKqnl9V/0Cz7tGgjgO2VtWN7dIYFwPrZznur4DzgJ8t4rklSUMwX1J4FU230ReTfDjJCTRjCoM6FLilb39bW9ZJcgxwWFV9er4nSnJGks1JNu/YsWMRIUiSFmPOpFBVn6qq1wDPAL4E/DFwcJIPJHnJAM89WwKp7sFkL+C9wJ8s9ERVtbGq1lTVmuXLlw/wqyVJO2PBgeaqureqLqqqlwMrgKuBOQeN+2wDDuvbXwHc2re/P/BM4EtJbgKOBzY52CxJ47OoazRX1Q+r6kNV9eIBDr8SWJ1kVZJlNIPWm/qe68dVdWBVrayqlcDlwLqq2ryYmCRJu86iksJiVNVDwJnA52hOYf14VW1J8s7+pbglSZNjkBnNO62qLgUunVF2zhzH/tYwY5EkLWxoLQVJ0u7HpCBJ6pgUJEkdk4IkqWNSkCR1TAqSpI5JQZLUMSlIkjomBUlSx6QgSeqYFCRJHZOCJKljUpAkdUwKkqSOSUGS1DEpSJI6JgVJUsekIEnqmBQkSR2TgiSpY1KQJHVMCpKkjklBktQxKUiSOiYFSVLHpCBJ6pgUJEkdk4IkqWNSkCR1TAqSpI5JQZLUMSlIkjomBUlSx6QgSeoMNSkkOTHJDUm2JjlrlsffmuRbSa5NclmSw4cZjyRpfkNLCkmWAOcDJwFHA6ckOXrGYd8A1lTVs4FPAucNKx5J0sKG2VI4DthaVTdW1QPAxcD6/gOq6otVdV+7ezmwYojxSJIWMMykcChwS9/+trZsLqcDn5ntgSRnJNmcZPOOHTt2YYiSpH7DTAqZpaxmPTD5A2AN8O7ZHq+qjVW1pqrWLF++fBeGKEnqt3SIz70NOKxvfwVw68yDkqwFzgZeVFX3DzEeSdIChtlSuBJYnWRVkmXABmBT/wFJjgE+BKyrqtuHGIskaQBDSwpV9RBwJvA54Hrg41W1Jck7k6xrD3s3sB/wiSRXJ9k0x9NJkkZgmN1HVNWlwKUzys7p2147zN8vSVocZzRLkjomBUlSx6QgSeqYFCRJHZOCJKljUpAkdUwKkqSOSUGS1DEpSJI6JgVJUsekIEnqmBQkSR2TgiSpY1KQJHVMCpKkjklBktQxKUiSOiYFSVLHpCBJ6pgUJEkdk4IkqWNSkCR1TAqSpI5JQZLUMSlIkjomBUlSx6QgSeqYFCRJHZOCJKljUpAkdUwKkqSOSUGS1DEpSJI6JgVJUsekIEnqDDUpJDkxyQ1JtiY5a5bH90lySfv4FUlWDjMeSdL8hpYUkiwBzgdOAo4GTkly9IzDTgd+VFVHAu8Fzh1WPJKkhQ2zpXAcsLWqbqyqB4CLgfUzjlkPXNhufxI4IUmGGJMkaR5Lh/jchwK39O1vA35jrmOq6qEkPwaeCtzRf1CSM4Az2t17ktywkzEdOPO5J8ikxmZci2Ncizepse1pcR0+yEHDTAqzfeOvnTiGqtoIbHzMASWbq2rNY32eYZjU2IxrcYxr8SY1tmmNa5jdR9uAw/r2VwC3znVMkqXAAcAPhxiTJGkew0wKVwKrk6xKsgzYAGyaccwm4LR2+9XAf1XVo1oKkqTRGFr3UTtGcCbwOWAJcEFVbUnyTmBzVW0CPgJ8LMlWmhbChmHF03rMXVBDNKmxGdfiGNfiTWpsUxlX/GIuSepxRrMkqWNSkCR1piYpLLTkxgjjOCzJF5Ncn2RLkje35e9I8n9Jrm5vJ48htpuSfLP9/Zvbsqck+UKS77b3Tx5xTEf11cnVSe5O8pZx1VeSC5LcnuS6vrJZ6yiN97XvuWuTHDviuN6d5Nvt7/5Ukie15SuT/LSv7j444rjmfO2S/FlbXzckeemw4pontkv64ropydVt+UjqbJ7Ph9G9x6pqj7/RDHR/DzgCWAZcAxw9plgOAY5tt/cHvkOzDMg7gLeNuZ5uAg6cUXYecFa7fRZw7phfxx/QTMIZS30BLwSOBa5bqI6Ak4HP0MzHOR64YsRxvQRY2m6f2xfXyv7jxlBfs7527f/BNcA+wKr2f3bJKGOb8fjfAeeMss7m+XwY2XtsWloKgyy5MRJVtb2qrmq3fwJcTzOze1L1L0VyIfC7Y4zlBOB7VXXzuAKoqq/w6Lk0c9XReuCj1bgceFKSQ0YVV1V9vqoeancvp5krNFJz1Ndc1gMXV9X9VfW/wFaa/92Rx9Yut/P7wL8O6/fPEdNcnw8je49NS1KYbcmNsX8Qp1kV9hjgirbozLYJeMGou2laBXw+ydfTLC0CcHBVbYfmDQscNIa4ejbwyH/ScddXz1x1NEnvuz+k+UbZsyrJN5J8OckLxhDPbK/dJNXXC4Dbquq7fWUjrbMZnw8je49NS1IYaDmNUUqyH/BvwFuq6m7gA8CvAM8BttM0XUftN6vqWJqVbd+Y5IVjiGFWaSZArgM+0RZNQn0tZCLed0nOBh4CLmqLtgNPq6pjgLcC/5LkiSMMaa7XbiLqq3UKj/wCMtI6m+XzYc5DZyl7THU2LUlhkCU3RibJ3jQv+EVV9e8AVXVbVT1cVT8HPswQm81zqapb2/vbgU+1MdzWa46297ePOq7WScBVVXVbG+PY66vPXHU09vddktOAlwOnVtsJ3XbP3Nluf52m7/7po4ppntdu7PUF3ZI7rwQu6ZWNss5m+3xghO+xaUkKgyy5MRJtX+VHgOur6j195f39gL8HXDfzZ4cc1xOS7N/bphmkvI5HLkVyGvAfo4yrzyO+uY27vmaYq442Aa9tzxA5HvhxrwtgFJKcCLwdWFdV9/WVL09zvROSHAGsBm4cYVxzvXabgA1pLr61qo3ra6OKq89a4NtVta1XMKo6m+vzgVG+x4Y9mj4pN5pR+u/QZPizxxjH82mad9cCV7e3k4GPAd9syzcBh4w4riNozvy4BtjSqyOapcwvA77b3j9lDHX2eOBO4IC+srHUF01i2g48SPMt7fS56oimaX9++577JrBmxHFtpelv7r3PPtge+6r2Nb4GuAp4xYjjmvO1A85u6+sG4KRRv5Zt+T8Br59x7EjqbJ7Ph5G9x1zmQpLUmZbuI0nSAEwKkqSOSUGS1DEpSJI6JgVJUsekIM2Q5OE8cmXWXbaqbrva5jjnVEjzGtrlOKXd2E+r6jnjDkIaB1sK0oDa9fXPTfK19nZkW354ksvaBd4uS/K0tvzgNNcxuKa9Pa99qiVJPtyul//5JPuO7Y+SZjApSI+274zuo9f0PXZ3VR0HvB/4+7bs/TTLFz+bZtG597Xl7wO+XFW/TrNu/5a2fDVwflX9GnAXzWxZaSI4o1maIck9VbXfLOU3AS+uqhvbRct+UFVPTXIHzVIND7bl26vqwCQ7gBVVdX/fc6wEvlBVq9v9twN7V9W7hv+XSQuzpSAtTs2xPdcxs7m/b/thHNvTBDEpSIvzmr77/2m3/5tm5V2AU4GvttuXAW8ASLJkxNcskHaK31CkR9s37QXbW5+tqt5pqfskuYLmC9UpbdmbgAuS/CmwA3hdW/5mYGOS02laBG+gWZVTmliOKUgDascU1lTVHeOORRoWu48kSR1bCpKkji0FSVLHpCBJ6pgUJEkdk4IkqWNSkCR1/h855cLtjJZ/DQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsvXecJFXVPv6cTtOT087uzM7mvAtL2kVAcpCsgCKoKAoiX9TXnBD9Kb6vAQMGRMSAAREEAQURRCQnd1kWWDaxOczu7M5OztPp/v44dbtuVVdP5zDT9/l85tM93dVVt7qrzjnPc849l4QQ0NDQ0NDQAABXoQegoaGhoVE80E5BQ0NDQyMK7RQ0NDQ0NKLQTkFDQ0NDIwrtFDQ0NDQ0otBOQUNDQ0MjCu0UNBKCiOYQkSAiTxLbfoSIXsjHuFJFrsdGRDcQ0W9ztf90QEQnE9FbhR6HHUR0GhG1FXocGrHQTmGSgYh2EVGAiKbYXn/dMOxz8jyep4noEBH1E9EbRHTRONveSERBIhpU/r6c5nGTdmTZghDiu0KIa/J1PCcY57xAGdPzQojFWdjvZiK62uH1zxDRGuP5j4hoKxENGNtfmelxNfIP7RQmJ3YCeL/8h4iWAygv0Fg+A6BFCFED4FoAdxFRyzjb3yuEqFL+fpDqAfPhCPLpbIoEfwTgZOQ/ZLwHAEMA3gmgFsCHAfyMiN6en+FpZAvaKUxO/AnWG/jDAO5UNyCiWiK604jidxPR14nIZbznNqK+TiLaAeACh8/eQUTtRLSPiL5NRG6ngQgh1gkhQvJfAF4AM1M9IYMBnaX8fyMR3WU8l6zgo0S0B8BTAJ4zNu01GMcJymd/REQ9RLSTiM5L5rwM6elFIvoJEXUDuNFhjE5j+jAR7TG+y68p27oNuWm7EVm/SkQzjfeWENETRNRNRG8R0WXK5/5ARLcb7w8Q0bNENNt4T57zG8Y5X26XaYhoKRE9Q0S9RLSBiN5l2/cviOifxr5XEdF84+0/AThJHkvuC8ARAO4BACHEN4UQm4UQESHEKgDPA4h+7+MhwbjOJ6KNxpj2EdEXjdenENEjxme6ieh5eQ1rpA/9BU5O/BdAjXGjuQFcDuAu2zY/B0d08wCcCnYiVxnvfQzAhQCOBrASwKW2z/4RQAjAAmObswHElU2MG3cUwCoAzwBYk+6JJcCpAJYCOAfAKcZrdQbjeNn4/zgAbwGYAuAHAO4gIjLeS3RexwHYAWAqgO8kOaaTACwGcCaAbxiGFAA+D2Zz5wOoAXA1gGEiqgTwBIC7jeO8H8BtRHSYss8rAPyfcQ6vA/gzAAgh5DkfaZzzvepAiMgL4B8A/m3s+1MA/kxEqrz0fgDfAlAPYJs8TyFEG4CnwcxA4koAjwohOu0nTUTlAI4FsCHRF5TEuO4A8P+EENUADgc7fQD4AoA2AE0ApgG4ARx4aGQA7RQmLyRbeAeAzQD2yTcUR/FVIcSAEGIXgJth3vCXAfipEGKvEKIbwPeUz04DcB6AzwohhoQQHQB+AuB98QYihLgQQDXYAD4uhIiMM+7LjMhP/k1P4ZxvNMY0Ms42u4UQvxFChMFOoAXAtCTPa78Q4udCiFCCY6j4lhBiRAjxBoA3ABxpvH4NgK8LId4SjDeEEF1gZ7xLCPF74zhrATwAq2P+pxDiOSHEGICvAThBsowEOB5AFYCbhBABIcRTAB6BIjUCeFAIsdpgd38GcJTy3h9hXCNGRH4FTOnIjtuN8308C+MKAlhGRDVCiB7jO5GvtwCYLYQIGvkT7RQyhHYKkxd/AvABAB+BTToCR5g+ALuV13YDaDWeTwew1/aexGywBNQuDTeAX4EjvLgwbtrHAJyjSgMOuE8IUaf87R9vvzbsTbwJDihjGjaeViG580pm/3GPB2DYOBbAEtp2h+1nAzhOdYxg49vsNA4hxCCAbvBvlgjTAey1OWX1dx9vvADwIIAWIjoewGkAKgD8034QIvohOKK/LEkjnWhc7wEHFLsNuUxKUj8Es5l/E9EOIro+iWNpJECpJctKBkKI3US0E3wzfdT2dic4ypoNYKPx2iyYbKIdVt1/lvJ8L4AxAFOUXEEq8ACYn3CrWAyBjZBEs8M2Is7zZJDMeWUzCt0L/h7WO7z+rBDiHeN8NvrbEFEVgAYAyTjP/QBmEpFLMcCzAGxJZsBCiGEiuh/MQMsB/EUIEVC3IaJvgRnXqUKI/mT2m2hcQohXAFxkyEz/A+A+ADOFEANgCekLhrz2NBG9IoR4MsnjajhAM4XJjY8COEMIMaS+aEgn9wH4DhFVG8nDz8PMO9wH4NNENIOI6gFcr3y2Haz93kxENUTkIqL5RHSq/eBGwvQ8IionIi8RfRCs9T+bxrm8DuB9xn6c8hx2HAIQAedMEiKV88oSfgvg/4hoITGOIKJGsGyyiIg+ZJyrl4iOVXIRAHA+EZ1ERD5wbmGVEEKyh4OIf86rwM71y8Z+TwNXC/0lhXH/ESw9vgc26YiIvgpmp+8wpLBkEXdcROQjoiuIqFYIEQTQDyBsHO9CIlpg5ITk6+EUjqvhAO0UJjGEENuFEPGSup8C34g7ALwATmz+znjvN2At+A0Aa8GygYorwfLTRgA9AO4Ha7t2ELhKpwNspD8D4HJFE04F/x84su4BJ0LvHm9jQxr6DoAXDRnm+CSOkex5ZQM/Bjvff4MN2h0Ayo3o92xwLmM/WM75PoAy5bN3A/gmWDZaAZaXJG4E8EfjnC9TXocR1b8LHMl3ArgNwJVCiM0pjPs5AH0A9hkRvIrvgiP8rWTOM7kh0Q6TGNeHAOwion4A1wH4oPH6QgD/ATAI4GUAtwkhnknhXDQcQDovo6ExcUBEfwDQJoT4eqHHojE5oZmChoaGhkYUOXMKROQnotXErQ02GAko+zZlRHQvEW0jnigzJ1fj0dDQ0NBIjJzJR0byp1IIMWhUDbwA4DNCiP8q23wCwBFCiOuI6H0ALhFCXJ6TAWloaGhoJETOmIIxIWfQ+Ndr/Nk90EUwKxjuB3CmMrtUQ0NDQyPPyOk8BWPm7KvgtgG/MPqhqGiFMRFHCBEioj4AjeAKBHU/14KbqaGysnLFkiVL0htQaBTo2ATUzwXK69Lbh4aGRmmgYxPbDACYfnRhx5IFvPrqq51CiKZE2+XUKRj18EcRUR2AvxHR4UIIdbKOEyuI0bOEEL8G8GsAWLlypVizJs3WOR2bgNuOBy79AXD4u9Pbh4aGRmnglqOB7h38/BurAJdjz8cJAyLanXirPFUfCSF6wY3QzrW91QZjdiZxK+JacO11jiB9kC7D1dDQSAA131pCpfu5rD5qMhiC7Jh4Frgxm4qHwW2dAZ6h+lROG1rJdEUJ/cAaGhppQm3FNG4Px8mFXMpHLeCZlW6w87lPCPEIEf0vgDVCiIfBszj/RETbwAwhbqfN7EDnsDU0NJJFJq20Ji5y5hSEEOvAPentr39DeT4K4L25GkMMNFPQ0NBIFlo+KgVopqChoZEkLE6hdOSjEnMKEqXj9TU0NNKExRGUjs0oLaeg5SMNDY2koeWjEkLp/MAaGhppokSrj0rLKWimoKGhkSxEaVYflZZT0JPXNDQ0koWFKZSOzSgtp6CZgoaGRtLQ1UclAF2SqqGhkSRKyBGoKDGnIKGZgoaGRgIIgWggWUIOorScgpaPNDQ0koYAyDCRJWQzSssp6ESzhoZGshBCaZddOjajtJyCZgoaGhrJQgiADKeg5aPJCs0UNDQ0koSImEyhhALJ0nIKevlnDQ2NpKEwhRIKJEvLKUiUkNfX0NBIEyICuFzm8xJBiTkFLR9paGgkCaGrjyY/dKJZQ0MjWYiIlo8mPzRT0NDQSBZKSaqWjyYpVKaw/SnNGDQ0NOJDZQolZCtKyylIprD7ReBPlwDtbxR2OBoaGsULIcxEcwmpC6XlFCRTGBvgx+Bw4caioaFR5NCJ5tJBOMiPkXBhx6GhoVGckE5Ay0eTHQZTkE5BaKegoWDXC0CkdBKKGuNAOgGdaJ7kkPJRRDMFDRsObgD+cAHnmzQ0pBPQJaklgnCAH0vI+2skgMwzBQYLOw6NIoGdKWinMDkhmUI4xI+aKWhIRPQ1oaEgyhR0m4tJDpt8pHMKGhLSKehrQgNQEs26JDVrIKKZRPQ0EW0iog1E9BmHbU4joj4iet34+0auxmOBrj7SsEMzBQ0VkhmUoHzkyeG+QwC+IIRYS0TVAF4loieEEBtt2z0vhLgwh+MwQfbqo9KhhBoJIKuO9DWhASDKDPQiO9mDEKJdCLHWeD4AYBOA1lwdLzlo+UgjDjRT0FBhZwpaPsouiGgOgKMBrHJ4+wQieoOIHiOiw3I8EH6U1Ue6Jl1DIppT0NeEBkp68lou5SMAABFVAXgAwGeFEP22t9cCmC2EGCSi8wH8HcBCh31cC+BaAJg1a1Ymo+GHsE4qatigE80aKqJMQVcfZRVE5AU7hD8LIR60vy+E6BdCDBrPHwXgJaIpDtv9WgixUgixsqmpKZMB8WOUKWgDoGFAXgv6mtAAYOYUdPVR1kBEBOAOAJuEED+Os02zsR2I6G3GeLpyNSadU9CIC80UNFRo+SgnOBHAhwC8SUSvG6/dAGAWAAghbgdwKYCPE1EIwAiA9wmRh29fUkEdFWpI6ESzhoqY3kfaKWQMIcQLMJc6i7fNrQBuzdUYYkC24eioUENCXgslpB1rjAcbU9Dy0WSFzSno6iMNCc0UNFTETF4rHVtRWk5BMwWNeJDOQF8TGoCSUyDr/yWA0nIKMUxBGwANA5opaKjQrbNLBDFMoXQooUYC6MlrGhboRXZKE1oq0JDQJakaKuxMQctHkxVaPtKIg+jktdKJCDXGgb0kVctHkxRaPtKIB51o1lARwxRKx1aUllPQTEEjHnSiWcMCXX1UGtAlqRrxoHMKGip06+wSgd0p6KhQQ0IzBQ0VMb2PtHxUGtBRoYZERLe50FAQ0/uocEPJN0rbKeioUENCz1PQsEAzhRKCIiGV0A+tkQBaPtJQIfR6CqUD0k5BwwFCl6RqKIhZeU07hUkMxSnoqFBDQq+8pmGBlo9KBxamoA2AhgFdkqqhQpeklhI0U9BwQDSnUDoRocY4KOHlOEvQKSjQUaGGhGYKGir0IjslBFU+0lGhhoTOKWhYoKuPSgg6p6DhAM0UNFREG+Lp6qPJD9I5BQ0H6BnNGipiZjSXznVRek5BMwUNJ+jJaxoq7IlmLR9NYmimoOEE3eZCwwI7U9BOYRJDz2jWcIBONGuo0DmFEoV2ChoSOtGsoULLRyUELR9pOEHnFDQskPKRZAqlE0CWnlPQiWYNJ2imoKEiZo1mzRQmLzRT0HCCNAL6mtAAYktStXyUOYhoJhE9TUSbiGgDEX3GYRsioluIaBsRrSOiY3I1HuWo5lMdFWpIRJlC6dz8GuMghimUjnzkyeG+QwC+IIRYS0TVAF4loieEEBuVbc4DsND4Ow7AL43H3EFdplm3udCQ0PKRhgW2NhclFCzkjCkIIdqFEGuN5wMANgFotW12EYA7BeO/AOqIqCVXY4odpDYAGgZ0ollDhW6dnVsQ0RwARwNYZXurFcBe5f82xDoOENG1RLSGiNYcOnQo09GYT7UB0JCItrnQ14QGYpfjLCH5KOdOgYiqADwA4LNCiH772w4fiXHJQohfCyFWCiFWNjU1ZTogZcfaAGgY0ExBQ0VM62zNFLICIvKCHcKfhRAPOmzSBmCm8v8MAPtzOSY9o1nDETqnoGGBnryWdRARAbgDwCYhxI/jbPYwgCuNKqTjAfQJIdpzNSZjYOZzHRVqSETbXOhAQQMlLR/lsvroRAAfAvAmEb1uvHYDgFkAIIS4HcCjAM4HsA3AMICrcjgeA4ZTcHlK6ofWSACdU9BQEdM6u3SYQs6cghDiBTjnDNRtBIBP5moMjpBMwePXTEHDhM4paKjQM5pLEG6fjgo1TOjW2RoW2Hof6ZzCZIZmChoO0IlmDRX2LqmaKUxiROUjzRQ0DAhhXgs60awBOJSkls51UXpOwcIUSueHnrDo2wfcNBvo2Jy7Y6iMUQcK+UfHZuAvVwChsUKPRIGt+kjLR5MYUaZQpg1AMhjqBB67HggHC3P8vjZgtBfo2Zm7Y6jXgZYU8489LwObH+HfuligE82lBMMpuMu0AUgGO58FVv0SOPRWYY4fMZxRtpxSfzvw4P8DgqPKMULmcx0o5B/y+w8OF3YcKmJKUktHVShBp2DAU1ZSP3TaCMtSzdD42+UKkSwff89LwLq/AF3bYo8B6EChEJAOP1BMTsHGFLR8NIkh5SNdkpocsm2UU0U4y/MHojOXg7GvAfqaKATCAX4MDhV2HBbInIJhL7R8NJlRgiWpq34FPPCx9D4rjedkYQoyKlV/e7lvt6+kbv6iQaQYmULpyke5bHNRnLCUpJbID73nZWCPvWt5kpAGs1CJ5qhTytLxnc4n6hR0nqkgCBdxTkHLR6WAEmQKwZH0jepkyyk47U8+13NXCgN5bRaVU9DzFEoHshtTKeUUAkOmbpsqCi0fZT2nIPfnkFPQTKEwkNdmMclH9tbZpUMUStAplCRTGDaNa6oodKI52/JVdH8OFUdub+kECsWEqHxURIlmvRxnCaKUJq8FR9JnCuFiySlkO9HsJB8ZZco62ZxfFHOiuQTXUyg9p2CZ0VwiBiAwxDdeOudaaPkoZzmFOIlmoKQMQFEgXIQ5BXubi1KwEwZKzymA+M/l5X9LwQAER/gxHbms0PJRthPd0XkKcRLN6jYa+UExOoXo5DXd+2jyg4i1Y1cJ0UJ5s6UjITnJLflE1pmCbJvhlFMwnEIpXBPFhKKXj6ikronScwogXopTVhVM9qhQCJaPgPTKUuX3M1lyCuOVpEadwiS/JooNRc0UiP+0fDSJQYZ0FNUKJ7kBCI0hSn3TMezFklPIdvWR6iCFjSlM9kCh2CB/k0ARVR+pOQVyQctHkx0ut1lqNtkNgBp9pWNYCy0fZXueglOOQq0+AiZ/oFBsiPY+GinsOFRE5SIjB6nlo8kMI6cQnZQyyQ2AxSmkkVModKI5V9VH4XHkI734Un5RlPKR0hCPXFo+mtQgI6cQZQqT3ACoybt0DOtk7X3k1C5bM4XCoBjlIzXRTAQtH9lARPOJqMx4fhoRfZqI6nI7tFxBJppLJKegzhLV1UfOTiaGKUzya6LYUIxMIeoEtHwUDw8ACBPRAgB3AJgL4O6cjSqXiJaklkpOQdFp00o0F8s8hSyvp+AkH2mmUBgUZUmqWn2k5SMnRIQQIQCXAPipEOJzAFpyN6xcwlaSOtkNgEU+moBOIWfVR+PlFCb5NVFsiCaah4vH+FpyCrok1QlBIno/gA8DeMR4zZubIeUYsiQ1H0yhaztw81Kgb1/ujpEIFvkoA6dQ8JxCtnsfOXVJLaFZ7sUEydpEOP0eXdmGZUazzik44SoAJwD4jhBiJxHNBXBX7oaVY7jcClPIoQHo2gYM7Ad6duXuGImQqXw06XIK4ySade+jwkB10EWTbFZyClo+ioUQYqMQ4tNCiHuIqB5AtRDipvE+Q0S/I6IOIlof5/3TiKiPiF43/r6RxvjTgC2nkEsDIKOeQkY/gQwTzYWevJar9RQccwpaPioI1GClWJLNluojlFSgkGz10TNEVENEDQDeAPB7Ivpxgo/9AcC5CbZ5XghxlPH3v8mMJWOQrfoolwZAXuyFkl4AK1NIqyTVoYFcPuE0Azkr+3PKKehEc0EQDgKecn5eLMlmNdGs5SNH1Aoh+gG8G8DvhRArAJw13geEEM8B6M5wfDmAbZ5CIgPw8m3Ar05N71BRp1BAppDp5LVCO7ac9T5yKEmV1UfFzhT2rAJ+vhIYGyz0SLKDSBDw1/LzYmEK9jYXWj6KgYeIWgBcBjPRnA2cQERvENFjRHRYvI2I6FoiWkNEaw4dOpTZEQmpMYWurUDnlvSOVXTyUSbVRwUylNlmKo5tLuxdUovcKXRs4OtyKMN7oVgQLkKnoLa5ID1PwQn/C+BxANuFEK8Q0TwAWzM89loAs4UQRwL4OYC/x9tQCPFrIcRKIcTKpqamDA+bYpuLUMBoKpcGIpNBPsryjOJUEWUqeWhzMVGYQjEw0GwiEjKdQtHIR7bW2SUkH3mS2UgI8VcAf1X+3wHgPZkc2JCj5PNHieg2IpoihOjMZL8JsfJqoLwu+ZLUcIAdRySsrNeaJIrh5s14RnORzFPIpXwkJlhJajEw0GwiHFCYQpFUH+neR+ODiGYQ0d+MaqKDRPQAEc3I5MBE1EzEa2MS0duMsXRlss+ksPIq4LBLki9JlTdeOmyhKJzCCOCrso4nFUy2eQpO+4tZT2GSOYXgCHD3+3jeTDFClY+KhSlYSlK1fOSE3wN4GMB0AK0A/mG8FhdEdA+AlwEsJqI2IvooEV1HRNcZm1wKYD0RvQHgFgDvEyKP7tiVZE4h6hRGUz9G9OYtoHwUGDZvuIzWUyh0TiFb1UcOiwbZq48minwUStIp9OwCtjwG7F2dsyFZ8MJPgbsvT27bSBiAKN6cQqHWUxg8BOxbm99jGkhKPgLQJIRQncAfiOiz431ACPH+BO/fCuDWJI+ffSSbU8iEqhcFUxgCymoA7EvPsIazXBKa8vGz7JScEufRLqkTJNGc6jUpA5p0Apt0sHc1sP+15LaVv2/ROQVFPipEQ7yXfw6svRP4yq78HhfJM4VOIvogEbmNvw8iH1JPLpHs5DUpG6UjH0WKwSmMKExBr6fg3OYixNGgy4iRip4ppMhAQ3nOQQx3Jn+/yDH5a/ixWOSjmOU483DMUMCsFhztB0Z6CtLaP1mncDW4HPUAgHaw9HNVrgaVFyS7RnMm0X7RyUcZVB8VOqeQ64Z45E6ePRYa0WsyWcMrA5s8MYWhzuTvl2jlVznLd8WSaIYAVx0hf/LR098Gfn8+P5dOtQDMKdk2F3uEEO8SQjQJIaYKIS4GT2SbuEh28tqETzQPm1FYRkyh0DmFHLe5mEgLL6UsHwWsj7nGcFcKTMG4R9wewFdRXExBzmXKl3zUtR3oa+Pn0oEH8j9BMZOV1z6ftVEUApSkAYjegBPYKXgruDPshM4p5LIhXmRitVNPWT7KY04hHARGe80y7kSQ15XLy9dpsazTLISRT4AxTSEPTGGkN1auLkCDwEycAmVtFIWArD7KKVMoEvnIV8nllhlVHxU6p5Bt+ciWU3C5k69IKzSi1UcpykfpBDapYljpbJPM+KJMQTqFIpGPVKaQL/lotBcIGU5ROvCxgdwf14ZMnMLEns2RbJuLjBLNUqooEFMQwmAK5UzPM5qnUGinkOU2F/aS1AnJFIpQPhpW5p4m44SiTsFXXPKRmlPIl3w00svXYjikyEf5d5LjlqQS0QCcjT8BKM/JiPKFpEtSJ3CiWc7GTlc+ikTMm6HgTCGXJakhaz+sYp+olGqTwnzKR8NKUWIyTigqH3kAb2VxlaRGmUKeVl4b6eHH0GhBcwrjOgUhRHW+BpJ3pNLmAshQPioQU5BRhrfCkI9SHIdFYil076NcykdhW6J5ojCFFMs+83EdDqXLFLzMFIaLpLGyiCg5hTzIR+GgKZ2FxpScwsRKNE9s5GXyWoHlI5m081UY8lGK0b5TK4h8I+u9j+K0uXC58rMaXzaQsnyUx5LUlJmC8Tu4vCxzFkuiGchv9dFIr/lcZQoFaI9euk4h2fLDiZxoljdYukxBHfdkyCmocti4JanFzhRSZE/ReQrFyBSMMbm9hnxkRMsHNxS2V5OIwDJPIVP56NBbQPfO+O+P2p3CxKw+mthIRj8WIrMoq9Dykaxk8PjTzCnYdPdCIHpckbmxFnHOR4RtOYVidwopBirZYApDncBj1yd2LBamMM742tYA911pjknKRzLR/PCngMe/lv54M4WlJDULrbMf+iTw+A3x35f5BKDgOYXSdQrJTF6TzbqAzCZ+FUw+Mi4sbznfdKkylqgTocLlFCIhRCO2TB1TOE6OZMIxhVTnKciS1Ayuw63/Blb9EjjouOS6CUv1UYAZmVNF0fangI0PAYMd/H90noKx7XC31VDmG2pOIRvy0UiP1WHGvK8wheCozikUBMm0uVDp70SUj2S04SlLzynI7b0VhWEKQvBxvUahW6ZjiJcjkWtlTJiS1BQr4jLp9CshV3lLZKSGOhF14qEx4KVbgNtPit1OGnz56PaYTiES4eOkaxDXPwj85swMJR9bm4tM5aPA8Pj5gRj5SOcU8o9kmIJ6003ELqlRp1DOOYWU5SPDcHr9hckpRLuXypbWWXIK5JrgOYUUq4+iJalxtg+Omu0V4kFG9ImM1HAXUDXVHGfvbqB3T+x2MU7BmKcgxzs2mP7Erd0vAfvWZOYELZPXslCSGhwCAuOcj4UpDJu/sc4p5BFJMQXFiE7E3kcqU3ClMXlNbVZWCKYgnZjHYAqZOibL+Yw3eW2iVB+l2CU13jX8ym+B294+ftFFskxhuAuomW4eLzjK37V9rFGnYBhDl5FoBtgZhEbSN4iDB4yxZjDnQc0pZGM5zuCI6VBX/Rp4ybZqgCqVjfaZz7V8lEck0zpbvYnS6n1U6OqjDHMKUfnIX5icgspU1P+zsT/HLqkTbfJasvJRgjYXgweAsb7xI+soU+iPv40QhlNoNY8nix3spabSGUjZRCaaAWDIOFa6BnEww88D8ZlCaMxaYZUMwiH+reR41t/PfypU+Uh9rp1CHpFMmwv1ppuI6ylYcgrpTF6TRrScb5J8dw8N25hCthLNkvnIGz04wuc4YXofpVt9FE8+imO4VUimkEgXj4QUphAw92l3OHb5yGXkFABg8KD5mXTY4YDBFDKaHa3mFJRE83M/An59Wmq7kmW24QD/BqN9sd/jSK95PFVK0jmFPCKZ8sNMnYK9nnzPqvwuAK7mFFye1I2qXb7Jt4QUk1PIkK3EMA9j/4Ehbho44RLNKVYfJXQK4xjRZKJvORu5usUY31j8fTvlFKJOocPcbjwd3glCmE4lEz3e3jpbykcHNwB9e1MLHFQZa2yQnYJ9bKO9QGWT8VyVj3ROIX9IJqmYcaJZmadwYD3wu7OBXc+nvp9UEAoAz/6QL6aMmYLx3WRLvkkV0glEq48yNNZRJyP3Z+ykc2awAAAgAElEQVQ/MAj4qiZgojlV+SjO9tJgx2MKkbBZajpe8lca+OpmfgwFzGtQ3bcQsTkFVT6SRh1IPVIe689OMznLPAWl+kgmzVXDnQiqQwwM8Kpqduc60mN+b1I+8vi1fJRXJBMVZjPRLG8qScNzhb2reAWnHc9mL6dgN6IAX8R3vQfo35/5mOMhmhjOVk5ByZGo+wsMAWVVE4gppNslNU7OIBFTGO425RNppJ0ciDTw0eqjOEwhOGz+FtIAyoZ4AC9aL5GqURxQHEpGUba9IZ5x/tIppDKHQh3HSI9RiTRoVQ1Gek2GJR1ORaN2CnlFyonmTEpSgyaFzDUdlFFWcJiNgFx7OJPJa3a5BQAOvAls+w+w79XMxxwPYRtTyDRhb3cycn9SPpoIK69FwkqrjmSdguEMIiFnFpSIKQzZ5JwD64HvzeDWDSqkga+aZhx3zDlfoRrUqHyUJaYgK4+AzHIKwtY6G4IN95hhsNVkcCKo45BBlIhYv5PRXqCqiY8lnWtFo84p5BXJrLyWzURzME9OQTIR6RQ85RzppNXmQinhBKxGedSoQsnlRZureQqqHCV71/smCFNIR9JMdB0nYgoqux0bADq38HfZsdG6nTSUUhsPx5GPVKcgfxNLTkGN9lPMKVjyEZlUHznIR+p8i5EUnIJ6z/ftc359pBcor+eARWUKkWD+llE1ULpOIZXJa25f6iWpQlhpftQp5NjzR5Ns0ikYBjWdldfC45SEytLEXJ5PTKI7Q2MdtstRQXP8vsqJUX1kcQopJpoB5+s4UfWRlHNqWjkIkO0aBg5Yt5OG0l/H11toTGEhisNxkl4s1UeKYU816FDHlNE8BbV1tiEf9e42308pp6B8r/2qUzAcXnCUS3f9dXyvRZ3rFGO7/LKF0nUKROCePkk4BV9V6kwhGgGVARBmgi7n8pHCFIKjZlSciXzklFOQTCGX5xNTLZSt6iOF+cjx+ww9m1zFPU8hnTxXQqbgYLhVSPmoYR4bKFllZM8njfayw/X6+boPB8y8VlDJZ9idgsvD96OTfJSqQRw8wKwYyDynoLa5gI0pxJOPRvti7zOLfOTAFORr5XU2pqCdQv7hcifHFMqqU3cK8sKQxkZGUbnWCOUNHLQxBZcnszYXgLVmfCwPTiEmss/WjGZFjoo6hSp+pATXRKFhaWeewsprbuOc05GPBjs48q9p5eAmyhTarduN9HK0CwAen9HDx2Hf8l6oNBLS0ojL4GM0gzr9wQ6gpoX3mcl6z/aSVCkfye/RST7qawNuORp46v+sr8eTj8YGjdnkJ/D/jQv52pROobLROFaP9XM5Rmk7BXKPzxRCilNIeS0ChWUA5oWer0RzVD4yDKosSU1lnkTYllNQjbK8cHMqH9lzAFmqPlLPR5WPAA4UJoJ85PKkVn1UZiyiOC5TiJdoPsR5grJqdgojBlOwy0ejvRztAmw81fJVp5xC3UxjW59xTi5TQpLGN9WcwsABoKqZf8+slaQqTqFxAY/XzhTCIeCBj7HDbF9nfc/CFJQeU4EhYPOjXIr6if8C807la1My1QrDKfznRuC24/PWGaG0nUJemIJxkefDiAJW+cjiFIxoLBWDF2OUVfkoH05BGnHDQGTc+8hh3oUjU5gA8pGvyjk/0LnN4TNjgL/GfG5HMkxBOoXAoNnmwS4f2ZmCqrsHh/lzO59jp+D2mQlpt7IqsLzWKqfwb5GqYR88CFRPM5xCpjkFWZKqyEf1swF/bSxTeOMeYM9L7JC6d1jfk+NweYB+hV0FBvi7mLIQmLqUX5PXOmDKR9ufZmauymo5RM6cAhH9jog6iMixATsxbiGibUS0joiOydVY4oJcyVUfpcMUInHko5xq8BFb9dFYrFNI5TxiJo/lWT6yVz9ls82F/N+eU5goTMFXFRs5tq0Bbl3B5cISQnBwUGY4BXtwI/vyAOOXpFZN5bkckZDpDAbarczTzhQsnT9HWCr547uAzq1caSMdsZSPAHOugq+Kj5eyfHSQS2J9lZnJR2pOATASzXuAulns+OxMYfdLLIcdcyXPeFYrhoJDfI7+OmtgFRhi1lXeYL4m7zXAZApyNnUu5wQpyCVT+AOAc8d5/zwAC42/awH8ModjcUYi/TgjpmB8VtLhqHyUw8h6tNe86ILDRk8fwynIGy+VvELUiDrkFPJRkjpe9VM6cGpzEZWPJFNwFXlOQTqFylgHLxOWajQqf0N/HKcQUhxBPKfQt48lDp8hQcmEa3DYygZG+sZhCiMGwxA8v8Vfx0YfMAMWwGTWZVV8vFTul4MbOfKumc73XbbaXJAxd2CsH6idyY7PzhTaXwemHwU0zo+tVAoM83nJ85XOZmyQx1teb25rYQqNsKA/P3mFnDkFIcRzALrH2eQiAHcKxn8B1BFRS67G4wiXK0FOwbiB0qk+kgYtmlOQcksOI2tLjbadKRi6bSq6ZFRuGS+nkE+mYBt7KMUcidP+JlxOwfgOyqpic0TSQaudTKVcFGUKo8D6B0yjpjoCJ/lotI9n4zcuUPISI+bsWzWvYGcKdvlI/h8eszIF1SnIICrKFJLMKQSGgL9+hFnC0R/iz2erdTa5zAKOqqkGU1D7Ew0DhzYDLUdxhRZglZCCQ8yApFOVM77H+nk/FqcgmQKZr8uE/CRgConQCmCv8n+b8VoMiOhaIlpDRGsOHcpim4hE+nH0BqxOfZ6CGtEBinyUw8haXrjkNuSjEcUpGLptSk7BxhRUo5zPeQpOM6pH+4AfzAM2P5LC/hyYR0xJarFXH9muK/X3lAZUNVjRYgnDKfTuBu6/Glh3H/9vaT/hwBS6tvNjw3wl0gUw7XB+HDAMVSTM10SUKZTFriamOqvyesURq0zBeK2s2jDsSV5fL93Kk+re/Rs2ur6KzK7NwBAsM5plcry8nh2fem4H17MdaTmSvyfA/N4A/l59FaZTrWzic5YLG1Uo8pFkCh4/sztyAcsvZWdZAk6BHF5zDPuEEL8WQqwUQqxsamrK3giSSTSTmyPl0FiKlTvy5rXLR3lgCnUzHXIKBlNIRz5yZAoFzin07OZE3Z7/pr+/eDmFok4026raVAlJVuqo0bWcUSzlI1naKMtKEzEFadwa55vHBIBph5nvP/N91tEBhSn4rL2W7FJTXKZQbp5fKjmFQ5uBhrlcwQMYOYU0mcLmR4HtTwILzuT/1d5H5fXs+FT5aP/r/Dj9KDbwZbVWphAYZqMunWpZDY8v+p0pTEGev6eMn3/gr8ApX2JJbKLLR0mgDcBM5f8ZAPLjCiUSlaSGx/jilhPQUtG0Izb5KB9rrkqnUD+HL0SnnEJKTME+2SvPM5qjJbEObS6kbNHlUG0TD/FyCu4y0zAlKj6w7K8AjEKtPgKsTiEZ+UjOLZCRbyKm0L0dAAH1c819ACZTeP5m4JnvAq/fzf+rTEFFcISdwvSj+f/yOsURq9VHak4hDlMY7Qf+cCHnECQG2oHq6cp+0ixJHe4GHvoE0HwEcMb/x6+RYibL67n6aLTPvE7aX+dKoZpWdiANc2PlI1+l+Zv5a5k19Do4BZUpAMDCs9jR1EwvCabwMIArjSqk4wH0CSHaE30oq0gUFYaD7BQ840z8iftZG82XCI3kzpgMdbDxr2nlm9DCFNKRj+IY5dBYdtoTJ3t8dQbym/fzuUnj1rk1+f05dX2VzfAkkpWPQmPAT48AVv8m+eNnAzHykeoUnJiC8b5kCtKwRJ1CgkRz1zZOrnr9VvmoZjobM/k77H6JH1WmIFFWaziFfmDqMuDcm4CjrlCYgrKtT6k+8sVhCntXcwv6tx41X+vfby7uI/eTzrXZ/gZ/N2fdaAYPqqgh5SMI0/nuN5LMMgfRON9wpgYCw3wNlylOwVdpykdq9ZG8X+1OtaZ14jsFIroHwMsAFhNRGxF9lIiuI6LrjE0eBbADwDYAvwHwiVyNJf4gk0g0exSnkEo5p736SEWuDKmsJ/dWcHRiySnIRHMqJakh/o7kRKJou2PjZvDXxrYABlhSyMZEG3tOo2MT8MBHOVEqmULPruQbhtnnKUj5SDV2iYoPJLY/zROROrckd+xsYTynIKPqUYUpSOcdlykYjqC8Pr581GgkT6UmDnBljIzM/XVA2yvmc8BWRdNgykf+WuD4jwPNhztXH6lMoazKOnlNMscDb/DjQaPaXQg+rxqlTsWXZvVRVIKdZb6mMgV/rXmOo708pkObgebl5jYN87hCS16XQSkfGb+Bv8YoXpHffZ352ahT8MMCyRTywE5zWX30fiFEixDCK4SYIYS4QwhxuxDiduN9IYT4pBBivhBiuRBiTa7GEhcJcwoGU5AGdbw1bGM+a5OPAHM/uXQKVU18Q4wNsFH3ZFiS6vKa9F5G7jJCqmllpqV+L/tfA25dCay7N7NzUY8nmYJMpHfvMFskizA7hnhoX2dO6HNan0EusCORLFPY+BA/ptIYLRtQix8Aq0N0lI8C1u1luao9x1XRGMsUhOCIt3EB/69+TxWNwOy3A8suAhafr+QuavnRbXMKY4Ns4FUJylE+kjmFaitT6NkFfHc655DkPIwDhlMY7uLzrLYxhXQ6jMrrSrb/BkwG4K9lmyGN+GgfJ9pFGKibbW5fP4fvC5kDCDjIRyo7rUiGKUzn46gVhjlCac9oTphTCGRBPlKYgiwty5UOP9LNN6u3IlY/d6eZU5BrMQCmo5OGUJYlqhT/6e/yDdGxKb1zUGHvfSRn0vbsYqYgjUnXOBLSny4GnvkeP4+ppgrFykfJlKSGAsBb/+TnalSeD4wrH8m5I6p8ZFyzUj6S6wHYmUJFYyxTGO7i31pW1KhOobweuOBHwGV3mklnwDSYHkUSKm8wZ+NKp6Huz+1UfWQwhUiQz6FzK+dH1j9otpHo3s7SjJRVVKYgJ8GlOoFt4KAR1SusSMpHUvuXTGGk18wL1Cnp0SpjBTVpwIO2RLPMKch9lynfiTceUzAKM/MgIZW2U0jIFMasTCEZ6SU4Cqz7q7N8VGVUTuXMKRg92dVjxsxoTtEpuD3K4jM2pyA1XHk+e18Btv6bn3fvTH38TscHzOhRVsz07GK5YLoxCT5eXmG0jz8j9V2nXkpjg6nnFHY+y/t2+6xReT6QlHyksBeZaPapRg6xiWYnpqBWHgEsrfmqjNbYSnQ/bZn5XBpMt20SlmQmjk5BcSDqPAU55sCQGRBs+gczxeYjzOBDSmLScALm95PqXIXBA8wSSMkjSPlIOoVyRT6SFUS1itwk73PJbAPDVqYgq4/kvlyKGR6PKQB5qUAqbaeQKKcQDlpzCskwhU0PAw9ewwkrwBpdyV4vuZKPRnr4pvQ5OYU0cgrhIEfjdulJlY8AYz3oMeDRL3IVxtxTY/u/pAN77yOLUzgANC1i9hWPKcjySzkD1848ZE5B/Y1c7sTVRzueYaM395TCyUfSYCaqPpLXrKfMaqhHevg8o0yhIdaAHjRkGikfAfxdqXIHYFYiuX1KSaU09GTVzC1OwUE+8tlyCgAzH9m+ZWA/AAEc9QFjjOvN6LlazSlIpzCUGsMfOGiVjgDTQYzHFGpnmNtLRWCwgyW4KFMwfjN/rXnNldu+S3ltqu0uAM0U8oZEk9dCBlOIGpEkDKqMHGT04igf5cApCGHMjqxzZgpRw55iWa1TTkFKJpKuBwaBJ77JpXnvuoWTbj27eExjg8mXeDodHzCrhaRTGO5ip1Ddws3EnJrAAWZU1dfGY4gmzuWcDZlTUJlCnPUUDm0BNvyNn3duZUNZ2VRk8pFT9ZHiFNToU0RY448mmo1ksFo08Ma9wJTF5ixdgA21vf1C1VQOBvx1pgF1K6WV6vXod8gpWBLNsvqo2jScgUF2CmrCd+k7+X3pFMhlNeZy32vuAH60KHnGIBvqOcHOFEa6gb49fO6W+9xoZDd0yMi1COvkNb/KFJRyVCA+U6ho5OtWM4UcI1GlicwpRBPNSUQcMpEnq2NUgyNpZbJT91PB2ADLHn6bU4jmFJIsSQ0HTSMeCfENa88p2JnCwQ3Aql8Cb7sWWHIBJ9pCI1zO+JNlwOt3pXdO8nhur5H/UR2a4H48jQvGYQqGgw4H+GZ3cnJOOQUpHwVHzUlK//0F8MA1/FrnFnZGZTWmRp8vJFt9JI27fF91CtK4jvSwI3B52VCJsHl9dGwC2lZzgzdVSqmfC0xZFDuu5sOtzkIyBa/dKTjIR+qM5rqZ/FvXTDeN6Gg/y0c1reykKhr5+bTDONk8sJ8dgtthvsPGh1nmSdaYDh40cwISdvmorJoDkoMbmSmo+QSAr9fyBmYK0hl5K4EZxwKHv4dlT3ludqcQL6dABFz1GHDC/yR3HhnAk3iTSQyVKWx8iC+8Yz9qvh8O8I8TlY+UKpsD64HX/gSc8z2rJijpnUwyWeSjHDIFqdmqk4KA1OWj208GDrsEOO0rhnzkjp9TkJHZvrX8ePil/Ngwlx9fu4u3TbdsMxICQMYYPEDY5sCrWzjSHe7iSUd2WUPWgQMsIUUT53anoFYfKYHCY1/mUstPvMxSVCTEbKh3N7D8vbzN2AA7UVee4iv75DVZXROJmBPxwmMcwHj95jXrVuSj2pl8DiM9xgTHCtOIBofZoK+9k431ke+zHv/yP1kjdolzvmsNduSxvBVWKUR1Ch4j4FKZwpyTgC9u5QVmZPAx0G6s6TAFOPUrBmsgNrKrf23txSQhvx/ZhmOgnR35eAgM8zHtTMEuHwFA6wpg36v83tRliEHVVM4pyES3r4Kvz0t/Z/xv3KP2azYeUwCAGSvHH3+WUOJMQYkK//tL4MWfWt+3MwXVoG58CFh1u3XRDMC8CGW1hSXRnEOnoK6Pq96E0ZXXkpCPxgaAQ5vMfEg0srblFEb7md5LKUBqz9IZ1BuPcparTBKmikjQjOrlo5pMrG7m1aoA55nNfftMA6Y6BbkvuTKYU0lqJMJ9lQ69xYxFOvuND3EgMWWREV1Hsls40LUd2DROP6dwgH8PGYmHRjlAkWOQkp40qCEHpiBzBJIpeMvNayY4zBPyXrkDWHqhKYVIeMudDda0w4BZx5v/qzNzvUrUq5akArHMFjBXHJM6fd9ec6GfxecxewF4Alw4wGXQ6sQ1wCrnALELAjkhWo5qYwr26iOAnUL3dm63os5piJ5DE5dCR5mCLUcQzSnEk49sTCGPKG2noJakdu9g6UfVv8NB682kykcyZ9CjtMgFTPlI6t9q1B5diDvHTMGSU1DWaAbGZwqyYkjKLtIoO81TUJNlHZuZHstEet0s/m5l9cVQJ8sZvz/fbMSWDKR8BZhjqJ1p3kgypwA4VyD1tZmTinp3K9VUxj4l43EqSW1/jX9DEebfWjr79Q/y45QFpoHLZgXS8z/mhnXx8jD2QGXTP4DbT2QGA5hOs3cPcPflZsLf4hSMaqIoUyg3tfw1v+eCgbknA+f9MP3zkOPzlluvR7tTuPxPwImfdt6Hv5bLNfva+BqS15fEtGXATMMRxTAFWycBNUEbCTv3MRswArkYpmCTjwB2CgDfI7U2+QiIZQpe23gS5hS0U8g5/rPxII7/7pPY36uU3ck2F2MDhuYc5DbBEqExQ1N3mNEcdQq7zNfCQWV1JOOis98Q7rLUlxhMBpIpqN0nAdMQJCMf9UinYLCfsDSiHvN/wJiZWqP03xljlhBNMnqt1RjDnfwd736R2xMki3DIPLaUfPy1nLMAsRxXN5uNvFNeoW8vR/SVTWwkwzYnJ7+zmJLUCLDtSfO1zi1mCaeMJhsXmkwpm8nmQ5v4+xyOw67CQWueR07kkk3ZZMS89d/Aln8BG//O/7vHYwqKxLPjGf6Or7jfzIGlA3kslYX4qq26P8DsQr1W7Kibybq9lI/sWHkVP9qZQtQIExtYyRSCo8CvT2PHZ4fTxDXAWT6afjSiDMKeUwD42lSZgp25RHMKdvmozPpYAJSMU6it8OJA/yg2H1Bu4LIajkDUmno1IRUOWG8mC1NQ2ixIDB5ETKNXt9c0yL7K9HuyAGx8Nj3C8o49QT4aRz6SzysaOOIZj0bL72Gkmy/mqHzkMrR2wykMHuQbxFPGRhQwDLUCWbFSNwsY6jKPqy4AkwiRUKx85K/lfVc3s4Fxe9gh2ZlCJMLRYe0MHkPvHv7OXB7zfOR3ZilJNXIKW58wE6d7V/Oj/L+mlatwpD6eqCy1cxvw42XWBm5OEILlKsBkaxJv3g/8ZDk712iTRpiOXE4WlMZR5nlk8KIGNw1OTMEwWgfe5GSumlxOB/KaV6uP1HxCsqidAXRsZEdpZwoAsOxi4Mj3A4vOsb4uHf3UpRzJS6b34s+AA+uYEclSZQmZB0xGPvLXAE2LjTE6MYUmDv6kYpAsU4iW9GqmkHMsbmbPvKldidJbjgA63zJ7qAC2VasCfDNFex8pTkHSUdUpyNck3XR5+eZSqXRZVfJOYcPfTXmq/Q3gV6cA917Bj/+63rpttN97nfUCVCOP2hnWPu92qHML+vfZNH0v/z/UyQm22SfyuUmDKvMJEk2L+b1F53KUJ41TKnXWTjkFfy1w+teAS39vbte4MDanMNTBn69pVZyCzck4yUfk5vHuW8PGBgD2ruLHhWfzo5Ss5EzURPJR++v8fb70c/M1J/mib6+ZG+iz5apeuYPLH7t3OOe5Dm3mRykf7X/N/Ky7jH8reS1UN7OhHulVnIJhjEIjPP8jUzgxBX9N/O3jQSbFAWen4PUDl9xunVUtj+/ysMxT08JBSfdO7uo673T+Pl6+zfoZOUveXnLrJB8BQKuR+I3HFABT1rMnlBvmMyNpPjx23OpjAVAyTqHG78WM+nJsaldu4OlHs1Qg+9gADkxBLUk1bsDQGEfTgLNTkJGYpPjy0VsZvx3wuvt45SiJwQ7grx8G/mtcuPd8gJOK77uHS9rabK2iRnrZoPmqbIlm5XnD/PEnlfXsNPX2vr0cMauafiTMnSlFhJOQgDnBqN7mFE79CvDRJzhyDY2Yxx2wOYVIBPjHZ7hSyQ6nnEJ5HWvis08wt5uygPevsidpVGtnslPo28tOXXVyTvKRy80JRBHhCVIVjeZ3vchYXVYmt8eTj3p2Af/8IssV0iGuv9+MRh+/AfjtWda+/JIlqOMHOGG+5yVzv6p8ZP+sZAqq/GSvaKloZAM30hsrHwHMFDKFW3UKGTIFCSf5KB6IgEt+BZz0Oc43DLQDGx7ka+CiX3Cl3No7rd//4EE25vZKMif5CABWXg2c+FlzMpsKWVSy/kE+vp1J17QAX9zCTEaFRzOFvGJpSw02H1CZwlH8uO1JnoDi8rBhb3uV6bpMNHsrOFqQVFDe5J5yZ6cgo5aoU5DyUUV8+WjTwzw5Slbq7HiGH7t3cLllfxtwwieBJecDM9/GOrfToulExg1uXMhqxNEwz9kpdG5juah7l1n21tdmlqQCLNOEgyxf1c7iNgOAaVDtTKGigROBFcaNLNmYlCwkXvwJ8Oof+M+OcMg8vsoU7GhcyA5cXRc32n7AYArhABtXNUchpZdqRS6Qcti80/h3rJ1h5oDmnQbMOdl0DtFEs00+ioSBBz4GvPIbjhQHDvB+wwFgze/YUay9k8td/3IF/76AKQG5vOZsbMCcNAew7q3245KQCU1VW5dGTFYqRZ1Cg+EUHOQjwHkeQqqIHlNlCmk4BTUKd2IK42H5pRxAVBtMoe1VDoxqW9mgB4eAHU/zPfHzlRyYVdulI5hMwW78Z6wA3vEtZ6lNjrV3N5fZJivHVTfzOg5LLkz+PLOM0nIKzdXYcWgQo0EjoqxpYf0wEmRJoLqFDfvT3wYe+iRHUW6j/K9pCWuRgKmPz1hpJFGNyH9gP0dIMpEnnYHbh2jCy1dpbt+5Fdj1gvHckD8k7d/+ND927zC1fqnTNy1mtqGympFe86IlMm9yNQJsmMfOQxohgA3Ur04B/vFpNqSz385j7Wsz5BslUh/tZWe19ELzIpdOwc4UJGR0d0CV6PYDz/4AuPMi4KnvsOFoX8dMbN1fgc1GszmZ05DHB5wNS7QCSZGQpPOrnWFGaV3brMxjtI+/J7WNgzQAcpKQ1Iv9tex0P/IIL3yijsWeU3jpFp74BfD3OHCAHdPCs7mufvMj/Psd/SFg9wvAjxYCj3yOJaCqaexgoxVgEeDN+4AmJaJU2asdaqfQpe8yti8zH72V7BwsTsHGFLIhH0WZgt/ct73yKBnUZuAUJKpb2CHvfA5oNfplta7gxPeOZ/ma69oGvO1jwNn/57ADQyb1xPnOnSCZAsCBRLIgAk75IjuuAqG0nEJLDSIC2HJQYQvTDbbQMI+jrL42jihCo4Z8YVzcLUdxhYcQJiOQddkyQu1v531I/dClyEfeCv7Bq1v45u9rA+55H3DvBzkilkZs/2t8jO1P8f89u83JX1KWkvRe6siAddF0wGQLqvFwWlT8wDqOmN78KwDBUWJ1i+EUVPnGy4wqPMazliV8VWxgnZJtgHkjH9xgvta9E3jmJh7H4e8Bzvs+77f9DeDRLwB/u44dl5pTkOOIxxTs38eOZ4Cph7Hxkw5rpFthHsb+ph1mvgZwoNByJLDAMPyyBr3G4Sb1+vn7VeUjITh3MPcU/r9vr9mS4+QvMtv85+f5PC74MXDdC8ARlzOD2PA3Dj5qWk356D/f5O/l+OtM1iWbFEoHpk6eUhsizjuNq1skQ6ibaTrQ8jrbPAXjM+4yaxvodGFhCpnIR8p1Zdf6k0W0HcuAWUrq9gBzTuTmhm/9kyfCnfs9jurtkDPnU4HqwOam4BSKACXnFABgs5pslssDSqewb41VDpBGdfpRnLwcaDflI+kUOrdwxN/5lrkiFWCVj2RJ2kmf5+jst+/g6GSkh6NFmcTet5aN2+ABvlAjQY5wQGbE27SEH1UNWnZIlfBVMDNRaausT1edgtTLo1VEczm67muzloS6PMyKfNXAzOPMz/tr2YjYSw0l5I0cGDCTb9v+w/X/Z38beM9v2HgBwL8l92oAACAASURBVMu3ctQ91s8JQUtOw20ez47KRv79dr/I/48NArtfNtfYlfMmgFjmoS6OAgDn/wi4+t/m9yY1bXsdvERZjTXR3LmVDf/yy/j36N1rLBXZDMw6jqPG0T5eg8Dj4+O/6+d8HQaH+betncEs8I17mXUc+zHgmA+b0WOUgRrGftYJ5jl5ysxyxykL2QjK/0//GrdKAHhsQx0sZarJ4MYFVieZLiw5hQzko6pp/JuV1aaffFV/O9lZFzAbN7a/wbJsPJx+g/m9JQtPGZ9vzYz4LLpIUVJOYVZDBSp8bry5TzH6FqfQarYFkBGKjHhk/mH/63yTu8uAFuOzf/8E8IcLuJyvYa5Ze6wmmuWN0bQIePv/sNQkI9w3/8qPdbOZKchlBldezY/b/mMuiQiwEayYEssUVM1TygQq6mYDIKtT2LeGz1u2M2iYZzoFS6RuPM471ZrkPOPrXP0RD2pyUFL3Lf/iR5mXqJvF57Px72zwDruEZZau7Q45BYekHsCOZdcLnPfY9TyPXUb7bq+pTdvPR45BwuW2zsCV14G9Dl5CrtcrsedlfpT191GmYGjVp32VI3zZJkMe850/43OfsZKPOXiQZ8w3LWEmRWSyFYssCUPyAxt/IlOmaZgHXPhjTrjK70EGJ3NPZecVsslH2ZCOAGv1ka+Kv2d5r6UCl4udYSpJZjvkd09urjiUmHeq+XzxBYgL9XtLBc1HcOO+TMt784yScgouF+Ht8xtx16rd+N6jmxAKR4D5Z3DflsXnmTe+vw5Y8WF+Lm+85uV8M+9/zZCJWlgmqpjCN8DFtwMf/gfvS8pH6s2rlome8mXg1OuBD97PUdDGf/DrR1zGDOG5H3HZ3Fzjoh3qMJdElGhaYmMKPbHykX1qvdfPhsrOFFpXAOd8B3j/vVxfXdvKxmzwoHkO0pjK6Fti6lJOfMeDr8qMGhuNWcA9Oznyk8yHyKT1c0/h77CshidyqdVCQPxoc95prNO3rWGZy1tpbbsgozV7iWuLzSnYIZ2Jk3wEcAWSKh/tXcXsqHEBG/eOzSzPScM050TgS9tjv8eWI7kaZfl7TXayfy1XyUjHGHUKSrBRXm8yR9lO21/D2/oq2eFOXRI77uWXAhfcDIB4vC43G+35Z4z/fSQLdZ6Cyw1c97xZsZYqpi6zdmpNFXLewbRl1nti6jKWeRoXZM8ZqpD2YIKh5Bri3fL+o/Htf27Cr57bgc7BAM5f3oyfrz0K73V14P1VLewlZxzLUeZT3zZLw3wVrOW3v86VOtXTzc6F5XXWxJKTfORVKoV8FcDpX+Xn05YxffXXAgveATz3Q5ZNLriZaa/HaGom8wkSTYu5xFEIs222GkX7HJgCwExGzlUY6uR8yLEf5TEvNqpq6mZzYq68ATj2Gn5NGuX5Z8buczwQ8Y3X38aGsbqF5Zbm5dYIqnUFsPVx0zlffhdw57tMhzJeohkwNHxifXjL46zjWiqv5nKliVtxMuR2bmamomE+H1Pmnuywy0d7XubWC0TsFCTrUyUMe826hLxu1CTjYRebz2XQEjW4ZRxBy+1leXDz8uQ08GOvAeaeZjq+a59J/JlkUVYNXkuhPuGmCXHxLxEzKTQVeHzsVOacYn2dCHjnLemxgGRANOFYAlCCTqHC58F3L1mOadV+/OQ/W/DA2jZU+z342t/WY920TnwfYKfQchRw8e0YnH0mtu3txaJpVaiYfhRLH24fT94CnCOMcluiec5J8Vt0txzFTqFxIUetFY3A2z9l6v/1c1gmanRwCqN9HM17y7mu3sIUKqxzFCQaF3C5bWjMzCfMONa6zRGXmzKOrMV3efiz9WkkISsbDafQwgyr863YCH3J+dzHZ8k7+f/ZJ3CrhWhkb0TL8SpYyus50n3p58zoLviR9X0ZaapMYcqiWDZlh78G+PKu+De3vwbo7ODqqZEeZmErjNYLao29U6ljPEjJatpya2dPub/ovJcKZkB+Y8KizB2882fJH2tKignUZFHRAFz9L2ZAmaI8jmSYCq55MrbxHjB+LqFEUXJOQeLTZy6Ax00YHAvhM2cuxL/WH8DNj0TwZPhofP+JRnjXvYBPnXEabvrtBuzqGoaLgC8sOgEfjzwG18hBbB+rxRPPbseVJ8xGhc/2NcqLWEZ0Z3w9/kCmHwWs/SPf/N5y4AtbrEnbhnnsFOxMQSbMdr9ozqxUmcLx11lLTyWWXMiVLhsfAna/xMbRfuP6a0z5TOLET8c2GUsWsmqmutmUQOxafvNy4OMvWF9TNV+317l3joqlF/J8iPfcEdv2wC4fLXtX8iWS47XF9tdyUviOd5j5KJn4tTiFOIlqJ9S08n7l6mLq64B5XV3yK6N9CXG0n07JZy6hyneFRjx2phGDknUKRIRPnm5GSRcf3Yozlk7Ffa8chjMGA/j7a/tw3V1rUV/hxQ/ecwQ2tvfjp6sIt4VvxvnuVXhh/XK0r9+Mv63dh2tOnguPm7C7axitdeU4f3kLKv21sbNODQgh8PzWThw9qw7VMoEdndtg+0lkhGtnCq3HMCPZ+oT5WTWiiqcNzzudHcyz3+fS0JVXJWfsj7gs8TbxIJOEVc2mcUyk5dvh8iSOGE/8LCfnnSSLBptTOPXLqR0/HspqWT5yeVk/Huk1E+pqS2V7k7Xx4PUDn11vWzwesfLRjBXmexfc7BwJa2ikiJJ1Ck6o8XtxzclshD9+2nzc9d/dOO/wZsxrYq32yhNm48lNHRgNHonvz6xDRAh87t7X8aX711n287W/rcfTvnKMdI1heiCEzoEA/r3xAF7f24sLj5iOZ97qwF9e2YspVT585ZyFuPTtnwEtv9R5UAvfwfKSfZq8y83Jyq1PcHkjkJx+63JxDuHxGzjyPvX6xJ/JFLJmu3oa5wx6dqbeSqFySvy5EBIud/zvQH5/rixf8lJeW3kVzzhXIZmCKu2kul8VUafgEGw41ddraKQB7RTioLbca2ESADCvqSrqICRe/uqZ6OgfQzASQWtdOdbv68MTmw5i86bjsLarDH/8zpMYHAtF9/nIOp7j8KHjZ2Njez++9MAGPLzwAlxQ50JT9UE0VZdh0bRq+L1Ku4V5pzkPcuHZXM76z8+zwVRrsMfDUR/geQAnfyGz9sjJ4vB3m/XzM1aaq0+lgnNvSryU6HjwVbL8kiiHkCqmLmUGdLJDK+bKqRzVVzdnJ+HoKeMJeU6LumhoZAkknLo1FjFWrlwp1qxZk3jDIsCqHV3486o9OGJGLc5e1ozpdX48+No+QACXHTsTkYjAn1ftxk2PbcZQwExEl3lcmNVQgX29Izhz6TR8++LDUVvuRSQicGhwDG09I6jwuTG3YhT+nywCIIDL/5xayV8knJ1JShMJe18xJ7plE0LEN/o/O4qd0VX/zM6x5JoQE7CqRaOwIKJXhRAJ1/TUTqEIEAhFcGhwDIcGxtDeO4LVu7qxt3sEdRVe/P21ffB5XKgq86B3OIhA2FyRy+Mi3Ff1I9TW1KD6ynswtaYcL23vxA0Pvgm/141jZtfjqrfPwfymKrhc2ogUBK/dxQngZe8q9Eg0ShzaKUwSvLG3F/e/2oZgOIK6Ch9a68vRWufH4FgYm9r7sWp7J17b2wO3y40zlkzF81s70Vzrx9wplXhxWyfGQuxEZtSX44IjWvBmWx+6hwK44rhZOHZuAyp9HowEwxgOhFFV5saCqax9CyFADtFoKBzB3av3oGswgHcf04rZjWlWJGloaOQVReEUiOhcAD8D4AbwWyHETbb3PwLghwBku89bhRC/HW+fpeYUksGOQ4O4e9Ue/PXVNkyrKcOfrzkeTdVl6Bocw8Nv7EfPcBCv7enB81s7MbuxArXlXqxrc14t7JRFTRgLhrF2Tw+WNNegssyNwbEQWuvKUVvuxcb2fqzf1w8iVk2On9eAdyxrRmtdOSp8buztGcZzWw5hU/sAvG7Cp85YiNMXT0VNuSfqZF7a3olfPL0Nx8yqx+fOWqRZjIZGHlBwp0BEbgBbALwDQBuAVwC8XwixUdnmIwBWCiH+J9n9aqcQHwGDFfg8znX1A6NBVJVxbcGG/f3Y3TWMobEQyn1uVPjceOvgAH793A7Ulntx2qImbO0YRDAcQYXPg329IxgaC6HC58ZnzlqEt81pwANr23Dfmr3Y3TVsOU5rXTmOmlmHnZ1D2GgsajSlyocPHT8Ha3Z34/mtnajxe9A/GsKJCxqxrKUGjVVlaKnl2eOLm6uxeFo1ntrcASLg9MVTMTgWgosIlWW6NkJDIx0Ug1M4AcCNQohzjP+/CgBCiO8p23wEWXAKwWAQbW1tGB0dzcbQNQz4/X7MmDEDXq/zfAuAZabuoQDa+0YxGgyjrsKL+U1VICJEIgLPbOnAjkNDeHbLITy/tRP1FVzV9cHjZ+PuVXvwi6e3YTgQxkjQOuO7ta4c+3p5MZ6lLTXYcWgQZR4X/u/iw9EzFMD6/f0YC0VwsJ9/81MWTsGM+grMbCjHitk8Uam9bwSrd3ajqaoMb5vbAI/b6iz3dg/jqc0dOHVRE+ZMcZbBhBAYGAuhuszjKKdpaEwUFINTuBTAuUKIa4z/PwTgONUBGE7hewAOgVnF54QQex12F4WTU9i5cyeqq6vR2Niob9wsQQiBrq4uDAwMYO7c7LT+3d01hIZKH6r9sU5mYDSIg/1jEELgiU0H8exbh/DuY1oRCEXw51V7sGJ2Pda19UU73E6rKUO5142p1X4MB0NYv8/sP/SeY2age2gMT791KPpatd+Dw6fXIhwR2Nc7gppyL7YcHEA4IkAEXHTkdNxwwVLc+tQ2rN7ZjWq/B8OBMPb3jqBnOIi3zWnAl85djJWz67Hl4CC2HBzABctb4HIRXtjaie//azOOndOAr1+wFC9u78S0Gj8WTatG73AAI8Ewmmv8+trUKCiKwSm8F8A5NqfwNiHEp5RtGgEMCiHGiOg6AJcJIWKm4hLRtQCuBYBZs2at2L17t+X9TZs2YcmSJfqmyzKEENi8eTOWLl2aeOM8YDQYxr/WH8Di5uro2hgS3UMB9A4H8MDaNtz2zHbUlntx9YlzccaSqWjrGcFzWw9hw/5+eF2EGfXl6BsJYn5TFS45phX/XNeOXz3HnWPDEYGTF06JymbTasrQVFWGu1fvRefgGGY3VmBP9zCE4PxLJCLwwrZONFT60D0UwMyGcuztHoHP48J7V8zA317bh+FAGA2VPpR5XPB73Wio9KGx0ocVs+tx9Ulz8dL2Lqze2YVqvxeDoyFMrSnDFcfNRtfQGN5s68Mxs+pRX2ld9UsIgQ37+zG1pgxTqwu3nq/GxEExOIWE8pFtezeAbiHEuCtxODGFTZs2FY3hmmyYiN/tjkODaKouc2Qk8fDKrm7c8uRWXH3SXJy+eGrM+0NjIfz99X149M12HDGjDlOqyvD9xzajvtKLj540F1eeMAd/eGkXfvv8Tnzs5Ll4YVsnnt/aidMXN+GURU146wCzkpFgGN1DARwaGMPWjkFMqynDwf6x6HFcBEQEcOKCRmzc34+e4SCIgPoKH/weF/pHQ6j2e+Aiwr7eEVSVefCFsxehxu/FvKZKzJ1Sic/e+zqGxkL45jsPw+Gt5u301oEB9I0EsXJ2PYiA9r5RbO0YxNLmagQjAj96/C0sa6nBh98+J25eSmPiohicggcsCZ0Jri56BcAHhBAblG1ahBDtxvNLAHxFCDFuFy3tFPIL/d3Gx9BYCF63y9GAhiMCOw4NYsHUqrgM9rE323HzE1tw0ZHTce2p8xAKC5R73bjz5V3430c2YklzDb54ziJsah/A/t4RjAYjqCn3oG8kiMHREE5d3ISHXtuP1bvMxodVZR4EQhFU+z3oGgqgta4c02rK0D8awrYOXht8eq0fI8EweoZ5hriLuDghHBEIhgVm1JfjrKXTcPZh0zCroQI/fmIL1uzqQf9oEOcsa0ZzrR/bDw1iSlUZyrx87h87eR6mVFlbta/f14f5TVUo95XYJMkiRcGdgjGI8wH8FFyS+jshxHeI6H8BrBFCPExE3wPwLgAhAN0APi6E2Bx/j8XpFLq6unDmmbzOwIEDB+B2u9HUxO0jVq9eDZ8v8YLfV111Fa6//nosXpxiT6Aco9DfbamirWcYU6v9CSP2cERgU3s/yn1uPPPWIfx7wwF86ZzFWDitGves3oON+/vRPRSA1004eWET6iu9ePTNA2io8OGw1hrMb6rCS9s70dE/hk+fuRBbOwbwh5d2Y/XOLowGuZqtzOPCWcumwesiPL7hIEZDYcyoL0fPUBCBUARhIbBiVj1+9aEV+NeGA/C6XXhi4wE8vuEgZtSX49pT5sHvcSMUEair8OL0xVPx2p4evLa3F+ccNg3/Wn8AT2zqwLuPbsVx8xoQCgssmlZtOfeuwTHct6YNFx89HS21ybUqGQ6E4Pe4dcmzgaJwCrlAMToFFTfeeCOqqqrwxS9ae+EIISCEgGu8NsxFiGL6bjXyh9FgGI9vOIDNBwZwxXGzMKOeO7COBMKICGEpDf77a/vw2Xtfh9dNCIbZnpR5XLj6pLl4ctNBbDk4aNm3z+OKlk9LzGmswC6ltNnvdWF5ay3mTalCXYUXD6zdh87BMdT4Pbjm5HmoLfdiV9cQCIR3LJsGj5sQjggsm16DVTu6ce8re/DU5g4cNr0WN192JBZNMydl7ukeht/rxrQaP6T929E5hG8/shFEhO+9ezmm1Uy+PE2yTmHSFX1/6x8bsHF/f+INU8Cy6TX45jsPS/lz27Ztw8UXX4yTTjoJq1atwiOPPIJvfetbWLt2LUZGRnD55ZfjG9/4BgDgpJNOwq233orDDz8cU6ZMwXXXXYfHHnsMFRUVeOihhzB1aqzOraGRK/i9blx0VCsusr3uJAVdfHQr9nQPY8P+Pnz8tAWoLfeiqsyDpuoyfPHsxdjfOwIiwO0i7OwcwmNvHsCiaVU4bfFUPLa+HQunVeO0RU1Yu6cHB/vHEBECa3b1YOP+fjy5uQO9wwEsbq7G99+zHLc9sx0/fmILj8XrRkQI/O7FnTFjaqouwwePn41H1rXjwltewGfOWojhQAj3rN6L7qEAAKCuwovhsXC0dUy134NQWODcnz6Hz561CGcunYo93cPYcWgIPrcL5xzWjNqKxHmqNbu68cDaNtxw/tKU8lrFgknnFIoNGzduxO9//3vcfjsvbn/TTTehoaEBoVAIp59+Oi699FIsW2ZdErKvrw+nnnoqbrrpJnz+85/H7373O1x/fR5aXGtopIlPn7nQ8XW3izCzwVznoaW2HG+fPyX6/7WnmOuEyPklAHDhEdOjz9WWK2csmYqhQBgjgTAaK30YDobx4rZO+L1uhCMRrGvrw7KWGpy+ZCq8bhc+feZCfP1v6/HDx3k98/MOb8Ypi5owHAhjW8cgaso98HvcKPO68N4VM9E3EsQND76Jbz68Ad98OJr+BAB8/e/rMX9qFco8Lmxq70dDpQ/1FT7s6hrC8tZaXHH8bPSNBPHtRzZiLBTB0FgYXzlvCe5f04adnYNYOacBHzw+duXCobEQbn92O845rNlSGKBiNBhGmceVlwrLSecU0onoc4n58+fj2GPN5S7vuece3HHHHQiFQti/fz82btwY4xTKy8tx3nnnAQBWrFiB559/Pq9j1tAoJqiGkIhQVeaJzsyvKvPgnMPMpU7PWGJdzGhKVRl++cFjsHpnN+oqfFjcPP66Fv9/e3cfXFWd33H8/U2ABCGQlchjFMKiq+jGECgyIgyWfSCIBGlmIYtbRRna6A5La9t1xW3XDs7U1lJk1roDs3F3HbrR4iK0I6CbTUGLPAXhElCeNMxiQoAoD0KKBH/945xcbi65IcHccy/h85q5k3N/99yTb37n5H7v7zx8zw0Zabz6F2N472A9B4+fYWiWd0ZX/edf8N+7ath35DQN5y/w/btu4sTZ83x65gvyB2fy+z1Hmffb9wHIze7NmKF9WLrhI9ZU1XLhS8f1Pbrxxo4a9tWdpk+PNM5f+JJv9M9g5OCv8ZPf7WL9vmP8+/8c5AdjBlM0Mpv/CtVw+NMG/mHqcBa9tY+yrX+kS4pRMuHrPPGd+B537HRJIdn06HHxStn9+/fzwgsvsGXLFjIzM3nwwQdbvAo78sB0amoqjY2NgcQq0hmZGXcN7dOu+e8elsXdwy6OaAZmdueb2bHPlv/plAvsPXKa1BTjln4ZpJhx/PQ5UlKMv/r2LQzolc5PV1Xxm/cOYQYp5h0DafL0fbdx4OjnvLLpEL/aWI0ZdE1JofzDOv7v/JfM/JMb6dOzG/mD23Ajra9ISSFAp06dIiMjg169elFbW8u6deuYNGlSosMSka8orUsqudnNbxe7aEZes+cLp93B7LE59OuVRrcuKew9cpr/PVDPDRlpFI307tI3/1u38PYHdYwecj3nGi/wdytCFOYNomRC1O1440hJIUD5+fkMHz6cO+64g6FDhzJ27NhEhyQiATEzhvW9eOfG3OzMSxJJ/97p/CDiuMPa+eMDi6+JTkmVVqlvRTqHtp6SenWdNC8iInGlpCAiImFKCiIiEqakICIiYUoKIiISpqQgIiJhSgodYMKECaxbt65Z2+LFi3nsscdivqdnT+985ZqaGoqKimIuN/r022iLFy/m7NmL1SUnT57MiRMn2hq6iEgzSgodoLi4mLKysmZtZWVlFBcXX/a9AwcOZMWKFVf8u6OTwptvvklmZmYr7xARia3zXdG85kk4sqtjl9n/m1DwTzFfLioq4umnn+bcuXOkpaVRXV1NTU0NeXl5TJw4kc8++4zz58+zcOFCCgubFyOurq5mypQpVFVV0dDQwOzZs9mzZw+33XYbDQ0N4flKSkrYunUrDQ0NFBUV8cwzz7BkyRJqamq49957ycrKoqKigiFDhrBt2zaysrJYtGgRpaWlAMyZM4f58+dTXV1NQUEB99xzDxs3bmTQoEGsWrWK7t3bduMSEencNFLoAH369GH06NGsXbsW8EYJM2bMoHv37qxcuZLt27dTUVHBE088QWtXkL/00ktcd911hEIhFixYQGVlZfi1Z599lm3bthEKhVi/fj2hUIh58+YxcOBAKioqqKioaLasyspKXn75ZTZv3symTZtYtmwZ77/vVXHcv38/jz/+OLt37yYzM5PXX389Dr0iIlejzjdSaOUbfTw17UIqLCykrKyM0tJSnHM89dRTbNiwgZSUFD755BPq6uro379/i8vYsGED8+bNAyA3N5fc3Nzwa6+99hpLly6lsbGR2tpa9uzZ0+z1aO+++y4PPPBAuErr9OnTeeedd5g6dSo5OTnk5XnFukaOHEl1dXUH9YKIXO00Uugg06ZNo7y8PHxXtfz8fJYvX86xY8eorKxkx44d9OvXr8VS2ZFauonGxx9/zPPPP095eTmhUIj77rvvsstpbUSSlnbxBusqzS0ikZQUOkjPnj2ZMGECjzzySPgA88mTJ+nbty9du3aloqKCQ4cOtbqM8ePHs3z5cgCqqqoIhUKAV3K7R48e9O7dm7q6OtasWRN+T0ZGBqdPn25xWW+88QZnz57lzJkzrFy5knHjxnXUnysinVTn232UQMXFxUyfPj18JtKsWbO4//77GTVqFHl5edx6662tvr+kpITZs2eTm5tLXl4eo0ePBuDOO+9kxIgR3H777ZeU3J47dy4FBQUMGDCg2XGF/Px8Hn744fAy5syZw4gRI7SrSERapdLZ0ir1rUjnoNLZIiLSbkoKIiIS1mmSwtW2G+xqoD4VufZ0iqSQnp5OfX29PsQ6kHOO+vp60tPTEx2KiASoU5x9lJ2dzeHDhzl27FiiQ+lU0tPTyc7OTnQYIhKgTpEUunbtSk5OTqLDEBG56sV195GZTTKzvWZ2wMyebOH1NDN71X99s5kNiWc8IiLSurglBTNLBV4ECoDhQLGZDY+a7VHgM+fcMODfgOfiFY+IiFxePEcKo4EDzrmPnHNfAGVAYdQ8hcCv/ekVwERrqfiPiIgEIp7HFAYBf4x4fhi4K9Y8zrlGMzsJ9AGOR85kZnOBuf7Tz81s7xXGlBW97CSSrLEprvZJ1rggeWNTXO1zpXENbstM8UwKLX3jjz5ntC3z4JxbCiz9ygGZbWvLZd6JkKyxKa72Sda4IHljU1ztE++44rn76DBwY8TzbKAm1jxm1gXoDXwax5hERKQV8UwKW4GbzSzHzLoBM4HVUfOsBh7yp4uAPzhdgSYikjBx233kHyP4IbAOSAVKnXO7zewfgW3OudXAL4FXzOwA3ghhZrzi8X3lXVBxlKyxKa72Sda4IHljU1ztE9e4rrrS2SIiEj+dovaRiIh0DCUFEREJu2aSwuVKbgQYx41mVmFmH5jZbjP7kd/+MzP7xMx2+I/JCYit2sx2+b9/m992vZm9bWb7/Z9fS0Bc34jolx1mdsrM5ieiz8ys1MyOmllVRFuLfWSeJf42FzKz/IDj+hcz+9D/3SvNLNNvH2JmDRH99ouA44q53szsJ35/7TWz78YrrlZiezUirmoz2+G3B9lnsT4jgtnOnHOd/oF3oPsgMBToBuwEhicolgFAvj+dAezDKwPyM+BvEtxP1UBWVNs/A0/6008CzyXBujyCdyFO4H0GjAfygarL9REwGViDdz3OGGBzwHF9B+jiTz8XEdeQyPkS0F8trjf//2AnkAbk+P+zqUHGFvX6vwJ/n4A+i/UZEch2dq2MFNpSciMQzrla59x2f/o08AHeld3JKrIUya+BaQmMBWAicNA5dygRv9w5t4FLr6WJ1UeFwG+cZxOQaWYDgorLOfeWc67Rf7oJ71qhQMXor1gKgTLn3Dnn3MfAAbz/3cBj88vtfA/4bbx+fyytfEYEsp1dK0mhpZIbCf8gNq8q7Ahgs9/0Q3/4V5qI3TR4V5O/ZWaV5pUWAejnnKsFb2MF+iYgrkgzaf6Pmug+g9h9lEzb3SN43yab5JjZ+2a23szGJSCeU+HlbAAAA7tJREFUltZbMvXXOKDOObc/oi3wPov6jAhkO7tWkkKbymkEycx6Aq8D851zp4CXgK8DeUAt3tA1aGOdc/l4lW0fN7PxCYghJvMugpwK/KfflAx91pqk2O7MbAHQCCz3m2qBm5xzI4C/Bv7DzHoFGFKs9ZYU/eUrpvmXj8D7rIXPiJizttB2xf12rSSFtpTcCIyZdcVb2cudc78DcM7VOecuOOe+BJYRx2FzLM65Gv/nUWClH0Nd01DU/3k06LgiFADbnXN1kBx95ovVRwnf7szsIWAKMMv5O6D93TP1/nQl3r77W4KKqZX1lvD+gnDJnenAq01tQfdZS58RBLSdXStJoS0lNwLh76v8JfCBc25RRHvkPsAHgKro98Y5rh5mltE0jXeQsormpUgeAlYFGVeUZt/eEt1nEWL10Wrgz/2zQ8YAJ5uG/0Ews0nAj4GpzrmzEe03mHe/E8xsKHAz8FGAccVab6uBmebdfCvHj2tLUHFF+BbwoXPucFNDkH0W6zOCoLazII6mJ8MD7wj9PrwMvyCBcdyDN7QLATv8x2TgFWCX374aGBBwXEPxzvzYCexu6iO8UublwH7/5/UJ6rfrgHqgd0Rb4H2Gl5RqgfN439AejdVHeMP6F/1tbhcwKuC4DuDta27azn7hz/tn/jreCWwH7g84rpjrDVjg99deoCDodem3/wr4y6h5g+yzWJ8RgWxnKnMhIiJh18ruIxERaQMlBRERCVNSEBGRMCUFEREJU1IQEZEwJQWRKGZ2wZpXZe2wqrp+tc1EXU8hcllxux2nyFWswTmXl+ggRBJBIwWRNvLr6z9nZlv8xzC/fbCZlfsF3srN7Ca/vZ959zHY6T/u9heVambL/Fr5b5lZ94T9USJRlBRELtU9avfRjIjXTjnnRgM/Bxb7bT/HK12ci1d0bonfvgRY75y7E69u/26//WbgRefc7cAJvKtlRZKCrmgWiWJmnzvnerbQXg38qXPuI79g2RHnXB8zO45XquG8317rnMsys2NAtnPuXMQyhgBvO+du9p//GOjqnFsY/79M5PI0UhBpHxdjOtY8LTkXMX0BHduTJKKkINI+MyJ+vudPb8SrvAswC3jXny4HSgDMLDXgexaIXBF9QxG5VHfzb9juW+ucazotNc3MNuN9oSr22+YBpWb2t8AxYLbf/iNgqZk9ijciKMGryimStHRMQaSN/GMKo5xzxxMdi0i8aPeRiIiEaaQgIiJhGimIiEiYkoKIiIQpKYiISJiSgoiIhCkpiIhI2P8DYl7eYeVF2ngAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(last_his_model3, \"rb\") as input_file:\n",
    "     his_model_3 = pd.DataFrame(pickle.load(input_file))\n",
    "\n",
    "with open(fur_his_model3, \"rb\") as input_file:\n",
    "     his_model_3_fur = pd.DataFrame(pickle.load(input_file))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure()\n",
    "plt.plot(pd.concat([his_model_3['acc'], his_model_3_fur['acc']], axis=0, ignore_index=True))\n",
    "plt.plot(pd.concat([his_model_3['val_acc'], his_model_3_fur['val_acc']], axis=0, ignore_index=True))\n",
    "plt.title('Model3 Further inceptionV2 accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure()\n",
    "plt.plot(pd.concat([his_model_3['loss'], his_model_3_fur['loss']], axis=0, ignore_index=True))\n",
    "plt.plot(pd.concat([his_model_3['val_loss'], his_model_3_fur['val_loss']], axis=0, ignore_index=True))\n",
    "plt.title('Model3 Further inceptionV2 loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 3])\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above loss graph, we can see that trend of loss value of validation set was already incresing that mean <b>overfitting of the model.</b> And as I already mention that the lowest validation loss of further training model is higher than the lowest validation loss from the last best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model 4 (InceptionResNetV2 pretraining model (freezing weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model4 inceptionV2 freezing weight...\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 95s 340ms/step - loss: 1.0832 - acc: 0.5425 - val_loss: 0.7696 - val_acc: 0.5344\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.76956, saving model to best_inceptionV2_freeze.hdf5\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 77s 276ms/step - loss: 0.7189 - acc: 0.5478 - val_loss: 0.7833 - val_acc: 0.5249\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.76956\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6882 - acc: 0.5672 - val_loss: 0.9812 - val_acc: 0.5067\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.76956\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6895 - acc: 0.5443 - val_loss: 0.6944 - val_acc: 0.5580\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.76956 to 0.69443, saving model to best_inceptionV2_freeze.hdf5\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6783 - acc: 0.5743 - val_loss: 0.8889 - val_acc: 0.5040\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.69443\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 77s 276ms/step - loss: 0.6752 - acc: 0.5796 - val_loss: 0.7069 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.69443\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6819 - acc: 0.5761 - val_loss: 0.6978 - val_acc: 0.5310\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.69443\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6735 - acc: 0.5810 - val_loss: 0.7542 - val_acc: 0.5229\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.69443\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 77s 276ms/step - loss: 0.6699 - acc: 0.5954 - val_loss: 0.7645 - val_acc: 0.5431\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.69443\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6710 - acc: 0.5896 - val_loss: 0.7291 - val_acc: 0.5337\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.69443\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 77s 276ms/step - loss: 0.6750 - acc: 0.5816 - val_loss: 1.0589 - val_acc: 0.5195\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.69443\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6732 - acc: 0.5861 - val_loss: 0.6963 - val_acc: 0.5391\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.69443\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6704 - acc: 0.5730 - val_loss: 0.7233 - val_acc: 0.5512\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.69443\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6678 - acc: 0.6032 - val_loss: 0.9928 - val_acc: 0.5182\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.69443\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6692 - acc: 0.5930 - val_loss: 0.7149 - val_acc: 0.5350\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.69443\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6583 - acc: 0.6148 - val_loss: 0.8559 - val_acc: 0.5343\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.69443\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6657 - acc: 0.5932 - val_loss: 0.7395 - val_acc: 0.5189\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.69443\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6671 - acc: 0.5903 - val_loss: 0.9621 - val_acc: 0.5121\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.69443\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6650 - acc: 0.6050 - val_loss: 0.7414 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.69443\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6656 - acc: 0.6005 - val_loss: 0.7126 - val_acc: 0.5485\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.69443\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6654 - acc: 0.5934 - val_loss: 0.7921 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.69443\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6642 - acc: 0.5990 - val_loss: 0.7163 - val_acc: 0.5512\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.69443\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6615 - acc: 0.5996 - val_loss: 0.7533 - val_acc: 0.5222\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.69443\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6535 - acc: 0.6083 - val_loss: 0.8641 - val_acc: 0.5371\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.69443\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6571 - acc: 0.6039 - val_loss: 0.7301 - val_acc: 0.5593\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.69443\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 78s 276ms/step - loss: 0.6621 - acc: 0.6021 - val_loss: 0.7994 - val_acc: 0.5404\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.69443\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 78s 279ms/step - loss: 0.6583 - acc: 0.6112 - val_loss: 0.9854 - val_acc: 0.5142\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.69443\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 78s 276ms/step - loss: 0.6589 - acc: 0.6145 - val_loss: 1.5634 - val_acc: 0.5054\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.69443\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 78s 279ms/step - loss: 0.6549 - acc: 0.6048 - val_loss: 0.7135 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.69443\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 78s 277ms/step - loss: 0.6551 - acc: 0.6121 - val_loss: 0.9893 - val_acc: 0.5243\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.69443\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 78s 277ms/step - loss: 0.6578 - acc: 0.6074 - val_loss: 0.7537 - val_acc: 0.5721\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.69443\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 78s 277ms/step - loss: 0.6579 - acc: 0.6083 - val_loss: 1.1339 - val_acc: 0.5337\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.69443\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 78s 277ms/step - loss: 0.6598 - acc: 0.6057 - val_loss: 0.7748 - val_acc: 0.5350\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.69443\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 77s 276ms/step - loss: 0.6577 - acc: 0.6054 - val_loss: 0.7371 - val_acc: 0.5606\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.69443\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 78s 276ms/step - loss: 0.6563 - acc: 0.6059 - val_loss: 0.7974 - val_acc: 0.5532\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.69443\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 77s 276ms/step - loss: 0.6599 - acc: 0.6125 - val_loss: 0.7345 - val_acc: 0.5539\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.69443\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6572 - acc: 0.6101 - val_loss: 0.7501 - val_acc: 0.5512\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.69443\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6585 - acc: 0.6010 - val_loss: 0.7603 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.69443\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6537 - acc: 0.6108 - val_loss: 0.7999 - val_acc: 0.5573\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.69443\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6570 - acc: 0.6043 - val_loss: 0.9838 - val_acc: 0.5249\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.69443\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6550 - acc: 0.6132 - val_loss: 1.1013 - val_acc: 0.5175\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.69443\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 78s 276ms/step - loss: 0.6487 - acc: 0.6201 - val_loss: 0.7908 - val_acc: 0.5553\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.69443\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6559 - acc: 0.6114 - val_loss: 1.1309 - val_acc: 0.5202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00043: val_loss did not improve from 0.69443\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 78s 277ms/step - loss: 0.6578 - acc: 0.6099 - val_loss: 0.8283 - val_acc: 0.5330\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.69443\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 77s 276ms/step - loss: 0.6525 - acc: 0.6150 - val_loss: 0.8297 - val_acc: 0.5458\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.69443\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 78s 276ms/step - loss: 0.6609 - acc: 0.6005 - val_loss: 0.9981 - val_acc: 0.5317\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.69443\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 78s 277ms/step - loss: 0.6533 - acc: 0.6074 - val_loss: 0.8830 - val_acc: 0.5425\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.69443\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 77s 276ms/step - loss: 0.6575 - acc: 0.6081 - val_loss: 1.1054 - val_acc: 0.5209\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.69443\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 78s 277ms/step - loss: 0.6541 - acc: 0.6154 - val_loss: 0.8333 - val_acc: 0.5350\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.69443\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 78s 277ms/step - loss: 0.6544 - acc: 0.6105 - val_loss: 0.7476 - val_acc: 0.5317\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.69443\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 78s 277ms/step - loss: 0.6587 - acc: 0.6090 - val_loss: 0.9189 - val_acc: 0.5195\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.69443\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 78s 277ms/step - loss: 0.6541 - acc: 0.6025 - val_loss: 0.9378 - val_acc: 0.5263\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.69443\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 77s 276ms/step - loss: 0.6546 - acc: 0.6114 - val_loss: 0.8055 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.69443\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6484 - acc: 0.6274 - val_loss: 0.8983 - val_acc: 0.5276\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.69443\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6542 - acc: 0.6157 - val_loss: 0.8770 - val_acc: 0.5216\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.69443\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 77s 274ms/step - loss: 0.6518 - acc: 0.6234 - val_loss: 0.8864 - val_acc: 0.5236\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.69443\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 77s 274ms/step - loss: 0.6548 - acc: 0.6097 - val_loss: 1.1319 - val_acc: 0.5310\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.69443\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 77s 274ms/step - loss: 0.6523 - acc: 0.6197 - val_loss: 1.1159 - val_acc: 0.5296\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.69443\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6584 - acc: 0.6070 - val_loss: 0.8122 - val_acc: 0.5492\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.69443\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 78s 277ms/step - loss: 0.6547 - acc: 0.6050 - val_loss: 0.8934 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.69443\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 78s 277ms/step - loss: 0.6521 - acc: 0.6139 - val_loss: 0.8594 - val_acc: 0.5364\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.69443\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 77s 276ms/step - loss: 0.6610 - acc: 0.5996 - val_loss: 0.8011 - val_acc: 0.5566\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.69443\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 78s 277ms/step - loss: 0.6535 - acc: 0.6108 - val_loss: 1.0141 - val_acc: 0.5364\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.69443\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 78s 276ms/step - loss: 0.6581 - acc: 0.6148 - val_loss: 0.9027 - val_acc: 0.5323\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.69443\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 78s 277ms/step - loss: 0.6540 - acc: 0.6117 - val_loss: 0.8971 - val_acc: 0.5317\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.69443\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 79s 280ms/step - loss: 0.6513 - acc: 0.6139 - val_loss: 1.2279 - val_acc: 0.5263\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.69443\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 78s 279ms/step - loss: 0.6446 - acc: 0.6319 - val_loss: 0.9726 - val_acc: 0.5472\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.69443\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 79s 281ms/step - loss: 0.6496 - acc: 0.6137 - val_loss: 0.8862 - val_acc: 0.5310\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.69443\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 78s 278ms/step - loss: 0.6505 - acc: 0.6172 - val_loss: 0.8101 - val_acc: 0.5384\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.69443\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 79s 280ms/step - loss: 0.6468 - acc: 0.6226 - val_loss: 0.9921 - val_acc: 0.5296\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.69443\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 79s 280ms/step - loss: 0.6507 - acc: 0.6161 - val_loss: 1.1934 - val_acc: 0.5175\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.69443\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 78s 279ms/step - loss: 0.6568 - acc: 0.6165 - val_loss: 1.2458 - val_acc: 0.5182\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.69443\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 78s 278ms/step - loss: 0.6514 - acc: 0.6197 - val_loss: 1.2212 - val_acc: 0.5168\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.69443\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 79s 280ms/step - loss: 0.6539 - acc: 0.6134 - val_loss: 0.8249 - val_acc: 0.5290\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.69443\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 79s 281ms/step - loss: 0.6481 - acc: 0.6214 - val_loss: 1.6517 - val_acc: 0.5135\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.69443\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 78s 279ms/step - loss: 0.6529 - acc: 0.6181 - val_loss: 1.6749 - val_acc: 0.5040\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.69443\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 78s 276ms/step - loss: 0.6439 - acc: 0.6343 - val_loss: 0.8644 - val_acc: 0.5499\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.69443\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 78s 278ms/step - loss: 0.6521 - acc: 0.6097 - val_loss: 0.9626 - val_acc: 0.5344\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.69443\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 78s 276ms/step - loss: 0.6485 - acc: 0.6145 - val_loss: 1.1017 - val_acc: 0.5317\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.69443\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 78s 277ms/step - loss: 0.6463 - acc: 0.6185 - val_loss: 1.3296 - val_acc: 0.5222\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.69443\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 78s 276ms/step - loss: 0.6472 - acc: 0.6177 - val_loss: 1.2750 - val_acc: 0.5276\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.69443\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6451 - acc: 0.6192 - val_loss: 0.8073 - val_acc: 0.5512\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.69443\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6458 - acc: 0.6301 - val_loss: 1.4436 - val_acc: 0.5128\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.69443\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6516 - acc: 0.6168 - val_loss: 0.9251 - val_acc: 0.5438\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.69443\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6520 - acc: 0.6199 - val_loss: 0.9356 - val_acc: 0.5303\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.69443\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6466 - acc: 0.6248 - val_loss: 1.0510 - val_acc: 0.5270\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.69443\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6371 - acc: 0.6341 - val_loss: 0.8988 - val_acc: 0.5377\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.69443\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 77s 276ms/step - loss: 0.6506 - acc: 0.6103 - val_loss: 1.0314 - val_acc: 0.5296\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.69443\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 77s 276ms/step - loss: 0.6405 - acc: 0.6363 - val_loss: 1.1558 - val_acc: 0.5216\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.69443\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 77s 276ms/step - loss: 0.6392 - acc: 0.6303 - val_loss: 1.0199 - val_acc: 0.5371\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.69443\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 78s 277ms/step - loss: 0.6476 - acc: 0.6228 - val_loss: 1.3412 - val_acc: 0.5189\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.69443\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 77s 275ms/step - loss: 0.6378 - acc: 0.6246 - val_loss: 1.2280 - val_acc: 0.5303\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.69443\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 78s 277ms/step - loss: 0.6494 - acc: 0.6201 - val_loss: 1.8514 - val_acc: 0.5094\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.69443\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 78s 279ms/step - loss: 0.6445 - acc: 0.6283 - val_loss: 1.7189 - val_acc: 0.5115\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.69443\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 78s 279ms/step - loss: 0.6430 - acc: 0.6263 - val_loss: 1.3293 - val_acc: 0.5195\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.69443\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 78s 276ms/step - loss: 0.6453 - acc: 0.6199 - val_loss: 1.0687 - val_acc: 0.5270\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.69443\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 78s 278ms/step - loss: 0.6456 - acc: 0.6250 - val_loss: 2.2689 - val_acc: 0.5121\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.69443\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 78s 278ms/step - loss: 0.6374 - acc: 0.6408 - val_loss: 1.6248 - val_acc: 0.5168\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.69443\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 78s 279ms/step - loss: 0.6475 - acc: 0.6272 - val_loss: 1.6057 - val_acc: 0.5209\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.69443\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 78s 276ms/step - loss: 0.6441 - acc: 0.6199 - val_loss: 1.0465 - val_acc: 0.5317\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.69443\n",
      "Done. Elapsed time 7794 seconds for 100 epochs, average 77.9 seconds/epoch.\n"
     ]
    }
   ],
   "source": [
    "# Start timing\n",
    "start = time.time()\n",
    "\n",
    "# Training\n",
    "print('Training the model4 inceptionV2 freezing weight...')\n",
    "history4 = model4.fit_generator(\n",
    "    generator = train_flow,\n",
    "    steps_per_epoch = TRAIN_STEPS,\n",
    "    epochs = N_EPOCHS + EPOCHS,\n",
    "    initial_epoch = N_EPOCHS,\n",
    "    verbose = 1,\n",
    "    callbacks = cb4,\n",
    "    validation_data = valid_flow,\n",
    "    validation_steps = VALID_STEPS)\n",
    "stop = time.time()\n",
    "etime = stop - start\n",
    "print('Done. Elapsed time {:.0f} seconds for {:} epochs, average {:.1f} seconds/epoch.'.format(etime, EPOCHS, etime/EPOCHS))\n",
    "\n",
    "# Save last model\n",
    "model4.save(last_weight_model4)\n",
    "\n",
    "# Save the history\n",
    "with open(last_his_model4, 'wb') as file_pi:\n",
    "    pickle.dump(history4.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This training model 4 used total time 7,794 seconds for 100 epochs, and average time 77.9 seconds/epoch. We ended up with <b>3rd as the best epoch</b>.\n",
    "\n",
    "Then, I plotted accuracy and loss value for each epoch into line graph as you can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXmcXFWV+L+nu6ur9z1LJx2yEJbsIYRNUEAQ2RFEAUUFF8Rl1NEZh3GcURn9iY4Coo6Ksigq6IAsIovsi8qSQAgkARLI1uks3Z30vlb3/f1x3qt6XV3VXb1Ud9J9vp9Pfaree/e9d99S99yz3HPFOYdhGIZhAGSMdwUMwzCM/QcTCoZhGEYUEwqGYRhGFBMKhmEYRhQTCoZhGEYUEwqGYRhGFBMKBzgiMkdEnIhkpVD2MhF5dpjn+bmI/Odw9k0XIvJhEfnreNcjESLybRGpE5FdY3jOg0SkRUQyx+qcQ2Eoz2sk76q3f8r/C6MvJhTGEBHZIiJdIlIRt36N9wLPGad6neid/9vJyjjnrnTO/fdY1itIoj+5c+53zrnTRnjcHBFpEJF3J9h2nYjcKSJhEblJRLaKSLOIvCwiZwxwzFnAV4CFzrnpI6nfUHDObXPOFTjnesbqnENhNJ6Xj4g8KSKfHI1jGX0xoTD2bAYu8RdEZAmQO16VEZEQ8CPg+fGqw3jinOsA/gB8NLje621fAvwayAK2AycCxcB/An8cQIjPBuqdc3sSbbTeq7E/Y0Jh7LmNvg3Qx4DfBAuISLGI/EZEar3e6ddFJMPblikiP/BME28DZyXY9yYR2SkiOzwzxkDmhK8AfwVeH6jSInKrr0mIyEkiUi0iXxGRPd65Lg+UzRWRH3p1bxSRZ0Uk19t2rIj83eudvyIiJwX2e1JEvisiL3j73SsiZd7mp73vBs9Ecly8iUFE3iEiL3r7vigi74g79n+LyN+83v5fAxrbr4H3i0he4JLfi/4/HnTOtTrnvumc2+Kc63XO3Y8K9yMT3KdTgUeAGV49bw1oOZ8QkW3A4ynci6TP0SvbEvg475n00aYGuWZE5KPeM6oXkf8U1WRPTXBNc706+u/gr0RkT2D7b0XkSynUO/55nSYib3jP639F5Kn43r/3ru8Tkc3iaWci8h3gncBPvOv/SXydE1zDDBG5T0T2isgmEflUYNvRIrJKRJpEZLeIXOutz/Gurd67/hdFZNpg5zrgcc7ZZ4w+wBbgVOANYAGQifZAZwMOmOOV+w1wL1AIzAHeBD7hbbsSbcBnAWXAE96+Wd72e4BfAPnAVOAF4NPetsuAZwP1me0duwC4Ffj2AHWPbgdOAiLA1UAIOBNoA0q97T8FngRmetf4DiDsLdd75TOA93jLU7z9ngR2AIu9+t8F/NbbNid4nfHX492LfcBH0J79Jd5yeeDYbwGHoprZk8A1gWO9CVwaWL4duD7JvZgGdACHJ9l+ElAdWPbr/hvvunJTuBdJn2Pcua7w3oei+Hs00DUDC4EW4AQgG/gB0A2cmuSatgFHer/fAN4GFgS2HTGU9w+oAJqAC7zn9UXv/J8MlO0GPoW+Q58BagAJXNsnB3hf4+/FU8D/AjnAcqAWOMXb9g/gI97vAuBY7/engT8DeV4djgSKxrsdSXs7Nd4VmEwfYkLh68B3gdPRXmWW9wLP8V6+TtQe7e/3aeBJ7/fjwJWBbaf5Lz/aWHUCuYHtlwBPeL+jf0pv+V7gIu/3rQxNKLTTt4HeAxyLNnDtwLIEx/g34La4dQ8DH/N+P0nfhnoh0OXdkz5/8vjrQYXBC3HH/gdwWeDYXw9s+yzwUGD568Bfvd9FqJA7IsE1hIBHgV8McK9OIrFQmJfKvRjsOQbWneDd90PjzpM12DUD/wXcHtiW593rZELhNuDLwHRUKHwf7aDMBRq8557y+4dqy/8IlBO0gxQUCpvi6ueA6YFrS0kooB2oHqAwsP27wK3e76eBbwEVccf4OPB3YOlYtRH7w8dsm+PDbeiLOJc40xHag8oGtgbWbUV7lgAz0D9PcJvPbLTR2iki/rqMuPIAiMg56J/kD8O7BOqdc5HAchvay6pAe2NvJdhnNvAB79w+IVTb8Ym/tpB3zMGYQd974e8/M7AcjATy6+vzG+AbIjITNR1tcs69HDyYZz65DW08P59CneIJXttA92LQ5yjqzP4jKlDfHOCcya65z3vknGsTkfoBjvMUcC5Qjb67T6KCuAN4xjnXKyIpv38Jzu9EpDpZ3b36Qd9nliozgL3OuebAuq3ASu/3J1Ct93UR2Qx8y6mJ8DZUoNwhIiXAb4H/cM51D6MOBwwmFMYB59xW7+U7E30hg9ShavNsYL237iDUrAKwE31RCWzz2Y721CriGuxEnAKslFjIZDHQIyJLnHPnDeV6EtS/AzgYeCVu23a0d/ypfnvFiL+2bu+YVYOctwa9Z0EOAh4arMKgkTsi8gzwYeAM+vt5BLgJ7Q2fOcyGIZiSOOm9EJFKBniOov6Ze1Dz1oPDqAfoe3RY3DHLByj/FPA/qFB4CngW+Dn6rJ/yygzl/dtJ4Jl693ewZxxkKOmda4AyESkMCIbof8o5txG4xBP6FwB3iki5c64V1SC+JRpU8ACqJd00hHMfcJijefz4BPBu78WL4jSc8I/Ad0Sk0Ot9fRntpeBt+4KIVIlIKXBVYN+dqNP4hyJSJCIZInKwiJyY4Pz/idqal3uf+4BfApcnKJsyzrle4GbgWs+5lynqFA5713COiLzXW5/jOUiDjcGlIrJQ1Ol7NXCnd09qgV5gXpJTPwAcKiIfEpEsEbkINT/dP4Tq/xrVAI4Hfhe37WeoH+gc51z7EI6ZjKT3IoXneDPwunPu+yM4/53e+d8hItlo4yfJCnsNZztwKfC0c64J2A28H08oDPH9+wuwRETeJ+oY/xxqmkqV3SR/F+Lrvh01A33Xu89L0f/f7wBE5FIRmeK9uw3ebj0icrKILPEc5U1oB2W/DPcdTUwojBPOubecc6uSbP4noBV15j0L/B5tCEAb7ofRXvhLwJ/i9v0oan5ajzpa7wQqE5y/2Tm3y/+gf/hW59zeEV2Y8i/Aq8CLwF7ge0CG9+c8D/ga2shvB/6Vvu/hbaj/YhdqhvqCV9824DvA37xIkGPjrqceOBuNpqoHvgqc7ZyrG0K97wRKgce8Bg4ATzB/GhWeuyQW9fPhIRy7Dynci4Ge48XA+dI3AumdQzz/OvQ9uwPttTej/onOAXZ7CjUbbgssCxA0s6X6/tUBH0B9E/WoAF81yPmD/Ai40ItMuiGF8pegfoYa4G7gG865R7xtpwPrRKTFO+7FTkOVp3v1bwI2eNf7WyY4viffMMYdEXkSjTb61XjXZbIhIgVoL/kQ59zmcTh/Bmqa+rBz7onByhvpwzQFw5ikiMg5IpInIvloSOqraITcWJ3/vSJS4pkWv4ZqHc+N1fmNxKRNKHi2uxdEB9qsE5FvJSgTFpE/eINJnpdxSvNgGJOU81BzSg1wCGo2GUvTwXFolFodcA7wvlHy1xgjIG3mIy+aIN851yKaSuFZ4IvOuecCZT6LxgBfKSIXA+c75y5KS4UMwzCMQUmbpuCUFm8x5H3iJdB5aMQHqEPnFAkEOBuGYRhjS1rHKXihXKuB+cBPnXPxSddm4g1gcc5FRKQRjZWuizvOFehwfvLz8488/PDD01ltwzCMCcfq1avrnHNTBiuXVqHgxZcv90YD3i0ii51zrwWKJNIK+tmznHM3AjcCrFy50q1alSyS0zAMw0iEiMSP+E/ImEQfOeca0GHxp8dtqsYbweoNYClG49oNwzCMcSCd0UdTPA3BH0J/Kv3TM9+HJgADuBB4fIyjHwzDMIwA6TQfVQK/9vwKGcAfnXP3i8jVwCrn3H1oDpHbRGQTqiFcnMb6GIZhGIOQNqHgnFsLHJFg/X8FfnegQ90Nw5iEdHd3U11dTUdHx3hXZcKQk5NDVVUVoVBoWPtbllTDMMaN6upqCgsLmTNnDhaNPnKcc9TX11NdXc3cuXOHdQxLc2EYxrjR0dFBeXm5CYRRQkQoLy8fkeZlQsEwjHHFBMLoMtL7aULBMAzDiGJCwTCMSUt9fT3Lly9n+fLlTJ8+nZkzZ0aXu7q6UjrG5ZdfzhtvvJHmmo4d5mg2DGPSUl5ezpo1awD45je/SUFBAf/yL//Sp4w/oX1GRuI+9C233JL2eo4lpikYhmHEsWnTJhYvXsyVV17JihUr2LlzJ1dccQUrV65k0aJFXH311dGyJ5xwAmvWrCESiVBSUsJVV13FsmXLOO6449izZ884XsXwME3BMIz9gm/9eR3ra5pG9ZgLZxTxjXMWDWvf9evXc8stt/Dzn/8cgGuuuYaysjIikQgnn3wyF154IQsXLuyzT2NjIyeeeCLXXHMNX/7yl7n55pu56qqrEh1+v8U0BcMwjAQcfPDBHHXUUdHl22+/nRUrVrBixQo2bNjA+vXr++2Tm5vLGWecAcCRRx7Jli1bxqq6o4ZpCoZh7BcMt0efLvLz86O/N27cyI9+9CNeeOEFSkpKuPTSSxOOBcjOzo7+zszMJBKJjEldRxPTFAzDMAahqamJwsJCioqK2LlzJw8//PB4VyltmKZgGIYxCCtWrGDhwoUsXryYefPmcfzxx493ldJG2uZoThc2yY5hTBw2bNjAggULxrsaE45E91VEVjvnVg62r5mPDMMwjCgmFAzDMIwoJhQMwzCMKCYUDMMwjCgmFAzDMIwoJhQMwzCMKCYUDMOYtJx00kn9BqJdf/31fPazn026T0FBAQA1NTVceOGFSY87WOj89ddfT1tbW3T5zDPPpKGhIdWqpw0TCoZhTFouueQS7rjjjj7r7rjjDi655JJB950xYwZ33nnnsM8dLxQeeOABSkpKhn280cKEgmEYk5YLL7yQ+++/n87OTgC2bNlCTU0Ny5cv55RTTmHFihUsWbKEe++9t9++W7ZsYfHixQC0t7dz8cUXs3TpUi666CLa29uj5T7zmc9EU25/4xvfAOCGG26gpqaGk08+mZNPPhmAOXPmUFdXB8C1117L4sWLWbx4Mddff330fAsWLOBTn/oUixYt4rTTTutzntHC0lwYhrF/8OBVsOvV0T3m9CVwxjVJN5eXl3P00Ufz0EMPcd5553HHHXdw0UUXkZuby913301RURF1dXUce+yxnHvuuUnnP/7Zz35GXl4ea9euZe3ataxYsSK67Tvf+Q5lZWX09PRwyimnsHbtWr7whS9w7bXX8sQTT1BRUdHnWKtXr+aWW27h+eefxznHMcccw4knnkhpaSkbN27k9ttv55e//CUf/OAHueuuu7j00ktH5155mKZgGMakJmhC8k1Hzjm+9rWvsXTpUk499VR27NjB7t27kx7j6aefjjbOS5cuZenSpdFtf/zjH1mxYgVHHHEE69atS5hyO8izzz7L+eefT35+PgUFBVxwwQU888wzAMydO5fly5cD6UvNbZqCYRj7BwP06NPJ+973Pr785S/z0ksv0d7ezooVK7j11lupra1l9erVhEIh5syZkzBVdpBEWsTmzZv5wQ9+wIsvvkhpaSmXXXbZoMcZKB9dOByO/s7MzEyL+cg0BcMwJjUFBQWcdNJJfPzjH486mBsbG5k6dSqhUIgnnniCrVu3DniMd73rXfzud78D4LXXXmPt2rWAptzOz8+nuLiY3bt38+CDD0b3KSwspLm5OeGx7rnnHtra2mhtbeXuu+/mne9852hd7qCYpmAYxqTnkksu4YILLoiakT784Q9zzjnnsHLlSpYvX87hhx8+4P6f+cxnuPzyy1m6dCnLly/n6KOPBmDZsmUcccQRLFq0qF/K7SuuuIIzzjiDyspKnnjiiej6FStWcNlll0WP8clPfpIjjjhizGZxS1vqbBGZBfwGmA70Ajc6534UV+Yk4F5gs7fqT865qxkAS51tGBMHS52dHkaSOjudmkIE+Ipz7iURKQRWi8gjzrl4L8szzrmz01gPwzAMI0XS5lNwzu10zr3k/W4GNgAz03U+wzAMY+SMiaNZROYARwDPJ9h8nIi8IiIPisj+NXO3YRhp50Cb/XF/Z6T3M+1CQUQKgLuALznnmuI2vwTMds4tA34M3JPkGFeIyCoRWVVbW5veChuGMWbk5ORQX19vgmGUcM5RX19PTk7OsI+R1jmaRSQE3A887Jy7NoXyW4CVzrm6ZGXM0WwYE4fu7m6qq6sHjd03UicnJ4eqqipCoVCf9ePuaBYdyXETsCGZQBCR6cBu55wTkaNRzaU+XXUyDGP/IhQKMXfu3PGuhhEgndFHxwMfAV4VkTXeuq8BBwE4534OXAh8RkQiQDtwsTM90jAMY9xIm1Bwzj0LJM4eFSvzE+An6aqDYRiGMTQszYVhGIYRxYSCYRiGEcWEgmEYhhHFhIJhGIYRxYSCYRiGEcWEgmEYhhHFhIJhGIYRxYSCYRiGEcWEgmEYhhHFhIJhGIYRxYSCYRjGeLPpMejtGe9aACYUDMMwxpfd6+G3F8DGR8a7JoAJBcMwjPGlo0G/W/eMbz08TCgYhmGMJ93t+t3eML718DChYBiGMZ5EvFnnOkwoGIZhGKYpGIZhGFFMUzAMwzCi+JpCR+P41sPDhIJhGMZ44msKZj4yDMMw6DbzkWEYhuETMUezYRiG4RPUFJwb37pgQsEwDGN88TWF3gh0tY5vXTChYBiGMb74mgLsFxFIJhQMwzDGE19TgP3C2WxCwTAMYzwJagr7gbPZhIJhGMZ4EmmHzLD+Nk3BMAxjktPdAYXT9fdE1hREZJaIPCEiG0RknYh8MUEZEZEbRGSTiKwVkRXpqo9hGMZ+SaQdCiv19wTXFCLAV5xzC4Bjgc+JyMK4MmcAh3ifK4CfpbE+hmEY+x/dHVAwBZCJrSk453Y6517yfjcDG4CZccXOA37jlOeAEhGpTFedDMMw9jsi7RDKh5yiyROSKiJzgCOA5+M2zQS2B5ar6S84EJErRGSViKyqra1NVzUNwzDGnu4OCOVATvGENx8BICIFwF3Al5xzTfGbE+zSb5y3c+5G59xK59zKKVOmpKOahmEY40OkA7JyIadkYpuPAEQkhAqE3znn/pSgSDUwK7BcBdSks06GYRj7Fd1tqinklkxsTUFEBLgJ2OCcuzZJsfuAj3pRSMcCjc65nemqk2EYxn5FT0RzHu1HmkJWGo99PPAR4FURWeOt+xpwEIBz7ufAA8CZwCagDbg8jfUxDMPYv/BTXOxHmkLahIJz7lkS+wyCZRzwuXTVwTAMY7/GT3GxH2kKNqLZMAxjvIjXFHo6++ZCGgdMKBiGYYwXfTSFYv09ziYkEwqGYRjjRVBTyCnR3+NsQjKhYBiGMZr09kJXW2plg5pCricUTFMwDMOYQKy+Ba5bBJ3Ng5eNagq5kFOqv01TMAzDmEDUvwXte2HTo4OX9TUF39EMpikYhmFMKNr36feGPw9e1tcU/JBUGPekeCYUDMMwRhO/p//mw4OHlwY1hZwi/W3mI8MwjAlEe4NOr9nVApufGrhsUFPIDEF2gZmPDMMwJhTt+2DeSRAugg33DVw2qCnAfjGq2YSCYRjGaNLRAAVT4dD3wusPaNK7ZAQ1Bdgv8h+ZUDAMwxhN2vdp477gHI1C2vb35GW7OwCBrLAum6ZgGIYxgehu10lzckth/qmQlTNwFFKkXcuIlzvUNAXDMIwJhN/LzymB7HwVDBv+rKOcE+FPxemTU2whqYZhGBMGv5fvD0Q7+N3QvBMatycuH2mP+RPAzEeGYRgTCr9Bz/VSVpTM1u/mJBNKxmsKuSXQ3Qo93emr4yCYUDAMY3yp2wiN1eNdi9HBH83sj04umqHfTTsSl4909NcUYFy1BRMKhmGMDw3b4E+fhp8cBfd9YbxrMzp0xGkKUaGQTFNo768pBI8zDqRzjmbDMIzEvHgTPPTvGnWTXwGtteNdo9HB1xT8xj2nGEL50FSTuLxpCoZhGMA/fgJTD4d/Wg1zT9SUEBOB9gZAIOzNoiai2kIy81F3W//oIxjXCCQTCoZhjD2dLTDjCCiugnBBanMPHAh0NGjDnhFoWosqk2sK3R06TsHH1zDefkJNS+OACQXDMMaerhZN/gYQLlQhMRHwRzMHKZo5gPmoXSfY8SmdC3PeqZrUdYvgie8Onml1lElJKIjIwSIS9n6fJCJfEJGSwfYzDMPoR2+Pmk3ChbqcXaiN40A5gg4U2htiTmafohkaktrb0798vKaQlQ0f+zNc9heoOgqeugZW35rWKseTqqZwF9AjIvOBm4C5wO/TVivDMCYuvv8gqil4310TwITUvi/mLPYpmgGuB1r29C8frymA+iHmnACX3KECo2lsw3VTFQq9zrkIcD5wvXPun4HK9FXL2K9xTqccNIzh4JuKwgHzUXD9gUxHIk1hpn43JzAhxWsKQUQgtwza9o1uHQchVaHQLSKXAB8D7vfWhdJTJWO/563H4cdHwt7N410T40DEdyr7moL/PRGczQl9Cv5YhTih0NsLPZ0Qykt+vLwyaKsf3ToOQqpC4XLgOOA7zrnNIjIX+G36qmXs1zRsBVxiddgwBsM3H/kaQrio7/oDFeeS+BQ8TSFeKETiJthJRF6Zpt8eQ1ISCs659c65LzjnbheRUqDQOXfNQPuIyM0iskdEXkuy/SQRaRSRNd7nv4ZRf2M8aPNe0olgAzbGHl8jiAoFX1NoGp/6jBZdLeo7iPcp5JVDZnb/sQq+UMiK8ykEyd1PNQUReVJEikSkDHgFuEVErh1kt1uB0wcp84xzbrn3uTqVuhj7Af6ozYlgAzbGnnhHc9R8dIC/T/GjmX2iA9jiNAV/HMKAmkJ5rBM2RqRqPip2zjUBFwC3OOeOBE4daAfn3NPA2F6NMTb4L/+Bru4b40MyR/OB/j7FZ0gNUphAKKSiKeSVqfM6UThrmkhVKGSJSCXwQWKO5tHgOBF5RUQeFJFFyQqJyBUiskpEVtXWTpAcKQcyUfNR6/jWwzgwiWoKvvnIjz46wM2R8RlSgyRKdZGKppBbBq53TNNepCoUrgYeBt5yzr0oIvOAjSM890vAbOfcMuDHwD3JCjrnbnTOrXTOrZwyZcoIT2uMGN/xdaD/iY3xIepTmGDmo/gMqUGKZmimVOdi61LSFMr1ewxNSKk6mv/PObfUOfcZb/lt59z7R3Ji51yTc67F+/0AEBKRipEc0xgjoprCAf4nNsaHrhaQzFh8flY2ZIYPfEdzMp8CaARST2ffxj0ln0KZfo+hszlVR3OViNztRRPtFpG7RKRqJCcWkekiOlu1iBzt1WVs3ezG8DBHszESOptVS/AnqwddHs1ORqQLnr1+bPMGBednjifRZDup+hRgTMNSUzUf3QLcB8wAZgJ/9tYlRURuB/4BHCYi1SLyCRG5UkSu9IpcCLwmIq8ANwAXOxfUrYz9EufM0WyMjM6WmD/BZ7ST4m37Bzz6Ddj81OgdczA6GiAjBNn5/bclGquQqk8BxtR8lOokO1Occ0EhcKuIfGmgHZxzlwyy/SfAT1I8v7G/0NGosdhgQsEYHl3NMeeyT3bh6Pqo/I7LWE7e449mDmpAPsPWFHyfwn5mPgLqRORSEcn0Ppdipp7JSVCNNfORMRw6W2JOZp9w4eh2Mnynb2vd6B1zMBKNZvYpmKp+lKFqCuFCyMjaL81HH0fDUXcBO1HTz+XpqpSxHxNMzmWagjEcgnMp+IQLRtfR7Nv328ZSKCTIkOqTkQmFcZPtpKIpRJPi7WeagnNum3PuXOfcFOfcVOfc+9CBbMZkw1fLC6abpmAMj0SaQnbB6L5PUU1hDA0aiTKkBimq7JspNRVNAcZ8VPNIZl778qjVwjhw8NXYklk2eM0YHl1JHM2jqXmOl6aQKBzVJz7VRSqaAnhJ8cYuffZIhEICb4ox4fF7LCUHWUI8Y3j4IalBwqPsaB4Ln0JPd9+OUXtjcvMRaARS447YALbudk2UlzFIMzzG6bNHIhQsfHQy0r4XEH3BzXxkDBXntPHv51Mo1Ck6U8nx09UGNWsGLjMWmsLDX4MbT9J5EXp7oLNxEPPRDOhujflOIh2Dawng+RT2E/ORiDSLSFOCTzM6ZsGYbLTthZxi/fR2Q6RzvGtkHEhEOjSkOZFPAVIzIb3wC7jxRHj9L8nLjIVPYecrUPcmbH02lptoQPORN1ahYZt+d7cN7k8A9Sm07+2bIiONDCgUnHOFzrmiBJ9C51yqYxyMiUT7PlVnJ0q+GmNsiWZILeq7PjyE2ddqXtbvuz+TfFpYX1Pobo05dEebfVv1e83tgRQXA2gKFYfqd92bXt0GmIozSF4Z9EbGLA3ISMxHxmSkfa+++OEh9OwMw6crbipOn6HM07zrVag6Wm3xf/yompPi6WiINbjpsMd3tUHLLvUJrL8XGqt1/UA+hfL5IBlQ6wmFSDuEUjQfwZiZkEwoGEOjba++pENR9w3DJ34uBZ/sFNNndzbD3rfhkNPggl/B7nXwl7hAyF4v1XTZPF1Oh7PZNwEdeZlqIy/9WpcH0hRCOVA6B2pf1+WUNYWxzZRqQsEYGu17VZ0Nm/nIGAbxs675RCfaGUQo7F6v39OXwCGnwvFfgFduh4btgXM06xwE5Qfrcjqczfu26PeSD0DZwbDOy/w/kE8BYMrhUPuG/o50pKYpjHFSPBMKxtBo2xenKVhYqhHH3s3Js5NGNYX4cQopdjJ2rdXv6Yv1e/YJ+t28M1bG9yeUH6Lf6XA2+0KhdA4s/1AsH9hA5iNQv0L9JuiJqK8jJaEwtvmPTCgYqdPTrUIgtzQgFGwAmxFg06Pw4xXw06Ng/X39I2aS+RSyU3Q073pV3z8/kqfAm3SrZU+sjO/0LZ+v3+nQFBq2QigP8qfAsouJDttKRVPo7YZ9m4cQkuqZpMx8ZOx3+H82Mx9NPNbfB7ecqfb44VL/Ftz5ce0NZxfAHz8CvzlXZxzzSeZT8KORBvNR7X4Npi2OZSItmKbfLbtjZfxw1JKDNJlcOnwK+7aoliACxVUw7yQI5UNWeOD9pngRSLWve5pCCj6FnBJ1UJv5yNjv8HsquaUxx6A5micGbz0GW/8GjduGt39nM9zxIc0E+qE/wKefgTP+B7b+HZ4PPkvyAAAgAElEQVT7377lIHFCPBg47LInoo7l6Utj6/I9TSGYIts3H+WWenmD0igUfM74Przvf5OVjuGHpda+kbqmkJGh12LmI2O/w++p9NEUzKcwIfBj7n0n6FBwDu6+Euo2wgdu1cYyMwuOuUJ76364JsQ6EfE+haywhncOpHnufUsb0ulLYusyQ9pgBs1H0bmSSyCvYvR9Cs71FwpTDoVF7xt833AhFM/S+5yqpgBjOqrZhIKROtEBOmVezpYs0xQmCg2eUNizYej77n4NXr8f3v0fMO/EvtsK45LAdTarLT4js/9xsgeZknPXq/rtO5l98qdCa9CnEJgWMz8NmkJrrY5GLpk9vP0rDlXzUSTFkFTwNB7TFIz9jaD5SMT7E5uj+YCntzcW0jkcTWHHav1edH7/bUUz+qaLTjSXgk+4YGDNc9erOt1lxWF91xdMhZaA+aijQTss2fmepjDKQsHXqoKawlCYcrhqValGH8GYZko1oWCkTtB8BKM/r64xPjTv1IgYgNphaAo7VmtHoXRu/21FldC8K+bATjSXgk+4aOD3aderMPVwyMruu75gal9Hc3uD55wVyK8Yuabwwi/hlTtiy8Fw1OEw5TAdzYwbgqZg5iNjf6Rtrzcxufenzi5IfZxCd8fIIluM9OGbjioOVU1hqM9px0sw88jEcxMXzoCerpjpYyBNIXuQ2dd2vQrTlvRfnz+1r6O5oyEWGppXoaObe7pTu5Z4ulrhkf+CR78Vuy++UCg5aHjHnBLQdFLVFPzZ18YgKZ4JBSN1/NHM/p8/Oz81TSHSBdcthDW/TW/9BqNlD/ziXcmTqO1PtOyBaxfB7y/ScNFIV/rO5ZtDDn2v2sobtw9cPkhXK+xZr0IhEf6E9b4JqbOlv5PZZ6CJdpp3q99gegKhUDBF9/NzIPmaAsS02uHa4998WO9Jcw3s9BLx7duiMw9m5w3vmH4EEgxNU+jp1LqkGRMKRuq074sl5wI1A6TiU2iu0T/lzlfSV7dU2LFa67Dl2fGtRypUvwhN1bDtHxrvf+3hsOu19JzL1xTmv0e//dw8qbDzFU0pMZhQ8J3NXQnmUvAJDzAl527fyZxEU4CYszmoKeRX6PdwhcK6P6mTVzJjqbrjI4+GSl5ZrM4p+xTGblSzCQUjddr29U34NVi0iE/jDu+7euByo0XdRrjzE/1TJvtJzPa+Pbzj/uY8eOhrI6tbquzxcvx8cS186P/UdPf6/ek5V8M2nVS+0ov/H4pQ8J3MM1Yk3h4vFBLNuuaTPYCjeWdceosg0QFsngmpj6bgCYXhOJs7mmDjI7D4QphzfEwoNGyF0mFGHvn4JqRUNYUxzJQ6aYTCW7Ut/OzJt2jqGKZt0YiZj3xSdTQ3jbFQ+MdP4bU7YyGMPiMRCt0dsPkZnVBlLNizQW3WuSVw6Gma1mG4wmww9m3V8MrcUjWL7BmiUCg5KJZuIp78qToa189NNKD5qCh5J+PtJzXqKFEW0miqC8/ZnFBTGIZQeONBDRtdfAEcfrYKyz0b9D0eiaYAGoEEpimMJxt3t/C9h15nW336bXITlra9cZpCfmqOZl8oNAzBVj1cIp2w7m79vXdz322+mSR+fSrUbtCkZ3Ubx8Zhvns9TF0UWy6bmz6hEOz5Tjls6JpCMtMR6CC2gukB89EgIaldLf3vb3uDjrY+7IzE+wXNR37a7H6awjAa03V/UmFcdXTs3M//HHCjIBSGqClEM6WmPyx10giFmSUqkXc0pGkWpoHY8qz2Xg9knOuvKWQPYAMO4puPOhtj0xami41/jY1o3RcvFAKawlCjOHzzhe90TCeRLqjfCFMXxNaVzRueMBuMnm4V2v5ArKkLUo9AaqnVezqQUAANS22q0XmMu9uSawrJ5ujY9KjOPHbYmYn381NdtNTG0mb7nZe8MkCSawpdbYmvtX0fbHpMx15kZKg2NH1pLDR1pELhoGMhM5y6GWoM51SYNEKhskQlcs14CIUXb9KQtjGaYzUtdLdpaGFQUwgXePM0DxIZExzR6guIdPHKHdpzLJieQFPYriOxu1v7pkVIBT9lM6i2kE7qN2kjOHVhbF3ZPG3YRluoNm7XRjSoKXS3phaBVPOSfg8mFAo9oZBsLgWfcJJ8Wm88qD3+qpWJ98vKVs2gdU9g1L2nKWRk6jubyKfQ0QTXLfJ6/3G8/hd9txdfEFt3+NlqToKRC4XpS+A/dsUmAhoMX/M5kM1HInKziOwRkYQhE6LcICKbRGStiCTxVI0O5fnZZGdljI9QaNiq4WTpyNY4VkRHMwc1hRST4jVVx4RJOv0KbXtVU1hyoaZNDmoKnc2q6cw6RpeHaorZuTb2B063UPCdzH00BW9g2GhrC7725GsKU7xzpjKyecdq9RdULhu4XNFM9Skky5DqE52SM2CS7OlWZ++hpydOjeFTME0FfTDFhU+yAWzr79F3Yv29/be9dpc2/EEH+uFn6XdmWDsdIyVjCM1vZhYsOGfkDu4USKemcCtw+gDbzwAO8T5XAD9LY10QEWaW5FLTmGTyj3Tix4E3jZGjNR3Ej2YG9SnA4EnxmmpijfFws3Cmwvp7VZtZehGUzenbgPr+DD83T7xpaSB6ezS/z/z3qDPUn3g9XexZryGQFYfE1vkCaTh+hd3rYpPdx+O/m/5ALN/WncrI5h2rVZvx34NkFFXqoLTmXbo8mKYQNElu/buaHQ9PYjryKZiqQiGYDM8nWVI83xRU/WJfDaxtL2x+Ghae13dA3rRFep9KZg2tQR8tLvqtTuiTZtJ2Zc65p4GBDGDnAb9xynNAiYhUpqs+ADNKcsZeU+hsifVSxir6Jh0k0hTCSWzAQSKdOtp0xhE6Gjqd92DtHzRCpXKZplxo3RNrYPwe8ewTtMEdqHGt29h3Mvi9b6v5rHKpNtRpFwob9DzB3Px+ComhCDOfP38Jfn+xpp6Op2Gr3g9/0pq8Mu11D6YpOOc5mVNQ8P1j+/dtMJ9CcFTzGw+qM3beSQOfI3+KZz5KpCkkSIq3b4s6rw8+RQMI3n4qtu3Nh9V8t+C8vvuIwJk/hFO+MXBdDnDG06cwEwgaLqu9df0QkStEZJWIrKqtrU1UJCVmFOeOvVAI2mYHahBr1sCvTt1/U1En1BTienaRLnjkG317ZX7kUfEsjVlPl1DYt0UHei27SP+8vrnFT0ngC4Xyg7Wnl0wodLXqqOfHvhVb5w+6m75UR6OOhfkoaDoCFcAF04auKfRE1B/Ssgveerz/9n1bdZKYzKzYuimHDZ4tde/bar8fzJ8A6lMAqPMEzUDRRxDrZDgHbzygAmEwbcRPipdUU4gTCmv/qN9n/UDf47cei23b8GcVZDOO6H+eQ0+DhecOXJcDnPEUCgkSpZDQE+ucu9E5t9I5t3LKlCTx0ClQWZLLnuZOuiKBaIN9W+H/VUH1qmEfd0B89RwGbhA3PaJq7M61ycuMJ76D2A//g/5/4u3Pw9+uV1utj+9kLprRP7f+aLLhz/q9+EL9ju9ZN2zVHmf+FC+SJ0njuu051QrW/kG1HNBGNSOkseUVh2j0UbqEd1erCrKgk9mndO7QfQp+imZInGYk0UCsKV4E0kCBEdtf0O+ZSZy/QfwBbL4wHSjNBcQ6GXs2aP2ShaIGKZiqkUe+iSrep9C+NxZl5By8cjvMeae+C/NO1Egj5/Tcbz2mTuXxMBHtB4znVVcDswLLVUBaY/1mluTgHOxuCvgVtjyjL9O259JzUj82Prd04IgO/w9Tn2IvtLcXHv0m1G0aUfVSpvoFdbzll8fW+b03Xyj4dd+9LlbGFybFVfpJl1DY9pz+wf0GLt4x27BNhZKIlqtPEpbqp8Bo36dOa1BBPXWBRrn4eWvSpS34YwTiNQUYWJglY+ca/Z7/Hnj9gf629YZt/ecFmHGERiBtfoqkbH8OwsWJhVc8vlDwTVJJRzTHOZrf8EYQHzqQa9LD76zUbYylzfbJq9AIKz8yqfpFvY/LLtbl+afof7Nuo4a/RjrUqTtJGU+hcB/wUS8K6Vig0Tm3c7CdRsIMb6xCHxOSryHsTVOStH3eBN+VywZuEP0/TKqNTd0b8Ox1Y5NkzjntGfrOYp+oDdgTCn7ddwcCznzzUdEMFQpNNYlt2yOt37bnYNaxsXW5pdpbDJqPfGdq2Tx1XiYaCLTlGTWJFExTR6Rzqin4KSDSLRR2+5FHCRrbsnkaxdM1hAGYNWv0OZ36DQ2xfPX/Ytu623UUcLymsOh8ja556n+SH3fbczDr6NR606Fc71l4Ajp7EE2hq1md+y/dBrOPh8IUIn0KfKHwRixttk/8qOZXbtdpMBd4ZqCDT9Hvtx7TVCJ55XDQcYOfc4KSzpDU24F/AIeJSLWIfEJErhSRK70iDwBvA5uAXwKfTVddfKJCoTEgFHZ4QqE+TT3uBi+FQPGs5ELBuYCmkGI9fDPTWCSZ27dFG494oRAfVx4VCutjqnrTDv2TZuerUHA9sZQHo8Xet/UPf1Bc/crmBsxHcULB3y9IZ4umgZ53Eiz5gDocd72qseH+vMClc9UxO5Cz2RdSf7gUbrtgaCOg92zQBitRHHy8nyQVdq7Ruk9fohrAy4FORHw4qk8oB074kqb02PK3/sds26sazUHH9t+WjKKZ6ryF5JpCVlh7+Z3N8OZD+t85+orUju8PYKvb1NefALGBXxv/Ck98F169ExacDTlFur50NpQfov6LNx/WQXJBH8skI53RR5c45yqdcyHnXJVz7ibn3M+dcz/3tjvn3Oeccwc755Y459Jk1I8xo9jXFDzzUVdbrGeWrnTK+zybbfEsbVh9O3WQphpV15HUI1v8wVQ716Z/UJxvP06mKQTNRxlZ2tPzQ0+balQYgN4DGH0Tkm/6mxXXSPk2eH+MwmBCYdtzKrTmvBOWXaI960e/qdt8oZCVrY1zMjPfzrXwq1Pg5vfCGw9p7zNZOGgi9qxXR2+imPyoSSxFE1JPRDOrzliuy8s/rNlG/Y5ENBw1Qez7io+pSebp7/ff5r8PQxIKnrNZMpOndvBn8+tsged+pu/L4WendnxfU4i09/UnBLf99evw1Pf0+b/zX/qWmX+KhqF2NsU0iEnKpPKk5GZnUpoXiqW62LlGG4GZR2qPdrSnlnTO0xQOijWMTQlG9PpRGbOO0T9qKrnzfaHQVjf6Pe94tj+v8fnxdu5oz65FE8bt2xoLHfT9Co3VMZtyuoTC9ue0IQjmqQdtRBu3x/wKvlAomQ1I/8Z1yzPqUJ51jGbjnL7Ei0qRvtk5yw9Jbj567Go935k/gC+t1fuzIcHgqGSCfM+G5Hb6oY5VqHtTG8lKTygsuVAHXj17nWpEvpkv0YCo7Dw4/guaiG7b8323bfuH3qdkmVET4b8D4YLEk/H4hIv0fdvyDBz1ydR77PmBAJR4TWHqQjj7erjkD/BvW+DTT+kMbkF8E1J2Yf95picZk0oogJqQoj4FP+3vUs/h1K/n+PzIokza92nPo2R2TCgkahD9Bubws1RIDRaL7pz2SP1Mi+mOWNr+vKYYiO+9inhJ8Vq8e+e8XpbEhELTjlicerH3PZRJXFJh2/PakMfbt0vnqsli69912e8Rh3L0ecRH8mx5Rq/Tnzxl2SX6XTavb8RMxSFeKoqevvv3RLTBXHQ+HP0pbQjnvksjo4JC4LW74NvT4C9f6Zv2o6VWQ0cTOZlB/SS5pbH3wzl4/DtqDkmE72T2NYXcUh38tO5u+OXJGnablRNLPR3Pyo+r6SVeW9j+vB5zKJPMFHpCIZk/wSdcoB2erFxY8dHUj58VjmkI8ZqCCKy8HA47vb/A8Jlzgt6LQ9/bd3zIJGRSCoWdvvmoepX2Hn01OGjPb62DW06Hv/94+CfzI49KBxMKb2okx5zjveVBnJiN2zUee/mHAOmbl2e06WjSBj7edOST7aXP9s0plcu0h777NdUe2upjQiE7Xwe/jaZQaNurmla8PwFi5pbNT+t38ay+24KdgI4mdcrOOSG2bskH1NzhO5l9Kg7VkdP+8/XZ9YoKSP85gkax7H07lrqitxee/J42fqtvhRuWw50fh1+9R/PwQOKJZKL1DkQgbXpMG+y7PgEPXtV/ysmaNRDK15QfPmddC1f+DS76HZz2HTj/58l77tn5cNznNSLHN9FFOlXLSPY+JMM3HyXzJ/j4wnfZRX3HxKSCbyZK1vAPRHYefOx+eO//G/q+E4xJJxRmxmsKM1fG1PKgUKh+UcPY/F7mcAjabP2GMZFQqH1De5/lXlqDwcJS/XkCDnqHDsYaqbO5enXy3uaOVYBL3giEvXmafV9I+XxNB7B7XWDgWmBMYskADvfhsN0zbcT7EyA2VmHLs16PODDGIj68M+hP8CmYChfeBO/6at/jJotA8p2yswOC5bCzAImNo9j0iAqx06+Bf3pJwyI3PaYN89Gfgotvh7kDmC9K58ayvD5+tXZqjrkSnv8Z3HZ+30FaO9eoQAtqeBkZagpbcDa84/Oq1QzEMZ/WSKSH/0PPWbNG83gNNTrHf/+TjVHw8f1Ux1w5cLlE+GGp8ZpCqsw6CgqTaE2TiEknFGaU5NDcGaG5rlp7rFUrtWErnKGx6z7VL3rfq4Y/P25QUwjl6EubqJdct1EbmpwiVeWDYw/2vg3XLe7b8O9cCwhMW6gO0JGaj/7yz3DPZxKbyrY9r0nPko1czfam5KzbpH/8cAFMW6yOe1/IFgWEwkBRWMNh23Nq306UbqGwUm3onY163mCPuHRu36yjW57RDKpVR/U9xqLz9T4H8XMSxQcFbHlWBXuwYSmcppqoLxT+dgMUVelxS2fDuT+Gq7bCJ/4K7/2O5vgZKMyzbJ7ev9fu0nfipH+HM74H5/9CHcC//6BqDL092nnw/QnDJTsf3v117Rys+5Oax2BoTmaIjWpONprZZ/6parZKZkIbiKimkGAiHiNlJp1QqPQikBo3ei+339iVHxynKawCRB11wzXP7NuqvZacYl1ONHiro1HtyFO83mf5IX01hXV3qyBZdXNs3a612jBl52tPsHHb8POs71yrjUtPl2ajjGf78zrZix++F092fsx85Jsppi0CnJodIE4ojPIAtu3Pq8kq0QxWGRmx0E7fyewTzXi6SYXh5qdVa0zFTp5XpgOigkKht0cbzKDpyGfBOWpOe/VODfM89jOQGUrp8vpRNk812Ae/qnmell6k65ddDBfcqNrv49/WunW3xfwJI2H5h1TQP/pNHdBWPj8W+58qQUfzQBz3WTj7umFVc0TmIyPKpBMK/liFyPZVGhnip/0tnx8TCr09ajf1U+UOd7Rzw7a+kR2JGkRfK/BNEhXz+5ol3nhIv1+7W230oD1AP0TSr3/81JOpsuZ32kPOLe0/B3BvjwrHRPZ6n3Ch2tF9bQc8oYDGfEOsQQC9B51NscRlI8G3bw/Ua/X9CvFCofxg/f7Vu+G7VWpqmfuu1M89bZEmUfMH4u1aq9cVND/5+GGV9/2T+o6O/Fjq54nHv562ejj5a31NQ4vep6Gkf7se/vYjXTdSTQH0HKd9W9/ntx4fupYA+n5l5QzuaB4JfgTScM1HBjAJhYI/A1t498v6x/Z7mOXzNZa9ba/a+Luavfzlc2Iq81DxB675+KaTYCSKH45aEdAU/Hq01KoZa/bxagJ58yFd37g95vyc7guFYWgzkU7N8XP42Xqtb/617ziKPev1PgzkVMwu0MFUnU0xs0rJHHVwNmzVxiDY+x7NsNSdr6h9e6D6lSYRClMXwunfg5O/Du/5bzjrh3DsEOzYx3xar88fIRz1JyTQFEpnq/DubtMomMHs6gPhaziVyxLH059+jWoQr9yuzyCYfnskHHyypsqA4Y32FdGxAYvfPzr1SYRpCqPCpBMKUwrDhDIcZQ2v9U3m5fcc69+K+ROqjtI/wLbnhj5AzLnEmkJ3W9/0CnVvqk3cN3NE7dUbvdw7TntphZWadsFv/H1NIb9czTPJ/Ar1byWf3OeNB7QuR1wKh5+jAsCP1IFYOuGBGt1wgV4TxMxHGRkxO3xRVd/yAwmFZ6/T1Aap4FwsH/5A9UumKYioEDjxXzUe/6hPDs0WfdiZGiX09P+otrD1b1B2cCzKJp4lH9RGejgO1CD5U7RxPeeGxL6H7Dy48Gb1pUxfMvDENEPl9Gt0HMohpw1v/xP/FQ45dfTqE0/lcjXrBaOtjCEz6YRCZuM2vpr3F8I9rX2n9/NfpPpNKhRyS7VXNusYdUgONRFZy25NrFUSJxSgr7O5bqOex7cx+/WoexPefDCWwnfJhRq58tYTun16IExy+tLEmkLbXrjxZPj1uf1j6kFTHhRV6R993omq2vsO0ba98MwPNcIpvkENEkw8Fhw85puQgqajZPcAdIKcR78Jf/5ibPxIMno9m/qqm9QpOVDEiB/eORzH5UCIwIn/pjmzXv0/FQqJ/Ak+x34WvrwuudAYynlP+c+BfQXTF8NH/gRnJhiNPBIq5sNH7+0bxbU/UbkUvvpWarmSjKRMHqHw9lPwixPhR0v5VOT3vBk6vG/2xZLZGpNev0nt6FVH6R/QV5UHMyF1tWkv20+XkSiFQKKxCn44arAemdka0rnpcR1MI6ID7Hoj8PwvVFAEs5VWLlUhEp8o7dlr1ey0Z536DoI0Vmso5PIPaW8yKwyHvEe1h94eeOS/1CR01g8HHoHq24izcvs6lKd5I4CD4aigPd1QnjrQ/UR6TTUqDCqXafTVPZ+N+U/i6emGe66EF27UGPqzrk1eN4DZ74AvvRYTUqPJYWepE/6hqzRgIJE/wScjY2yjYuacMPg0mYaRgMkjFLLztfE79Vv897zfcXnmd/sOjsnKVlNPzcua7Ms3LVUcqo6rZELh5d/qwKNrZsGvz4H/PQ7W/l/fcFSfeNNJT7eOTvWnQAQd1l82D9beofmQDvVyyU9fDNOWaDRUUEsAXXa9cSmrq+H5G1WYzDpGI1KC0xy+9BvA9Z3eb8HZOkva32+Al2/T3m18OGY8fjRJxfy+5gxfKBTFCYWMDBU0256DW8/U/Pf3fFZ9Ge+/WUM0a1+HJwODiOo2wT9+Cnd8GH54mPpB3v2falYbSGD5lMwavMxwyMiAE78am9glkT/BMA4wJk8qwKqV8CmdeSrc8jq7X3+bnl5HZkagUSmfr71nXMy0lJGh0Rbx+V8ANj4K935OG8B3/BNUHa2N158+GTOlBE0v+RVq6/VNJ3s3a+8/PmdP+XxtGEN5fSNill0Ef321/whbf3nTIzoAB+DJa/Q63v0f0LwbbjpVG/uT/h2e+1946vva0/Vt7qCOxMxsNeMUVal5ZDD8uPPyOIdm5VIVRokiepZ/SG2///cx+MlRqpGcfZ0Klor5mt7g7z/We/XW47FMtqVzVLtbcE5qE6+MBQvOVad1pLO/VmQYByCTRygEmFGSS6TXUdvcyfTiQMbG8vmxiVWCg7UOOlYjf1rrYvHZjTvgT59SgfDJR2NRTPNPhQe+oj3xgml94+dF+oal+hOqxEeI+MvzTtZBbz5LL4KXfweHvLdv+eJZ2vg+9T01Ix39aTUXHXOlN9H4QbDoAh041bRDtZsF52pce5CcIvUvbPwrnHHN4DHlEPMpxF9Ddr4OyErGoafBZffr3MFz3wVHXh7bdtp31Hfy9PfVPHPat3WwV3FV8uONFxkZ8KE/xmY3M4wDnEkpFKpKtaG+5e+b+dfTDiMr0zN7+BFIFYf1DWvzUyhs/RssPE/NPnd+XAd8feDWvg1/VrZGhlQdlThiqbgKGrbDmt/Dw1/TrJAVh/Ut4/e6D4ubcapgKnwuwZgJEbj0bo1Pf/IatddnF8I7vxIrc+o3dBzCy79VW/x7/jtx9MpJ/66NdKopi/3wynhtJxVmHgn//JpGXwXNQDlF8PGH1E4/dWFqJqLxJF3mKcMYByalUDhhfgUXHDGTXzz1Ni9u3suPLj6CWWV5scifYFQSaPRPVi788aPa+OWWabrm99+UOA5cJHmGx+JZOlvajlVqbjr3hv498kNOg+WXqgBKlcwseNe/qHnloat0IFNw1GnpHE2F0BuBpR9MfpyZKxKnjEhG5XLVjoYy8CtIsoyU/vSdhmGMKeLSPUHLKLNy5Uq3atXozMdz75odfP2e1+ju6aU8P0xhpJ77IldyU+mX6V16EccdXM6c8nyKc0Nk7nyZ7jcfoXPLC2TtfoX6OWeRe87/UJafPbSTrroFHvmGhhWu/MSknRzcMIyxRURWO+dWDlpuMgsFgOp9bfzsybfo6O4lOyuDwq49PL0zi9d3xyJ1RKAoJ0RTR3c/i9D0ohzmVOQxtTCHqYVhcrMz6Yz00tndQ1NHhD3NHdQ2d9La2UN+OJP87EwKckIU5mRRGA5RlJtFSV42ZfnZFISziPT20tmt0zcuqSpmwfQiMjxneEd3D2/XttLSGaGju4euiNY5P5xJbigLEejpdfQ616eeocwMCsJZ5IUzyc/OIieUgezvJhnDMEYVEwojpK6lk1Vb9rKrsYO9bd00tHVRmpfNwVMLmFeRT1N7N+tqmlhX00j1vnb2NHeyp7mDzkgvOVmZZGdpQzy1KMzUwjD52Vm0dfXQ2hWhuSNCc0c3zR0Rmjq66ehOPodvUU4Wi2cWs6uxgy31rfSOwuPKzBDysjOZVpTDwsoiFs0ooqIgTF1LJ7XNnexq6mBnYwc1De20dESoKAwzpSBMaX4IQeh1GrVVmp9NRUGYsrwQWZkZZIjgcDS0dVPf0sW+ti6cc2RlZpApQnt3Dy2dEVo6ImRnZVCcF6IkN0RuKJPMTCGUkUFrV4S6li5qmzvo7YWi3BAleSHCWRl09/TSFeklKzODyuIcphfnUJKbTWuXHrMj0kMoI4OsTCE3lMmssjwOKstjalGYHfva2VzXytb6Npo6umnpiNDa1UNFQTZVpblMK8ph2942XtneyLqaRkryQiysLGZBZSFZmcKeJr03IlCcG6I4N0Q4lK627fcAAA5gSURBVInzBHBzR4SaxnZqGtrp7nEcVJbHrLI8phaGoy6RUGYGM0tyqSrNpTAnxM7GdrbWt7GnuYPcUCaFOSFyszNp7YzQ0KbvR252BsW5IfKzs6hv7aJ6Xxs1DR1kiFCQk0VRThZFOdq5KMzRWQVf2d7A2upGMkQ7FktnllCUq+fb2dhBZ3cP5QVhyguyKcvLptDrpJTlZzOjJLdPRJ5zjrauHrp7eunucTgcZXnZMT8c0BXpZWdjO2/XtfJ2bSvb6lspLwhz6LQC5k8txDlHbUsn9S1dFORkMbc8n5mluQhQ29JJTYNe/yHTCggFjtvT62jv7iEvlBntGA2Hls4IOxva6XEOQcjMgIqCMMW5oaSdo47uHjJEyM6aOJq8CYVxwjk35F54e1cP+9q6aOmMkJ2ZQTiUQVekl5e27eOFzXtZV9NEZXEOh00v4tBpBRTnhsgJZUYbytbOHtq6IjgHGRlCpkjUKuUcdPf00tLZQ2tnhNauCG2d2jhX72tnfU0jNY2xyJncUCbTisJUFudSWZJDUU6IupZO9jR30tDWhSBRjWRvaxd727oS+tMLwllRIdLT64j09pITyqQwJ4uCcBZdkV4a2rtpaOums7uH7l5HpKeX3FAmUwrDVBSEycwQGtu7aWrvptPTikKZem/2NHeMSEDmZ2eSE8pkX1tXn+NUFGSzaEYxje3dvL6rqY/AzgllIKhwS3ZMv1HdvreN1q7E5UC1z+H+9QrDWTi0sUu4PSeLpVXF9PQ61u1oojlQLjsrg3BWBs0diffNzspgbnk+UwrD7G7SjkH8dWSIpospzw9T36rvRvBaCsJZSevmk5WhnYvgvQ9nZbBwRhHFuSG21bexfV8b3T1aIC87k7zsLHKzM8gNaafLOaL7h7MyyAllkJ2VSU+vdh7au3uoaehgb2vi1PcF4SxmluSyoLKQFbNLWVpVwqY9LTz46k6e2VinY0arilkxu5R5FfkU5oQoCGext7WLtdWNvLqjga5IL0fNKePYeeWU5of4x1v1PLupjs11rZR6FoDS/GwKslVTz87KoLUzQlN7hNbOiFoVIj30Opg/pYDFVcUcNq2QTXtaeGFzPS9tayArU5hSEGZKYZgzFldy1tLhjYo3oWCkzL7WLhrau5lSGCY/O3NIQi3S00tjezc9vQ6HNnTFudrjTSeRnl72NHfS1NFNfnYWhTlZ5IQyifQ6uiO9tHRG2L6vjW31bexu6mRmaS5zK/KZW+H5iLyeZ3dPL7saVTOaWZrLjOKc6PVHenrZUt8WbQQLwlmICJ2RHhrbu+mK9CIiCJAf1l67v69zKjTrW7vw76Y2Uu1U72unoa2bmaW5zC7LY3pxDu3dPTR3RGjv6qEgJ4uS3BAFOVm0d6kZsrmjm/L8MDNLcynO1ZQovb2Olq4ITe3dNLWr1llREGZeRX60Z93b69hS30pbVw+VxTmU5WcjInRFelWot2pnpLmjm7qWTt6ubeWt2hZqW7qYXhRmZolqWuGsDLIyBAeqTTZ2UN/aRXl+tnffcpk7JZ95FfmU5WfT3t3Dpj0tbNrTQmaGNmrlBWGaOro9ja0VQagsyaGyOIfmjgivVjeytrqR1q4Is8vzOKgsn9K8kGrYnarZdXT30N7VQ1dPLxkCIoJz0BnpobO7l86eXkIZQsjrXFUW5zKrLJeZJblkZ2bQ6yDS20ttcyfV+9rZvreNtTsaqW2OJYKcUZzDexdPJ1OE1dv2sW5HE109fbX5nFAGi2YUk5UhvLxdhYPPwsoiFlQW0dTRzd5W1ZjbOtVK0BnppSCcFe0chbMyCGdl4nC8sauZfW2x2fMqCsIcNaeUDBFqmzupbenkoqNmceWJBw/rP2NCwTAMIwWcc+xoaGdtdSMzSnJZVlXcp2PU0d1DfWsXLZ5wLsjJYv6UgqgJraO7hzXbG2ho6+KoOWWUFwxvjme/Hm/ubmZOuXZgRtP3l6pQmJQhqYZhGD4iQlVpHlWliSdYygllRlPuJ9t+7LzypNtHqx5jxcTxohiGYRgjxoSCYRiGEcWEgmEYhhHFhIJhGIYRJa1CQUROF5E3RGSTiFyVYPtlIlIrImu8zyfTWR/DMAxjYNIWfSQimcBPgfcA1cCLInKfc259XNE/OOc+n656GIZhGKmTTk3haGCTc+5t51wXcAcwhLSfhmEYxliTTqEwEwjOzl7trYvn/SKyVkTuFBFLTG8YhjGOpFMoJBqKFz98+s/AHOfcUuBR4NcJDyRyhYisEpFVtbW1o1xNwzAMwyedQqEaCPb8q4CaYAHnXL1zzk868kvgSBLgnLvRObfSObdyypQpaamsYRiGkV6h8CJwiIjMFZFs4GLgvmABEQmm+zsX2JDG+hiGYRiDkLboI+dcREQ+DzwMZAI3O+fWicjVwCrn3H3AF0TkXCAC7AUuS1d9DMMwjMGxLKmGYRiTgFSzpNqIZsMwDCOKCQXDMAwjigkFwzAMI4oJBcMwDCOKCQXDMAwjigkFwzAMI4oJBcMwDCOKCQXDMAwjigkFwzAMI4oJBcMwDCOKCQXDMAwjigkFwzAMI4oJBcMwDCOKCQXDMAwjigkFwzAMI4oJBcMwDCOKCQXDMAwjigkFwzAMI4oJBcMwDCOKCQXDMAwjigkFwzAMI4oJBcMwDCOKCQXDMAwjigkFwzAMI4oJBcMwDCOKCQXDMAwjigkFwzAMI4oJBcMwDCNKWoWCiJwuIm+IyCYRuSrB9rCI/MHb/ryIzElnfQzDMIyBSZtQEJFM4KfAGcBC4BIRWRhX7BPAPufcfOA64Hvpqo9hGIYxOOnUFI4GNjnn3nbOdQF3AOfFlTkP+LX3+07gFBGRNNbJMAzDGICsNB57JrA9sFwNHJOsjHMuIiKNQDlQFywkIlcAV3iLLSLyxjDrVBF/7EnCZLzuyXjNMDmvezJeMwz9umenUiidQiFRj98NowzOuRuBG0dcIZFVzrmVIz3OgcZkvO7JeM0wOa97Ml4zpO+602k+qgZmBZargJpkZUQkCygG9qaxToZhGMYApFMovAgcIiJzRSQbuBi4L67MfcDHvN8XAo875/ppCoZhGMbYkDbzkecj+DzwMJAJ3OycWyciVwOrnHP3ATcBt4nIJlRDuDhd9fEYsQnqAGUyXvdkvGaYnNc9Ga8Z0nTdYh1zwzAMw8dGNBuGYRhRTCgYhmEYUSaNUBgs5cZEQERmicgTIrJBRNaJyBe99WUi8oiIbPS+S8e7rulARDJF5GURud9bnuulT9nopVPJHu86jiYiUiIid4rI694zP24yPGsR+Wfv/X5NRG4XkZyJ+KxF5GYR2SMirwXWJXy+otzgtW9rRWTFcM87KYRCiik3JgIR4CvOuQXAscDnvOu8CnjMOXcI8Ji3PBH5IrAhsPw94DrvuvehaVUmEj8CHnLOHQ4sQ699Qj9rEZkJfAFY6ZxbjAaxXMzEfNa3AqfHrUv2fM8ADvE+VwA/G+5JJ4VQILWUGwc8zrmdzrmXvN/NaCMxk77pRH4NvG98apg+RKQKOAv4lbcswLvR9Ckwwa5bRIqAd6ERfDjnupxzDUyCZ41GTeZ6Y5vygJ1MwGftnHua/uO2kj3f84DfOOU5oEREKodz3skiFBKl3Jg5TnUZE7yMs0cAzwPTnHM7QQUHMHX8apY2rge+CvR6y+VAg3Mu4i1PtGc+D6gFbvFMZr8SkXwm+LN2zu0AfgBsQ4VBI7Caif2sgyR7vqPWxk0WoZBSOo2JgogUAHcBX3LONY13fdKNiJwN7HHOrQ6uTlB0Ij3zLGAF8DPn3BFAKxPMVJQIz4Z+HjAXmAHko6aTeCbSs06FUXvfJ4tQSCXlxoRAREKoQPidc+5P3urdvirpfe8Zr/qlieOBc0VkC2oafDeqOZR4JgaYeM+8Gqh2zj3vLd+JComJ/qxPBTY752qdc93An4B3MLGfdZBkz3fU2rjJIhRSSblxwOPZ0W8CNjjnrg1sCqYT+Rhw71jXLZ045/7dOVflnJuDPtvHnXMfBp5A06fABLtu59wuYLv8//buIMSmKI7j+PeX0JMsUFIaElkoZiFNspjYyU6aRGpiMxs2pGykWNhpGptRdlI2ZCV6CxGRmpFYTrNDZoFE0vS3OOddtzczzXvTPG+89/vUbe78Z5o5tzPT/55z7v0faUcOHQTe0+F9TZo26pO0Kv+91667Y/u6zlz9+wA4mZ9C6gO+1qaZmtU1bzRLOkS6e6yV3Lja5iYtOkn7gafAW/7OrV8krSvcBXpI/1RHI6IjCw9K6gfORcRhSVtJI4e1wBhwIiJ+tbN9i0lSL2lhfQUwAQySbvQ6uq8lXQYGSE/bjQGnSfPnHdXXku4A/aQS2Z+AS8B9ZunfnCBHSE8r/QAGI+L1gn5vtyQFMzObX7dMH5mZWQOcFMzMrOCkYGZmBScFMzMrOCmYmVnBScGsjqRpSeOlY9HeFJa0pVz10mypadl2nGb/sZ8R0dvuRpi1g0cKZg2SNCnpmqRX+diW45slVXMd+6qknhzfIOmepDf52Jd/1DJJN/OeAI8kVdp2UWZ1nBTMZqrUTR8NlL72LSL2kt4evZ5jI6SyxbuA28Bwjg8DTyJiN6ku0bsc3w7ciIidwBfgSIuvx6xhfqPZrI6k7xGxepb4JHAgIiZy4cGPEbFO0hSwMSJ+5/iHiFgv6TOwqVxuIZc0f5w3SUHSBWB5RFxp/ZWZzc8jBbPmxBznc33PbMo1eabx2p4tIU4KZs0ZKH18kc+fk6qzAhwHnuXzKjAExf7Ra/5VI80WyncoZjNVJI2XPn8YEbXHUldKekm6oTqWY2eAW5LOk3ZDG8zxs8CopFOkEcEQabcwsyXLawpmDcprCnsiYqrdbTFrFU8fmZlZwSMFMzMreKRgZmYFJwUzMys4KZiZWcFJwczMCk4KZmZW+AMSPSfUQG614wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure()\n",
    "plt.plot(history4.history['acc'])\n",
    "plt.plot(history4.history['val_acc'])\n",
    "plt.title('Model4 inceptionV2 freezing weight accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure()\n",
    "plt.plot(history4.history['loss'])\n",
    "plt.plot(history4.history['val_loss'])\n",
    "plt.title('Model4 inceptionV2 freezing weight loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 3])\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model, accuracy of validation-set didn't much and the loss value showed that <b>this model overfit very quickly</b> as Model 2 (as you can see from the minimum validation loss is at 3rd epoch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model 5 (4 convolutional layers model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model5 4-Conv layers...\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 49s 174ms/step - loss: 0.7021 - acc: 0.5100 - val_loss: 0.6937 - val_acc: 0.5027\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69365, saving model to best_4conv.hdf5\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 33s 119ms/step - loss: 0.6940 - acc: 0.4935 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69365 to 0.69321, saving model to best_4conv.hdf5\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 33s 118ms/step - loss: 0.6940 - acc: 0.4958 - val_loss: 0.6932 - val_acc: 0.4987\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.69321 to 0.69315, saving model to best_4conv.hdf5\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 35s 126ms/step - loss: 0.6939 - acc: 0.4998 - val_loss: 0.6932 - val_acc: 0.4987\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.69315\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 33s 117ms/step - loss: 0.6936 - acc: 0.4929 - val_loss: 0.6932 - val_acc: 0.4980\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.69315\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 33s 118ms/step - loss: 0.6942 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.69315 to 0.69313, saving model to best_4conv.hdf5\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 33s 119ms/step - loss: 0.6936 - acc: 0.4998 - val_loss: 0.6932 - val_acc: 0.4980\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.69313\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 33s 118ms/step - loss: 0.6938 - acc: 0.4924 - val_loss: 0.6931 - val_acc: 0.4987\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.69313\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 34s 123ms/step - loss: 0.6940 - acc: 0.4982 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.69313\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 34s 123ms/step - loss: 0.6934 - acc: 0.5202 - val_loss: 0.6920 - val_acc: 0.5168\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.69313 to 0.69196, saving model to best_4conv.hdf5\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 34s 120ms/step - loss: 0.6940 - acc: 0.4938 - val_loss: 0.6933 - val_acc: 0.4993\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.69196\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 34s 123ms/step - loss: 0.6939 - acc: 0.5096 - val_loss: 0.6910 - val_acc: 0.5391\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.69196 to 0.69096, saving model to best_4conv.hdf5\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 34s 119ms/step - loss: 0.6937 - acc: 0.5131 - val_loss: 0.6917 - val_acc: 0.5168\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.69096\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 33s 119ms/step - loss: 0.6919 - acc: 0.5205 - val_loss: 0.6930 - val_acc: 0.5492\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.69096\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 35s 125ms/step - loss: 0.6927 - acc: 0.5193 - val_loss: 0.6902 - val_acc: 0.5357\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.69096 to 0.69020, saving model to best_4conv.hdf5\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 34s 122ms/step - loss: 0.6915 - acc: 0.5227 - val_loss: 0.6887 - val_acc: 0.5505\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.69020 to 0.68869, saving model to best_4conv.hdf5\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 34s 121ms/step - loss: 0.6917 - acc: 0.5269 - val_loss: 0.6905 - val_acc: 0.5209\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.68869\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 35s 124ms/step - loss: 0.6923 - acc: 0.5125 - val_loss: 0.6933 - val_acc: 0.5034\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.68869\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 34s 120ms/step - loss: 0.6936 - acc: 0.5113 - val_loss: 0.7055 - val_acc: 0.5451\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.68869\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 34s 120ms/step - loss: 0.6925 - acc: 0.5320 - val_loss: 0.6892 - val_acc: 0.5418\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.68869\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 34s 121ms/step - loss: 0.6886 - acc: 0.5478 - val_loss: 0.6879 - val_acc: 0.5457\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.68869 to 0.68790, saving model to best_4conv.hdf5\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 34s 121ms/step - loss: 0.6913 - acc: 0.5331 - val_loss: 0.7345 - val_acc: 0.5162\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.68790\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 33s 118ms/step - loss: 0.6897 - acc: 0.5427 - val_loss: 0.7257 - val_acc: 0.5290\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.68790\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 33s 118ms/step - loss: 0.6902 - acc: 0.5329 - val_loss: 0.6882 - val_acc: 0.5492\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.68790\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 33s 117ms/step - loss: 0.6897 - acc: 0.5318 - val_loss: 0.6827 - val_acc: 0.5586\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.68790 to 0.68273, saving model to best_4conv.hdf5\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 33s 118ms/step - loss: 0.6899 - acc: 0.5411 - val_loss: 0.6866 - val_acc: 0.5499\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.68273\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 35s 124ms/step - loss: 0.6887 - acc: 0.5394 - val_loss: 0.6860 - val_acc: 0.5586\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.68273\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 34s 122ms/step - loss: 0.6903 - acc: 0.5289 - val_loss: 0.6860 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.68273\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 33s 119ms/step - loss: 0.6888 - acc: 0.5409 - val_loss: 0.6861 - val_acc: 0.5492\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.68273\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 34s 119ms/step - loss: 0.6865 - acc: 0.5478 - val_loss: 0.7004 - val_acc: 0.5465\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.68273\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 35s 125ms/step - loss: 0.6896 - acc: 0.5411 - val_loss: 0.6941 - val_acc: 0.5553\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.68273\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 35s 123ms/step - loss: 0.6882 - acc: 0.5463 - val_loss: 0.6842 - val_acc: 0.5566\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.68273\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 33s 117ms/step - loss: 0.6880 - acc: 0.5469 - val_loss: 0.6848 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.68273\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 33s 117ms/step - loss: 0.6875 - acc: 0.5465 - val_loss: 0.6864 - val_acc: 0.5633\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.68273\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 33s 119ms/step - loss: 0.6899 - acc: 0.5418 - val_loss: 0.6890 - val_acc: 0.5209\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.68273\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 34s 122ms/step - loss: 0.6924 - acc: 0.5256 - val_loss: 0.6896 - val_acc: 0.5303\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.68273\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 35s 125ms/step - loss: 0.6866 - acc: 0.5476 - val_loss: 0.6914 - val_acc: 0.5364\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.68273\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 35s 124ms/step - loss: 0.6855 - acc: 0.5465 - val_loss: 0.6856 - val_acc: 0.5694\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.68273\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 33s 116ms/step - loss: 0.6896 - acc: 0.5465 - val_loss: 0.6860 - val_acc: 0.5586\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.68273\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 33s 116ms/step - loss: 0.6865 - acc: 0.5480 - val_loss: 0.6863 - val_acc: 0.5465\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.68273\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 33s 119ms/step - loss: 0.6859 - acc: 0.5525 - val_loss: 0.6910 - val_acc: 0.5573\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.68273\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 33s 118ms/step - loss: 0.6916 - acc: 0.5331 - val_loss: 0.6856 - val_acc: 0.5647\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.68273\n",
      "Epoch 43/100\n",
      "281/281 [==============================] - 33s 118ms/step - loss: 0.6909 - acc: 0.5347 - val_loss: 0.6926 - val_acc: 0.5465\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.68273\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 33s 118ms/step - loss: 0.6886 - acc: 0.5411 - val_loss: 0.6855 - val_acc: 0.5573\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.68273\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 36s 127ms/step - loss: 0.6886 - acc: 0.5360 - val_loss: 0.7076 - val_acc: 0.5553\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.68273\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 34s 121ms/step - loss: 0.6875 - acc: 0.5378 - val_loss: 0.6956 - val_acc: 0.5580\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.68273\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 33s 117ms/step - loss: 0.6874 - acc: 0.5463 - val_loss: 0.6849 - val_acc: 0.5627\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.68273\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 33s 118ms/step - loss: 0.6890 - acc: 0.5302 - val_loss: 0.6904 - val_acc: 0.5633\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.68273\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 34s 120ms/step - loss: 0.6883 - acc: 0.5503 - val_loss: 0.6930 - val_acc: 0.5088\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.68273\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 33s 116ms/step - loss: 0.6900 - acc: 0.5391 - val_loss: 0.6872 - val_acc: 0.5303\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.68273\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 33s 118ms/step - loss: 0.6876 - acc: 0.5536 - val_loss: 0.7039 - val_acc: 0.5512\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.68273\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 34s 122ms/step - loss: 0.6889 - acc: 0.5447 - val_loss: 0.6847 - val_acc: 0.5559\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.68273\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 33s 119ms/step - loss: 0.6882 - acc: 0.5467 - val_loss: 0.6986 - val_acc: 0.5532\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.68273\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 34s 122ms/step - loss: 0.6897 - acc: 0.5431 - val_loss: 0.6878 - val_acc: 0.5633\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.68273\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 35s 124ms/step - loss: 0.6876 - acc: 0.5427 - val_loss: 0.6924 - val_acc: 0.5620\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.68273\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 34s 120ms/step - loss: 0.6879 - acc: 0.5447 - val_loss: 0.6922 - val_acc: 0.5485\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.68273\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 34s 120ms/step - loss: 0.6868 - acc: 0.5496 - val_loss: 0.6965 - val_acc: 0.5546\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.68273\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 33s 119ms/step - loss: 0.6896 - acc: 0.5394 - val_loss: 0.7002 - val_acc: 0.5559\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.68273\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 34s 120ms/step - loss: 0.6845 - acc: 0.5587 - val_loss: 0.6843 - val_acc: 0.5445\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.68273\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 33s 118ms/step - loss: 0.6902 - acc: 0.5331 - val_loss: 0.6845 - val_acc: 0.5532\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.68273\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 33s 117ms/step - loss: 0.6851 - acc: 0.5585 - val_loss: 0.6904 - val_acc: 0.5580\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.68273\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 34s 121ms/step - loss: 0.6905 - acc: 0.5416 - val_loss: 0.6967 - val_acc: 0.5573\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.68273\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 33s 119ms/step - loss: 0.6840 - acc: 0.5547 - val_loss: 0.6916 - val_acc: 0.5633\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.68273\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 33s 118ms/step - loss: 0.6858 - acc: 0.5460 - val_loss: 0.7126 - val_acc: 0.5330\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.68273\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 33s 117ms/step - loss: 0.6858 - acc: 0.5516 - val_loss: 0.6972 - val_acc: 0.5660\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.68273\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 34s 121ms/step - loss: 0.6879 - acc: 0.5463 - val_loss: 0.6848 - val_acc: 0.5404\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.68273\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 34s 122ms/step - loss: 0.6876 - acc: 0.5427 - val_loss: 0.6829 - val_acc: 0.5687\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.68273\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 33s 117ms/step - loss: 0.6880 - acc: 0.5414 - val_loss: 0.6933 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.68273\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 33s 118ms/step - loss: 0.6932 - acc: 0.5182 - val_loss: 0.6849 - val_acc: 0.5640\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.68273\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 34s 121ms/step - loss: 0.6900 - acc: 0.5336 - val_loss: 0.6985 - val_acc: 0.5492\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.68273\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 34s 120ms/step - loss: 0.6866 - acc: 0.5529 - val_loss: 0.6888 - val_acc: 0.5586\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.68273\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 34s 121ms/step - loss: 0.6915 - acc: 0.5302 - val_loss: 0.6922 - val_acc: 0.5425\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.68273\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 35s 126ms/step - loss: 0.6913 - acc: 0.5378 - val_loss: 0.6926 - val_acc: 0.5216\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.68273\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 36s 128ms/step - loss: 0.6908 - acc: 0.5394 - val_loss: 0.6885 - val_acc: 0.5795\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.68273\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 37s 131ms/step - loss: 0.6910 - acc: 0.5398 - val_loss: 0.6865 - val_acc: 0.5721\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.68273\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 34s 120ms/step - loss: 0.6864 - acc: 0.5480 - val_loss: 0.6894 - val_acc: 0.5209\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.68273\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 34s 123ms/step - loss: 0.6905 - acc: 0.5365 - val_loss: 0.6886 - val_acc: 0.5606\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.68273\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 38s 134ms/step - loss: 0.6863 - acc: 0.5476 - val_loss: 0.7012 - val_acc: 0.5425\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.68273\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 35s 124ms/step - loss: 0.6865 - acc: 0.5507 - val_loss: 0.6986 - val_acc: 0.5606\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.68273\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 35s 123ms/step - loss: 0.6876 - acc: 0.5592 - val_loss: 0.7205 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.68273\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 34s 122ms/step - loss: 0.6902 - acc: 0.5427 - val_loss: 0.6876 - val_acc: 0.5620\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.68273\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 32s 112ms/step - loss: 0.6859 - acc: 0.5427 - val_loss: 0.6909 - val_acc: 0.5606\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.68273\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 31s 111ms/step - loss: 0.6848 - acc: 0.5625 - val_loss: 0.6968 - val_acc: 0.5566\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.68273\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 33s 119ms/step - loss: 0.6883 - acc: 0.5425 - val_loss: 0.6922 - val_acc: 0.5398\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.68273\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 36s 126ms/step - loss: 0.6879 - acc: 0.5465 - val_loss: 0.6931 - val_acc: 0.5559\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.68273\n",
      "Epoch 86/100\n",
      "281/281 [==============================] - 34s 122ms/step - loss: 0.6893 - acc: 0.5407 - val_loss: 0.6873 - val_acc: 0.5586\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.68273\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 32s 114ms/step - loss: 0.6888 - acc: 0.5463 - val_loss: 0.6943 - val_acc: 0.5553\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.68273\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 33s 116ms/step - loss: 0.6896 - acc: 0.5431 - val_loss: 0.6920 - val_acc: 0.5135\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.68273\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 33s 118ms/step - loss: 0.6908 - acc: 0.5334 - val_loss: 0.6899 - val_acc: 0.5364\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.68273\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 33s 119ms/step - loss: 0.6854 - acc: 0.5463 - val_loss: 0.6863 - val_acc: 0.5580\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.68273\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 34s 120ms/step - loss: 0.6866 - acc: 0.5576 - val_loss: 0.7338 - val_acc: 0.5175\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.68273\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 34s 119ms/step - loss: 0.6888 - acc: 0.5367 - val_loss: 0.6965 - val_acc: 0.5687\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.68273\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 33s 117ms/step - loss: 0.6861 - acc: 0.5569 - val_loss: 0.7033 - val_acc: 0.5411\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.68273\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 33s 116ms/step - loss: 0.6866 - acc: 0.5549 - val_loss: 0.7123 - val_acc: 0.5613\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.68273\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 33s 117ms/step - loss: 0.6882 - acc: 0.5487 - val_loss: 0.6880 - val_acc: 0.5559\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.68273\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 33s 116ms/step - loss: 0.6897 - acc: 0.5405 - val_loss: 0.7101 - val_acc: 0.5566\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.68273\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 33s 118ms/step - loss: 0.6891 - acc: 0.5523 - val_loss: 0.7250 - val_acc: 0.5451\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.68273\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 33s 118ms/step - loss: 0.6869 - acc: 0.5458 - val_loss: 0.6875 - val_acc: 0.5606\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.68273\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 33s 117ms/step - loss: 0.6868 - acc: 0.5503 - val_loss: 0.6898 - val_acc: 0.5593\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.68273\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 33s 117ms/step - loss: 0.6902 - acc: 0.5396 - val_loss: 0.7135 - val_acc: 0.5553\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.68273\n",
      "Done. Elapsed time 3400 seconds for 100 epochs, average 34.0 seconds/epoch.\n"
     ]
    }
   ],
   "source": [
    "# Start timing\n",
    "start = time.time()\n",
    "\n",
    "# Training\n",
    "print('Training the model5 4-Conv layers...')\n",
    "history5 = model5.fit_generator(\n",
    "    generator = train_flow,\n",
    "    steps_per_epoch = TRAIN_STEPS,\n",
    "    epochs = N_EPOCHS + EPOCHS,\n",
    "    initial_epoch = N_EPOCHS,\n",
    "    verbose = 1,\n",
    "    callbacks = cb5,\n",
    "    validation_data = valid_flow,\n",
    "    validation_steps = VALID_STEPS)\n",
    "stop = time.time()\n",
    "etime = stop - start\n",
    "print('Done. Elapsed time {:.0f} seconds for {:} epochs, average {:.1f} seconds/epoch.'.format(etime, EPOCHS, etime/EPOCHS))\n",
    "\n",
    "# Save last model\n",
    "model5.save(last_weight_model5)\n",
    "\n",
    "# Save the history\n",
    "with open(last_his_model5, 'wb') as file_pi:\n",
    "    pickle.dump(history5.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This training model 5 used total time 3,400 seconds for 100 epochs, and average time 34.0 seconds/epoch. We ended up with <b>24th as the best epoch</b>.\n",
    "\n",
    "Then, I plotted accuracy and loss value for each epoch into line graph as you can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure()\n",
    "plt.plot(history5.history['acc'])\n",
    "plt.plot(history5.history['val_acc'])\n",
    "plt.title('Model5 4-Conv layers accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure()\n",
    "plt.plot(history5.history['loss'])\n",
    "plt.plot(history5.history['val_loss'])\n",
    "plt.title('Model5 4-Conv layers loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 3])\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model didn't tend to have more accuracy or even less loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I modified function from Sakari's notebook (Demo 11) by adding calculation for <b>Sensitivity, Specification, and False negative rate</b>. I use this function to showed efficiecy of each model by using the same validation flow.\n",
    "\n",
    "<a href=\"https://en.wikipedia.org/wiki/Sensitivity_and_specificity\">(From this link)</a> Normally, we will consider positive as sick people (1 in my case) and negative to healthy people (0 in my case). So, I had to set the label of 'confusion_matrix' function as [1,0] to get the correct definition of False negative rate as I want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display confusion matrix, classification report, accuracy, specification, sensitivity, and false negative\n",
    "def display_results(path, flow):\n",
    "    global valid_flow, valid_test_generator\n",
    "     \n",
    "    # Reinitial valid_flow\n",
    "    valid_flow = valid_test_generator.flow_from_dataframe(\n",
    "        dataframe = df_val_balance,\n",
    "        directory = balance_dir,\n",
    "        has_ext = False,\n",
    "        x_col = 'image', \n",
    "        y_col = 'level', \n",
    "        target_size = (IMAGE_SIZE, IMAGE_SIZE), \n",
    "        classes = [0, 1], \n",
    "        class_mode = 'binary', \n",
    "        batch_size = BATCH_SIZE, \n",
    "        shuffle = False)\n",
    "    \n",
    "    # Load model from given path\n",
    "    m = load_model(path)\n",
    "    \n",
    "    # Get the true and predicted values\n",
    "    y_true = flow.classes\n",
    "    predict = m.predict_generator(flow, steps=len(flow), verbose=1)\n",
    "    y_pred = 1*(predict > 0.5)\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        \n",
    "        # Create confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "        print('Confusion matrix:')\n",
    "        print(cm)\n",
    "        print('')\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        a = accuracy_score(y_true, y_pred)\n",
    "        print('Accuracy: {:.4f}'.format(a))\n",
    "        print('')\n",
    "        \n",
    "        # Calculate Sensitivity\n",
    "        sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "        print('Sensitivity: {:.4f}'.format(sensitivity))\n",
    "        print('')\n",
    "        \n",
    "        # Calculate Specificity\n",
    "        specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "        print('Specificity: {:.4f}'.format(specificity))\n",
    "        print('')\n",
    "        \n",
    "        # Calculate False Negative Rate\n",
    "        print('False Negative Rate: {:.4f}'.format(1-sensitivity))\n",
    "        print('')\n",
    "        \n",
    "        # Display classification report\n",
    "        cr = classification_report(y_true, y_pred)\n",
    "        print('Classification report:')\n",
    "        print(cr)\n",
    "    \n",
    "    # Clear tensorflow backend session and delete m variable\n",
    "    K.clear_session()\n",
    "    del m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection the best of all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show efficiency of each model after training 100 epochs (200 epochs for some model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** VALIDATION SET ****\n",
      "\n",
      "Result from the LAST model1 Xception\n",
      "Found 1500 images belonging to 2 classes.\n",
      "94/94 [==============================] - 15s 163ms/step\n",
      "Confusion matrix:\n",
      "[[491 259]\n",
      " [189 561]]\n",
      "\n",
      "Accuracy: 0.7013\n",
      "\n",
      "Sensitivity: 0.6547\n",
      "\n",
      "Specificity: 0.7480\n",
      "\n",
      "False Negative Rate: 0.3453\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.75      0.71       750\n",
      "           1       0.72      0.65      0.69       750\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      1500\n",
      "   macro avg       0.70      0.70      0.70      1500\n",
      "weighted avg       0.70      0.70      0.70      1500\n",
      "\n",
      "=====================================\n",
      "Result from the LAST further model1 Xception\n",
      "Found 1500 images belonging to 2 classes.\n",
      "94/94 [==============================] - 16s 166ms/step\n",
      "Confusion matrix:\n",
      "[[514 236]\n",
      " [215 535]]\n",
      "\n",
      "Accuracy: 0.6993\n",
      "\n",
      "Sensitivity: 0.6853\n",
      "\n",
      "Specificity: 0.7133\n",
      "\n",
      "False Negative Rate: 0.3147\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70       750\n",
      "           1       0.71      0.69      0.70       750\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      1500\n",
      "   macro avg       0.70      0.70      0.70      1500\n",
      "weighted avg       0.70      0.70      0.70      1500\n",
      "\n",
      "=====================================\n",
      "Result from the LAST model2 Xception freezing weight\n",
      "Found 1500 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pasin\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\saving.py:327: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 18s 190ms/step\n",
      "Confusion matrix:\n",
      "[[332 418]\n",
      " [270 480]]\n",
      "\n",
      "Accuracy: 0.5413\n",
      "\n",
      "Sensitivity: 0.4427\n",
      "\n",
      "Specificity: 0.6400\n",
      "\n",
      "False Negative Rate: 0.5573\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.64      0.58       750\n",
      "           1       0.55      0.44      0.49       750\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      1500\n",
      "   macro avg       0.54      0.54      0.54      1500\n",
      "weighted avg       0.54      0.54      0.54      1500\n",
      "\n",
      "=====================================\n",
      "Result from the LAST model3 InceptionV2\n",
      "Found 1500 images belonging to 2 classes.\n",
      "94/94 [==============================] - 24s 253ms/step\n",
      "Confusion matrix:\n",
      "[[353 397]\n",
      " [112 638]]\n",
      "\n",
      "Accuracy: 0.6607\n",
      "\n",
      "Sensitivity: 0.4707\n",
      "\n",
      "Specificity: 0.8507\n",
      "\n",
      "False Negative Rate: 0.5293\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.85      0.71       750\n",
      "           1       0.76      0.47      0.58       750\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      1500\n",
      "   macro avg       0.69      0.66      0.65      1500\n",
      "weighted avg       0.69      0.66      0.65      1500\n",
      "\n",
      "=====================================\n",
      "Result from the LAST further model3 InceptionV2\n",
      "Found 1500 images belonging to 2 classes.\n",
      "94/94 [==============================] - 23s 245ms/step\n",
      "Confusion matrix:\n",
      "[[503 247]\n",
      " [236 514]]\n",
      "\n",
      "Accuracy: 0.6780\n",
      "\n",
      "Sensitivity: 0.6707\n",
      "\n",
      "Specificity: 0.6853\n",
      "\n",
      "False Negative Rate: 0.3293\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.68       750\n",
      "           1       0.68      0.67      0.68       750\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      1500\n",
      "   macro avg       0.68      0.68      0.68      1500\n",
      "weighted avg       0.68      0.68      0.68      1500\n",
      "\n",
      "=====================================\n",
      "Result from the LAST model4 InceptionV2 freezing weight\n",
      "Found 1500 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pasin\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\saving.py:327: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 32s 345ms/step\n",
      "Confusion matrix:\n",
      "[[645 105]\n",
      " [594 156]]\n",
      "\n",
      "Accuracy: 0.5340\n",
      "\n",
      "Sensitivity: 0.8600\n",
      "\n",
      "Specificity: 0.2080\n",
      "\n",
      "False Negative Rate: 0.1400\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.21      0.31       750\n",
      "           1       0.52      0.86      0.65       750\n",
      "\n",
      "   micro avg       0.53      0.53      0.53      1500\n",
      "   macro avg       0.56      0.53      0.48      1500\n",
      "weighted avg       0.56      0.53      0.48      1500\n",
      "\n",
      "=====================================\n",
      "Result from the LAST model5 4-Conv layers\n",
      "Found 1500 images belonging to 2 classes.\n",
      "94/94 [==============================] - 6s 63ms/step\n",
      "Confusion matrix:\n",
      "[[278 472]\n",
      " [197 553]]\n",
      "\n",
      "Accuracy: 0.5540\n",
      "\n",
      "Sensitivity: 0.3707\n",
      "\n",
      "Specificity: 0.7373\n",
      "\n",
      "False Negative Rate: 0.6293\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.74      0.62       750\n",
      "           1       0.59      0.37      0.45       750\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      1500\n",
      "   macro avg       0.56      0.55      0.54      1500\n",
      "weighted avg       0.56      0.55      0.54      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('**** VALIDATION SET ****')\n",
    "print('')\n",
    "\n",
    "# Display evaluation of the last model\n",
    "print('Result from the LAST model1 Xception')\n",
    "display_results(last_weight_model1, valid_flow)\n",
    "print('=====================================')\n",
    "\n",
    "print('Result from the LAST further model1 Xception')\n",
    "display_results(fur_weight_model1, valid_flow)\n",
    "print('=====================================')\n",
    "\n",
    "print('Result from the LAST model2 Xception freezing weight')\n",
    "display_results(last_weight_model2, valid_flow)\n",
    "print('=====================================')\n",
    "\n",
    "print('Result from the LAST model3 InceptionV2')\n",
    "display_results(last_weight_model3, valid_flow)\n",
    "print('=====================================')\n",
    "\n",
    "print('Result from the LAST further model3 InceptionV2')\n",
    "display_results(fur_weight_model3, valid_flow)\n",
    "print('=====================================')\n",
    "\n",
    "print('Result from the LAST model4 InceptionV2 freezing weight')\n",
    "display_results(last_weight_model4, valid_flow)\n",
    "print('=====================================')\n",
    "\n",
    "print('Result from the LAST model5 4-Conv layers')\n",
    "display_results(last_weight_model5, valid_flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show efficiency of each model from the epoch that given the minimum validation loss while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION SET\n",
      "\n",
      "Result from the BEST model1 Xception\n",
      "Found 1500 images belonging to 2 classes.\n",
      "94/94 [==============================] - 16s 167ms/step\n",
      "Confusion matrix:\n",
      "[[541 209]\n",
      " [193 557]]\n",
      "\n",
      "Accuracy: 0.7320\n",
      "\n",
      "Sensitivity: 0.7213\n",
      "\n",
      "Specificity: 0.7427\n",
      "\n",
      "False Negative Rate: 0.2787\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.73       750\n",
      "           1       0.74      0.72      0.73       750\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      1500\n",
      "   macro avg       0.73      0.73      0.73      1500\n",
      "weighted avg       0.73      0.73      0.73      1500\n",
      "\n",
      "=====================================\n",
      "Result from the BEST further model1 Xception\n",
      "Found 1500 images belonging to 2 classes.\n",
      "94/94 [==============================] - 15s 164ms/step\n",
      "Confusion matrix:\n",
      "[[432 318]\n",
      " [ 85 665]]\n",
      "\n",
      "Accuracy: 0.7313\n",
      "\n",
      "Sensitivity: 0.5760\n",
      "\n",
      "Specificity: 0.8867\n",
      "\n",
      "False Negative Rate: 0.4240\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77       750\n",
      "           1       0.84      0.58      0.68       750\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      1500\n",
      "   macro avg       0.76      0.73      0.72      1500\n",
      "weighted avg       0.76      0.73      0.72      1500\n",
      "\n",
      "=====================================\n",
      "Result from the BEST model2 Xception freezing weight\n",
      "Found 1500 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pasin\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\saving.py:327: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 18s 190ms/step\n",
      "Confusion matrix:\n",
      "[[223 527]\n",
      " [141 609]]\n",
      "\n",
      "Accuracy: 0.5547\n",
      "\n",
      "Sensitivity: 0.2973\n",
      "\n",
      "Specificity: 0.8120\n",
      "\n",
      "False Negative Rate: 0.7027\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.81      0.65       750\n",
      "           1       0.61      0.30      0.40       750\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      1500\n",
      "   macro avg       0.57      0.55      0.52      1500\n",
      "weighted avg       0.57      0.55      0.52      1500\n",
      "\n",
      "=====================================\n",
      "Result from the BEST model3 InceptionV2\n",
      "Found 1500 images belonging to 2 classes.\n",
      "94/94 [==============================] - 23s 244ms/step\n",
      "Confusion matrix:\n",
      "[[442 308]\n",
      " [142 608]]\n",
      "\n",
      "Accuracy: 0.7000\n",
      "\n",
      "Sensitivity: 0.5893\n",
      "\n",
      "Specificity: 0.8107\n",
      "\n",
      "False Negative Rate: 0.4107\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.81      0.73       750\n",
      "           1       0.76      0.59      0.66       750\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      1500\n",
      "   macro avg       0.71      0.70      0.70      1500\n",
      "weighted avg       0.71      0.70      0.70      1500\n",
      "\n",
      "=====================================\n",
      "Result from the BEST further model3 InceptionV2\n",
      "Found 1500 images belonging to 2 classes.\n",
      "94/94 [==============================] - 23s 245ms/step\n",
      "Confusion matrix:\n",
      "[[486 264]\n",
      " [195 555]]\n",
      "\n",
      "Accuracy: 0.6940\n",
      "\n",
      "Sensitivity: 0.6480\n",
      "\n",
      "Specificity: 0.7400\n",
      "\n",
      "False Negative Rate: 0.3520\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71       750\n",
      "           1       0.71      0.65      0.68       750\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      1500\n",
      "   macro avg       0.70      0.69      0.69      1500\n",
      "weighted avg       0.70      0.69      0.69      1500\n",
      "\n",
      "=====================================\n",
      "Result from the BEST model4 InceptionV2 freezing weight\n",
      "Found 1500 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pasin\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\saving.py:327: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 32s 342ms/step\n",
      "Confusion matrix:\n",
      "[[418 332]\n",
      " [327 423]]\n",
      "\n",
      "Accuracy: 0.5607\n",
      "\n",
      "Sensitivity: 0.5573\n",
      "\n",
      "Specificity: 0.5640\n",
      "\n",
      "False Negative Rate: 0.4427\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56       750\n",
      "           1       0.56      0.56      0.56       750\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      1500\n",
      "   macro avg       0.56      0.56      0.56      1500\n",
      "weighted avg       0.56      0.56      0.56      1500\n",
      "\n",
      "=====================================\n",
      "Result from the BEST model5 4-Conv layers\n",
      "Found 1500 images belonging to 2 classes.\n",
      "94/94 [==============================] - 6s 66ms/step\n",
      "Confusion matrix:\n",
      "[[352 398]\n",
      " [267 483]]\n",
      "\n",
      "Accuracy: 0.5567\n",
      "\n",
      "Sensitivity: 0.4693\n",
      "\n",
      "Specificity: 0.6440\n",
      "\n",
      "False Negative Rate: 0.5307\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.64      0.59       750\n",
      "           1       0.57      0.47      0.51       750\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      1500\n",
      "   macro avg       0.56      0.56      0.55      1500\n",
      "weighted avg       0.56      0.56      0.55      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('VALIDATION SET')\n",
    "print('')\n",
    "\n",
    "# Display evaluation of the best model\n",
    "print('Result from the BEST model1 Xception')\n",
    "display_results(best_weight_model1, valid_flow)\n",
    "print('=====================================')\n",
    "\n",
    "print('Result from the BEST further model1 Xception')\n",
    "display_results(best_weight_model1_fur, valid_flow)\n",
    "print('=====================================')\n",
    "\n",
    "print('Result from the BEST model2 Xception freezing weight')\n",
    "display_results(best_weight_model2, valid_flow)\n",
    "print('=====================================')\n",
    "\n",
    "print('Result from the BEST model3 InceptionV2')\n",
    "display_results(best_weight_model3, valid_flow)\n",
    "print('=====================================')\n",
    "\n",
    "print('Result from the BEST further model3 InceptionV2')\n",
    "display_results(best_weight_model3_fur, valid_flow)\n",
    "print('=====================================')\n",
    "\n",
    "print('Result from the BEST model4 InceptionV2 freezing weight')\n",
    "display_results(best_weight_model4, valid_flow)\n",
    "print('=====================================')\n",
    "\n",
    "print('Result from the BEST model5 4-Conv layers')\n",
    "display_results(best_weight_model5, valid_flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the result, Top 3 best models (consider from high accuracy) are:\n",
    "    1. BEST Model 1 Xception pretraining model (89th epoch)\n",
    "        * Accuracy = 73.20%\n",
    "        * False Negative Rate = 27.87%\n",
    "    2. BEST futher Model 1 Xception pretraining model (124th epoch)\n",
    "        * Accuracy = 73.13%\n",
    "        * False Negative Rate = 42.40%\n",
    "    3. BEST Model 3 InceptionResNetV2 pretraining model (36th epoch)\n",
    "        * Accuracy = 70.00%\n",
    "        * False Negative Rate = 41.07%\n",
    "    \n",
    "\n",
    "From above comparison, the best model that I selected was <b> Model 1 Xception pretraining model (89th epoch)</b> because  it has highest average accuracy score and lowest False Negative rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with training by imbalance dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I already mentioned before, one of my hypothesis is that traning with balanced dataset should given a better result than training with imbalance dataset that lead model to has bias. Now, I will try to <b>train my best model (<b>Xception model</b>) with imbalance dataset</b> that I already created.\n",
    "\n",
    "So, I created new flow for imbalanced training-set and validation-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training flow (imbalance):\n",
      "Found 768 images belonging to 2 classes.\n",
      "Validation flow (imbalance):\n",
      "Found 239 images belonging to 2 classes.\n",
      "\n",
      "How many records for each class (imbalance)\n",
      "0    3334\n",
      "1    1166\n",
      "Name: level, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Training flow (imbalance)\n",
    "print('Training flow (imbalance):')\n",
    "train_flow_unbalance = train_generator.flow_from_dataframe(\n",
    "    dataframe = df_unbalance[:SPLIT],\n",
    "    directory = unbalance_dir,\n",
    "    has_ext = False,\n",
    "    x_col = 'image', \n",
    "    y_col = 'level', \n",
    "    target_size = (IMAGE_SIZE, IMAGE_SIZE), \n",
    "    classes = [0, 1], \n",
    "    class_mode = 'binary', \n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = True, \n",
    "    seed = 1)\n",
    "\n",
    "# Validation flow (imbalance)\n",
    "print('Validation flow (imbalance):')\n",
    "valid_flow_unbalance = valid_test_generator.flow_from_dataframe(\n",
    "    dataframe = df_unbalance[SPLIT:],\n",
    "    directory = unbalance_dir,\n",
    "    has_ext = False,\n",
    "    x_col = 'image', \n",
    "    y_col = 'level', \n",
    "    target_size = (IMAGE_SIZE, IMAGE_SIZE), \n",
    "    classes = [0, 1], \n",
    "    class_mode = 'binary', \n",
    "    batch_size = BATCH_SIZE, \n",
    "    shuffle = False)\n",
    "\n",
    "print('')\n",
    "print(\"How many records for each class (imbalance)\")\n",
    "print(df_unbalance[:SPLIT]['level'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I reinitial my best architecture model with the same weight from ImageNet pretraining and them train it by 100 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitial the best model\n",
    "base_model1_unbal = Xception(input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "x_model1_unbal = Dense(1)(base_model1_unbal.get_layer('avg_pool').output)\n",
    "y_model1_unbal = Activation('sigmoid')(x_model1_unbal)\n",
    "unbalance_model = Model(inputs = base_model1_unbal.input, outputs = y_model1_unbal)\n",
    "\n",
    "# Optimizer, loss and metrics\n",
    "unbalance_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for history and weight after trainging\n",
    "last_weight_unbal_model = \"100_unbal.hdf5\"\n",
    "last_his_unbal_model = \"100_unbal_his\"\n",
    "best_weight_unbal_model = \"best_unbal.hdf5\"\n",
    "\n",
    "# Create model checkpoint\n",
    "cp_unbal = ModelCheckpoint(best_weight_unbal_model, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min')\n",
    "\n",
    "N_EPOCHS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model with unbalace dataset...\n",
      "Epoch 1/100\n",
      "281/281 [==============================] - 253s 900ms/step - loss: 0.6163 - acc: 0.7327 - val_loss: 1.2433 - val_acc: 0.6619\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.24329, saving model to best_unbal.hdf5\n",
      "Epoch 2/100\n",
      "281/281 [==============================] - 231s 824ms/step - loss: 0.5170 - acc: 0.7696 - val_loss: 1.4088 - val_acc: 0.7227\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.24329\n",
      "Epoch 3/100\n",
      "281/281 [==============================] - 232s 825ms/step - loss: 0.4729 - acc: 0.7916 - val_loss: 2.1885 - val_acc: 0.7402\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.24329\n",
      "Epoch 4/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.4442 - acc: 0.8069 - val_loss: 0.9942 - val_acc: 0.6883\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.24329 to 0.99420, saving model to best_unbal.hdf5\n",
      "Epoch 5/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.4222 - acc: 0.8145 - val_loss: 0.9157 - val_acc: 0.7454\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.99420 to 0.91572, saving model to best_unbal.hdf5\n",
      "Epoch 6/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.3922 - acc: 0.8310 - val_loss: 1.0283 - val_acc: 0.6424\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.91572\n",
      "Epoch 7/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.3657 - acc: 0.8412 - val_loss: 0.7735 - val_acc: 0.7112\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.91572 to 0.77351, saving model to best_unbal.hdf5\n",
      "Epoch 8/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.3404 - acc: 0.8503 - val_loss: 0.9385 - val_acc: 0.7375\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.77351\n",
      "Epoch 9/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.3110 - acc: 0.8732 - val_loss: 1.5728 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.77351\n",
      "Epoch 10/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.2808 - acc: 0.8757 - val_loss: 1.7018 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.77351\n",
      "Epoch 11/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.2669 - acc: 0.8910 - val_loss: 2.0412 - val_acc: 0.7099\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.77351\n",
      "Epoch 12/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.2412 - acc: 0.9039 - val_loss: 2.1237 - val_acc: 0.7422\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.77351\n",
      "Epoch 13/100\n",
      "281/281 [==============================] - 232s 824ms/step - loss: 0.2310 - acc: 0.9075 - val_loss: 1.7521 - val_acc: 0.7341\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.77351\n",
      "Epoch 14/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.1978 - acc: 0.9217 - val_loss: 3.7433 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.77351\n",
      "Epoch 15/100\n",
      "281/281 [==============================] - 232s 825ms/step - loss: 0.1725 - acc: 0.9357 - val_loss: 1.4674 - val_acc: 0.7205\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.77351\n",
      "Epoch 16/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.1677 - acc: 0.9324 - val_loss: 3.6137 - val_acc: 0.7173\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.77351\n",
      "Epoch 17/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.1582 - acc: 0.9399 - val_loss: 1.2022 - val_acc: 0.7051\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.77351\n",
      "Epoch 18/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.1223 - acc: 0.9513 - val_loss: 1.8853 - val_acc: 0.7179\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.77351\n",
      "Epoch 19/100\n",
      "281/281 [==============================] - 232s 825ms/step - loss: 0.1338 - acc: 0.9542 - val_loss: 1.8816 - val_acc: 0.7254\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.77351\n",
      "Epoch 20/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.1140 - acc: 0.9562 - val_loss: 2.7804 - val_acc: 0.7218\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.77351\n",
      "Epoch 21/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.1090 - acc: 0.9580 - val_loss: 1.5555 - val_acc: 0.7308\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.77351\n",
      "Epoch 22/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.1022 - acc: 0.9635 - val_loss: 1.7604 - val_acc: 0.7551\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.77351\n",
      "Epoch 23/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.0854 - acc: 0.9682 - val_loss: 2.5470 - val_acc: 0.7355\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.77351\n",
      "Epoch 24/100\n",
      "281/281 [==============================] - 232s 824ms/step - loss: 0.0815 - acc: 0.9704 - val_loss: 3.1033 - val_acc: 0.7220\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.77351\n",
      "Epoch 25/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0801 - acc: 0.9704 - val_loss: 3.3756 - val_acc: 0.7387\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.77351\n",
      "Epoch 26/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0856 - acc: 0.9735 - val_loss: 2.9782 - val_acc: 0.7301\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.77351\n",
      "Epoch 27/100\n",
      "281/281 [==============================] - 232s 824ms/step - loss: 0.0774 - acc: 0.9700 - val_loss: 2.5549 - val_acc: 0.7625\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.77351\n",
      "Epoch 28/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0712 - acc: 0.9749 - val_loss: 2.1477 - val_acc: 0.7065\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.77351\n",
      "Epoch 29/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0672 - acc: 0.9762 - val_loss: 2.6033 - val_acc: 0.7152\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.77351\n",
      "Epoch 30/100\n",
      "281/281 [==============================] - 231s 824ms/step - loss: 0.0586 - acc: 0.9798 - val_loss: 2.1555 - val_acc: 0.7043\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.77351\n",
      "Epoch 31/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0651 - acc: 0.9773 - val_loss: 2.1895 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.77351\n",
      "Epoch 32/100\n",
      "281/281 [==============================] - 231s 824ms/step - loss: 0.0547 - acc: 0.9822 - val_loss: 3.0060 - val_acc: 0.7335\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.77351\n",
      "Epoch 33/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.0573 - acc: 0.9798 - val_loss: 2.8868 - val_acc: 0.7179\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.77351\n",
      "Epoch 34/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0554 - acc: 0.9815 - val_loss: 1.8647 - val_acc: 0.7018\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.77351\n",
      "Epoch 35/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0500 - acc: 0.9844 - val_loss: 3.0623 - val_acc: 0.7205\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.77351\n",
      "Epoch 36/100\n",
      "281/281 [==============================] - 232s 824ms/step - loss: 0.0507 - acc: 0.9827 - val_loss: 2.9849 - val_acc: 0.7348\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.77351\n",
      "Epoch 37/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0439 - acc: 0.9829 - val_loss: 2.5840 - val_acc: 0.7362\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.77351\n",
      "Epoch 38/100\n",
      "281/281 [==============================] - 231s 824ms/step - loss: 0.0401 - acc: 0.9884 - val_loss: 2.2549 - val_acc: 0.6775\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.77351\n",
      "Epoch 39/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0543 - acc: 0.9824 - val_loss: 2.1292 - val_acc: 0.7139\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.77351\n",
      "Epoch 40/100\n",
      "281/281 [==============================] - 231s 821ms/step - loss: 0.0424 - acc: 0.9851 - val_loss: 2.6008 - val_acc: 0.7421\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.77351\n",
      "Epoch 41/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0382 - acc: 0.9860 - val_loss: 2.1928 - val_acc: 0.6849\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.77351\n",
      "Epoch 42/100\n",
      "281/281 [==============================] - 232s 824ms/step - loss: 0.0437 - acc: 0.9871 - val_loss: 2.4192 - val_acc: 0.6937\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.77351\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 231s 824ms/step - loss: 0.0333 - acc: 0.9902 - val_loss: 2.7392 - val_acc: 0.7240\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.77351\n",
      "Epoch 44/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0381 - acc: 0.9882 - val_loss: 2.4273 - val_acc: 0.7139\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.77351\n",
      "Epoch 45/100\n",
      "281/281 [==============================] - 232s 824ms/step - loss: 0.0414 - acc: 0.9862 - val_loss: 2.3186 - val_acc: 0.7157\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.77351\n",
      "Epoch 46/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0392 - acc: 0.9882 - val_loss: 2.1968 - val_acc: 0.6835\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.77351\n",
      "Epoch 47/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0401 - acc: 0.9882 - val_loss: 2.6536 - val_acc: 0.7301\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.77351\n",
      "Epoch 48/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0383 - acc: 0.9893 - val_loss: 1.8568 - val_acc: 0.7287\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.77351\n",
      "Epoch 49/100\n",
      "281/281 [==============================] - 231s 824ms/step - loss: 0.0312 - acc: 0.9898 - val_loss: 2.1804 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.77351\n",
      "Epoch 50/100\n",
      "281/281 [==============================] - 231s 824ms/step - loss: 0.0358 - acc: 0.9893 - val_loss: 2.5846 - val_acc: 0.7319\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.77351\n",
      "Epoch 51/100\n",
      "281/281 [==============================] - 232s 824ms/step - loss: 0.0296 - acc: 0.9893 - val_loss: 2.6356 - val_acc: 0.7159\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.77351\n",
      "Epoch 52/100\n",
      "281/281 [==============================] - 231s 824ms/step - loss: 0.0296 - acc: 0.9911 - val_loss: 2.5108 - val_acc: 0.7287\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.77351\n",
      "Epoch 53/100\n",
      "281/281 [==============================] - 232s 824ms/step - loss: 0.0279 - acc: 0.9900 - val_loss: 3.6657 - val_acc: 0.7233\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.77351\n",
      "Epoch 54/100\n",
      "281/281 [==============================] - 232s 824ms/step - loss: 0.0319 - acc: 0.9900 - val_loss: 3.2401 - val_acc: 0.7416\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.77351\n",
      "Epoch 55/100\n",
      "281/281 [==============================] - 232s 824ms/step - loss: 0.0252 - acc: 0.9924 - val_loss: 3.0325 - val_acc: 0.7454\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.77351\n",
      "Epoch 56/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.0247 - acc: 0.9933 - val_loss: 2.9219 - val_acc: 0.7389\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.77351\n",
      "Epoch 57/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.0318 - acc: 0.9902 - val_loss: 2.4320 - val_acc: 0.6910\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.77351\n",
      "Epoch 58/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0258 - acc: 0.9922 - val_loss: 3.1846 - val_acc: 0.7429\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.77351\n",
      "Epoch 59/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.0232 - acc: 0.9931 - val_loss: 2.9862 - val_acc: 0.7389\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.77351\n",
      "Epoch 60/100\n",
      "281/281 [==============================] - 231s 824ms/step - loss: 0.0272 - acc: 0.9913 - val_loss: 3.4402 - val_acc: 0.7218\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.77351\n",
      "Epoch 61/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0255 - acc: 0.9918 - val_loss: 2.3957 - val_acc: 0.7092\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.77351\n",
      "Epoch 62/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0235 - acc: 0.9935 - val_loss: 2.8789 - val_acc: 0.7463\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.77351\n",
      "Epoch 63/100\n",
      "281/281 [==============================] - 232s 824ms/step - loss: 0.0301 - acc: 0.9915 - val_loss: 2.6089 - val_acc: 0.7193\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.77351\n",
      "Epoch 64/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0274 - acc: 0.9915 - val_loss: 2.9006 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.77351\n",
      "Epoch 65/100\n",
      "281/281 [==============================] - 231s 824ms/step - loss: 0.0214 - acc: 0.9935 - val_loss: 3.2780 - val_acc: 0.7502\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.77351\n",
      "Epoch 66/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0422 - acc: 0.9902 - val_loss: 3.3481 - val_acc: 0.7470\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.77351\n",
      "Epoch 67/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0209 - acc: 0.9940 - val_loss: 3.3454 - val_acc: 0.7463\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.77351\n",
      "Epoch 68/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0220 - acc: 0.9938 - val_loss: 3.2331 - val_acc: 0.7220\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.77351\n",
      "Epoch 69/100\n",
      "281/281 [==============================] - 232s 825ms/step - loss: 0.0254 - acc: 0.9933 - val_loss: 2.1904 - val_acc: 0.7018\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.77351\n",
      "Epoch 70/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0228 - acc: 0.9938 - val_loss: 2.3900 - val_acc: 0.7529\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.77351\n",
      "Epoch 71/100\n",
      "281/281 [==============================] - 231s 824ms/step - loss: 0.0204 - acc: 0.9940 - val_loss: 3.1342 - val_acc: 0.7476\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.77351\n",
      "Epoch 72/100\n",
      "281/281 [==============================] - 231s 824ms/step - loss: 0.0217 - acc: 0.9947 - val_loss: 3.0533 - val_acc: 0.7537\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.77351\n",
      "Epoch 73/100\n",
      "281/281 [==============================] - 232s 824ms/step - loss: 0.0266 - acc: 0.9929 - val_loss: 1.9265 - val_acc: 0.7038\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.77351\n",
      "Epoch 74/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0202 - acc: 0.9933 - val_loss: 2.7128 - val_acc: 0.6950\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.77351\n",
      "Epoch 75/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0188 - acc: 0.9940 - val_loss: 2.7697 - val_acc: 0.7752\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.77351\n",
      "Epoch 76/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0187 - acc: 0.9956 - val_loss: 3.6747 - val_acc: 0.7476\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.77351\n",
      "Epoch 77/100\n",
      "281/281 [==============================] - 231s 824ms/step - loss: 0.0210 - acc: 0.9942 - val_loss: 3.1114 - val_acc: 0.7409\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.77351\n",
      "Epoch 78/100\n",
      "281/281 [==============================] - 232s 824ms/step - loss: 0.0199 - acc: 0.9944 - val_loss: 3.3100 - val_acc: 0.6876\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.77351\n",
      "Epoch 79/100\n",
      "281/281 [==============================] - 231s 824ms/step - loss: 0.0305 - acc: 0.9931 - val_loss: 2.9778 - val_acc: 0.7348\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.77351\n",
      "Epoch 80/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0174 - acc: 0.9947 - val_loss: 2.3355 - val_acc: 0.6766\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.77351\n",
      "Epoch 81/100\n",
      "281/281 [==============================] - 232s 824ms/step - loss: 0.0124 - acc: 0.9962 - val_loss: 2.4591 - val_acc: 0.7045\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.77351\n",
      "Epoch 82/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0159 - acc: 0.9956 - val_loss: 3.2429 - val_acc: 0.7206\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.77351\n",
      "Epoch 83/100\n",
      "281/281 [==============================] - 232s 825ms/step - loss: 0.0169 - acc: 0.9962 - val_loss: 2.9434 - val_acc: 0.7186\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.77351\n",
      "Epoch 84/100\n",
      "281/281 [==============================] - 232s 824ms/step - loss: 0.0280 - acc: 0.9929 - val_loss: 3.1098 - val_acc: 0.7422\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.77351\n",
      "Epoch 85/100\n",
      "281/281 [==============================] - 232s 824ms/step - loss: 0.0259 - acc: 0.9938 - val_loss: 3.1487 - val_acc: 0.7198\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.77351\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0130 - acc: 0.9962 - val_loss: 3.0428 - val_acc: 0.6795\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.77351\n",
      "Epoch 87/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0258 - acc: 0.9929 - val_loss: 2.9817 - val_acc: 0.7260\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.77351\n",
      "Epoch 88/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.0126 - acc: 0.9958 - val_loss: 2.7277 - val_acc: 0.6808\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.77351\n",
      "Epoch 89/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0177 - acc: 0.9949 - val_loss: 3.0503 - val_acc: 0.7186\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.77351\n",
      "Epoch 90/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0127 - acc: 0.9960 - val_loss: 3.2878 - val_acc: 0.6651\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.77351\n",
      "Epoch 91/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.0204 - acc: 0.9940 - val_loss: 3.3438 - val_acc: 0.7260\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.77351\n",
      "Epoch 92/100\n",
      "281/281 [==============================] - 231s 824ms/step - loss: 0.0208 - acc: 0.9956 - val_loss: 3.0198 - val_acc: 0.7139\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.77351\n",
      "Epoch 93/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.0287 - acc: 0.9935 - val_loss: 3.2988 - val_acc: 0.7247\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.77351\n",
      "Epoch 94/100\n",
      "281/281 [==============================] - 231s 824ms/step - loss: 0.0123 - acc: 0.9973 - val_loss: 3.4767 - val_acc: 0.7233\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.77351\n",
      "Epoch 95/100\n",
      "281/281 [==============================] - 231s 824ms/step - loss: 0.0173 - acc: 0.9956 - val_loss: 3.3390 - val_acc: 0.7468\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.77351\n",
      "Epoch 96/100\n",
      "281/281 [==============================] - 231s 824ms/step - loss: 0.0091 - acc: 0.9978 - val_loss: 3.2245 - val_acc: 0.6950\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.77351\n",
      "Epoch 97/100\n",
      "281/281 [==============================] - 231s 823ms/step - loss: 0.0218 - acc: 0.9940 - val_loss: 2.9327 - val_acc: 0.6876\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.77351\n",
      "Epoch 98/100\n",
      "281/281 [==============================] - 231s 822ms/step - loss: 0.0140 - acc: 0.9949 - val_loss: 2.3079 - val_acc: 0.7206\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.77351\n",
      "Epoch 99/100\n",
      "281/281 [==============================] - 232s 824ms/step - loss: 0.0119 - acc: 0.9964 - val_loss: 2.9544 - val_acc: 0.7402\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.77351\n",
      "Epoch 100/100\n",
      "281/281 [==============================] - 232s 824ms/step - loss: 0.0196 - acc: 0.9958 - val_loss: 3.1125 - val_acc: 0.7056\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.77351\n",
      "Done. Elapsed time 23171 seconds for 100 epochs, average 231.7 seconds/epoch.\n"
     ]
    }
   ],
   "source": [
    "# Start timing\n",
    "start = time.time()\n",
    "\n",
    "# Training\n",
    "print('Training the model with unbalace dataset...')\n",
    "history_unbal = unbalance_model.fit_generator(\n",
    "    generator = train_flow_unbalance,\n",
    "    steps_per_epoch = TRAIN_STEPS,\n",
    "    epochs = N_EPOCHS + EPOCHS,\n",
    "    initial_epoch = N_EPOCHS,\n",
    "    verbose = 1,\n",
    "    callbacks = [cp_unbal],\n",
    "    validation_data = valid_flow_unbalance,\n",
    "    validation_steps = VALID_STEPS)\n",
    "stop = time.time()\n",
    "etime = stop - start\n",
    "print('Done. Elapsed time {:.0f} seconds for {:} epochs, average {:.1f} seconds/epoch.'.format(etime, EPOCHS, etime/EPOCHS))\n",
    "\n",
    "# Save the last model\n",
    "unbalance_model.save(last_weight_unbal_model)\n",
    "\n",
    "# Save the history\n",
    "with open(last_his_unbal_model, 'wb') as file_pi:\n",
    "    pickle.dump(history_unbal.history, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the same balanced validation set to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION SET\n",
      "\n",
      "Result from the LAST unbalance model\n",
      "Found 1500 images belonging to 2 classes.\n",
      "94/94 [==============================] - 16s 173ms/step\n",
      "Confusion matrix:\n",
      "[[337 413]\n",
      " [132 618]]\n",
      "\n",
      "Accuracy: 0.6367\n",
      "\n",
      "Sensitivity: 0.4493\n",
      "\n",
      "Specificity: 0.8240\n",
      "\n",
      "False Negative Rate: 0.5507\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.82      0.69       750\n",
      "           1       0.72      0.45      0.55       750\n",
      "\n",
      "   micro avg       0.64      0.64      0.64      1500\n",
      "   macro avg       0.66      0.64      0.62      1500\n",
      "weighted avg       0.66      0.64      0.62      1500\n",
      "\n",
      "Result from the BEST unbalance model\n",
      "Found 1500 images belonging to 2 classes.\n",
      "94/94 [==============================] - 15s 162ms/step\n",
      "Confusion matrix:\n",
      "[[188 562]\n",
      " [ 40 710]]\n",
      "\n",
      "Accuracy: 0.5987\n",
      "\n",
      "Sensitivity: 0.2507\n",
      "\n",
      "Specificity: 0.9467\n",
      "\n",
      "False Negative Rate: 0.7493\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.95      0.70       750\n",
      "           1       0.82      0.25      0.38       750\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      1500\n",
      "   macro avg       0.69      0.60      0.54      1500\n",
      "weighted avg       0.69      0.60      0.54      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('VALIDATION SET')\n",
    "print('')\n",
    "\n",
    "# Display evaluation of the best model that are trained by imbalanced dataset\n",
    "print('Result from the LAST imbalance model')\n",
    "display_results(last_weight_unbal_model, valid_flow)\n",
    "\n",
    "print('Result from the BEST imbalance model')\n",
    "display_results(best_weight_unbal_model, valid_flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this result, you can see that the model with the same architechture but was trained by a imbalanced set <b>tend to predict more number of class that was higher amount in class distribution</b> (you can see from the confusion matrix metric). \n",
    "\n",
    "So, <b>I chosen the model that was trained by balanced dataset</b> as by best model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model with test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As same as the 'display_results' function that I define above, but this time I use test set (10,000 records) that is unseen data to evaluate my final model for getting the final score of my best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result from the BEST model\n",
      "TEST SET\n",
      "625/625 [==============================] - 241s 385ms/step\n",
      "Confusion matrix:\n",
      "[[3567 1433]\n",
      " [1460 3540]]\n",
      "\n",
      "Accuracy: 0.7107\n",
      "\n",
      "Sensitivity: 0.7134\n",
      "\n",
      "Specificity: 0.7080\n",
      "\n",
      "False Negative Rate: 0.2866\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71      5000\n",
      "           1       0.71      0.71      0.71      5000\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     10000\n",
      "   macro avg       0.71      0.71      0.71     10000\n",
      "weighted avg       0.71      0.71      0.71     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Result from the BEST model')\n",
    "print('TEST SET')\n",
    "\n",
    "# Load the final model from the given path\n",
    "m_final = load_model(best_weight_model1)\n",
    "\n",
    "# Get the true and predicted values\n",
    "y_true = test_flow.classes\n",
    "predict = m_final.predict_generator(test_flow, steps=len(test_flow), verbose=1)\n",
    "y_pred = 1*(predict > 0.5)\n",
    "\n",
    "# Calculate and print the metrics results\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    # Display Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    print('Confusion matrix:')\n",
    "    print(cm)\n",
    "    print('')\n",
    "    \n",
    "    # Calculate Accuracy\n",
    "    a = accuracy_score(y_true, y_pred)\n",
    "    print('Accuracy: {:.4f}'.format(a))\n",
    "    print('')\n",
    "\n",
    "    # Calculate Sensitivity\n",
    "    sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "    print('Sensitivity: {:.4f}'.format(sensitivity))\n",
    "    print('')\n",
    "\n",
    "    # Calculate Specificity\n",
    "    specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "    print('Specificity: {:.4f}'.format(specificity))\n",
    "    print('')\n",
    "\n",
    "    # Calculate False Negative\n",
    "    print('False Negative Rate: {:.4f}'.format(1-sensitivity))\n",
    "    print('')\n",
    "    \n",
    "    # Display Classification report\n",
    "    cr = classification_report(y_true, y_pred)\n",
    "    print('Classification report:')\n",
    "    print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the histogram of the predicted values\n",
    "plt.hist(predict, bins = np.arange(0, 1, 0.01));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I use an ROC curve, that is a graph showing the performance of a classification model at all classification thresholds, to find new decision point that given the highest True positive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, predict)\n",
    "\n",
    "# Plot the ROC Curve\n",
    "plt.plot(fpr, tpr, color='darkorange', lw = 2)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw = 2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to change decision point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From my experiment, I got the <b>highest accuracy (72.14%)</b> by setting decision point equal to 0.6004, <b>but at this point it make we got lower Sensitivity and higher False Negative Rate</b>.\n",
    "\n",
    "\n",
    "Finally, <b>I chosen 0.4605 as my new decision point</b> because I want the accuracy score still higher than 70% but by reducing the decision point let we get higher Sensitivity and lower False Negative Rate. And this is my new metrics from new decision point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix with decision point 0.4605\n",
      "[[3776 1224]\n",
      " [1776 3224]]\n",
      "\n",
      "Accuracy with decision point 0.5000 ==> 0.7107\n",
      "Accuracy with decision point 0.4605 ==> 0.7000\n",
      "\n",
      "Sensitivity with decision point 0.5000 ==> 0.7134\n",
      "Sensitivity with decision point 0.4605 ==> 0.7552\n",
      "\n",
      "Specificity with decision point 0.5000 ==> 0.7080\n",
      "Specificity with decision point 0.4605 ==> 0.6448\n",
      "\n",
      "False Negative with decision point 0.4605 ==> 0.2866\n",
      "False Negative with decision point 0.5000 ==> 0.2448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define new decison point from ROC Curve\n",
    "dp = 0.4605\n",
    "y_pred_new = 1*(predict > dp)\n",
    "\n",
    "# Calculate new confusion matrix\n",
    "cm_new = confusion_matrix(y_true, y_pred_new, labels=[1,0])\n",
    "print('Confusion matrix with decision point {:.4f}'.format(dp))\n",
    "print(cm_new)\n",
    "print('')\n",
    "\n",
    "# Calculate new accuracy\n",
    "a_new = accuracy_score(y_true, y_pred_new)\n",
    "print('Accuracy with decision point {:.4f} ==> {:.4f}'.format(0.5, a))\n",
    "print('Accuracy with decision point {:.4f} ==> {:.4f}'.format(dp, a_new))\n",
    "print('')\n",
    "\n",
    "# Calculate new sensitivity\n",
    "sensitivity_new = cm_new[0,0]/(cm_new[0,0]+cm_new[0,1])\n",
    "print('Sensitivity with decision point {:.4f} ==> {:.4f}'.format(0.5, sensitivity))\n",
    "print('Sensitivity with decision point {:.4f} ==> {:.4f}'.format(dp, sensitivity_new))\n",
    "print('')\n",
    "\n",
    "# Calculate new specificity\n",
    "specificity_new = cm_new[1,1]/(cm_new[1,0]+cm_new[1,1])\n",
    "print('Specificity with decision point {:.4f} ==> {:.4f}'.format(0.5, specificity))\n",
    "print('Specificity with decision point {:.4f} ==> {:.4f}'.format(dp, specificity_new))\n",
    "print('')\n",
    "\n",
    "# Calculate new false Negative\n",
    "print('False Negative with decision point {:.4f} ==> {:.4f}'.format(dp, 1-sensitivity))\n",
    "print('False Negative with decision point {:.4f} ==> {:.4f}'.format(0.5, 1-sensitivity_new))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this case, I have learned about how to preprocess the images dataset and I found that it is specific for each dataset, maybe you can't use the same tecqnique when you deal with other datasets. But some techniques is still useful such as Data audmentation and Subtract color average. Using pretraining model is one of useful technique that we can use for feature extraction and fine-tuning with image data.\n",
    "\n",
    "Another topic that I have leraned in this assignment is about imbalance dataset. As my hypothesis, using imbalanced dataset to train model, it will tend to get a bias model. So, if it is possible we sholud use balanced dataset to train model or find other methods to handle them such as setting class weight.\n",
    "\n",
    "The last one is that I have used a ROC-curve metric in this case that is used to show the performance of a classification model and find a new decision point for our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
